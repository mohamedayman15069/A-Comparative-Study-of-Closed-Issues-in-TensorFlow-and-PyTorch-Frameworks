Issue Number,Issue Title,Time to Close,Number of Assignees,Number of Comments,Number of Labels,Type of Issue
93148,No matching distribution found for torch on pyenv apple silicon,0,0,2,0,['Other']
93068,Unexpected keyword argument during model compilation,0,0,1,1,['Other']
93058,why doe torch.inference_mode() requires 'with' keyword  ,0,0,2,0,['Other']
93054,DISABLED test_roi_align_dynamic_shapes_cuda (__main__.CudaTests),0,0,9,3,['Other']
93028,`torch.fft.ifft` has different jacobians computed by reverse and forward mode,0,0,2,0,['Other']
93023,building sources on Windows fails due missing cmake cache variable CMAKE_BUILD_TYPE,0,0,1,0,['Other']
93015,`split_with_sizes_copy` is missing,0,0,1,0,['Other']
93006,PT2.0 CUDA topk illegal memory access ,1,0,2,0,['Other']
92984,`retain_grad` makes the `gradcheck` fail in the forward mode ad,0,0,1,0,['Other']
92978,Segmentation fault when replaying an uninitialized CUDA graph,0,1,1,2,['Other']
92968,Segfault when running torch.cuda.comm.broadcast_coalesced,1,0,1,0,['Other']
92966,Floating point exception when running torch.nn.functional.conv3d,0,0,1,0,['Other']
92965,Floating point exception when running torch.nn.functional.conv2d,1,0,1,0,['Other']
92964,Floating point exception when running torch.nn.functional.conv_transpose2d,1,0,1,0,['Other']
92963,Floating point exception when running torch.nn.functional.conv_transpose1d,1,0,1,0,['Other']
92962,Segfault when running torch.mul,1,0,1,0,['Other']
92961,Segfault when running torch.max22,1,0,1,0,['Other']
92960,Segfault when running torch.lu_unpack,1,0,1,0,['Other']
92959,Segfault when running torch.lt,1,0,1,0,['Other']
92958,Segfault when running torch.le,1,0,1,0,['Other']
92957,Segfault when running torch.inverse,1,0,1,0,['Other']
92956,Segfault when running torch.gt,1,0,1,0,['Other']
92955,Segfault when running torch.ge,1,0,1,0,['Other']
92954,Segfault when running torch.fmod,1,0,1,0,['Other']
92953,Segfault when running torch.floor_divide,1,0,1,0,['Other']
92952,Segfault when running torch.div,1,0,1,0,['Other']
92951,Segfault when running torch.div2,1,0,1,0,['Other']
92950,Segfault when running torch.cuda.comm.broadcast_coalesced,1,0,1,0,['Other']
92949,Segfault when running torch.bitwise_xor,1,0,1,0,['Other']
92948,Segfault when running torch.bitwise_and,1,0,1,0,['Other']
92947,Segfault when running torch.add,1,0,1,0,['Other']
92941,torch.where + DDPoptimizer + Dynamo causes faketensor error,0,1,12,3,['Bug']
92887,[SDPA] Investigate compiled code not calling the same fused kernel,0,0,2,3,['Other']
92852,Nightly conda CUDA builds timeout since Sat Jan 21th 2023,2,1,10,3,['Critical']
92843,Segfault when running torch.nn.CTCLoss,0,0,1,2,['Bug']
92830,Segfault when running torch.lt,1,0,4,0,['Other']
92827,Segfault when running torch.logical_xor,1,0,1,0,['Other']
92825,munmap_chunk(): invalid pointer when running torch.linalg.ldl_solve,0,0,1,2,['Other']
92819,Segfault when running torch.linalg.inv,1,0,1,0,['Other']
92815,Tensorboard Plugin In VSCode,0,0,1,0,['Other']
92814,`torch.compile` triggers assertion error when explicitly provide `out=None`,1,1,1,3,['Bug']
92809,weight_v seems to be the same as the original weight? (About nn.utils.weight_norm()),0,0,1,2,['Other']
92808,SIGSEGV on a big-endian machine when reading a model generated on a little-endian machine ,0,0,0,3,['Other']
92807,RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation,3,0,2,3,['Bug']
92800,Segmentation fault when running torch.gt,2,0,1,0,['Other']
92799,Segfault when running torch.eq.py,2,0,1,0,['Other']
92798,FLP when running torch.nn.functional.pixel_shuffle,1,0,2,2,['Other']
92797,Segfault when running torch.div.py,2,0,2,0,['Other']
92796,FLP when running torch.nn.functional.adaptive_max_pool3d,3,0,4,0,['Other']
92795,FLP when running torch.nn.functional.pixel_unshuffle,2,0,2,0,['Other']
92793,Segfault when running torch.lu_unpack,2,0,3,0,['Other']
92792,FLP when running torch.nn.functional.conv_transpose2d,1,0,2,2,['Other']
92791,FLP when running torch.nn.functional.conv_transpose3d,2,0,4,0,['Other']
92790,Crash when running torch.Tensor.is_coalesced,4,1,3,2,['Critical']
92789,Crash when running torch.Tensor.indices,2,0,1,0,['Other']
92786,Crash when running torch.Tensor.coalesce,2,0,2,0,['Other']
92782,Double free when running torch.linalg.ldl_solve,0,0,4,3,['Other']
92780,Segfault when running torch.Tensor.copy_,2,0,1,0,['Other']
92777,Floating point exception when running torch.nn.functional.adaptive_max_pool3d,1,0,3,2,['Other']
92757,sum() not working for SparseTensor,4,1,6,2,['Other']
92684,Crash when using CUDA Graphs and calling ,3,1,12,3,['Critical']
92680,ValueError: At least one stride in the given numpy array is negative,0,0,1,2,['Bug']
92659,Large Memory Regression Between Recent Performance Dashboards,5,0,2,2,['Other']
92656,Make True the default for set_to_none in Optimizer.zero_grad for 2.0 release,5,1,4,5,['enhancement']
92633,TorchInductor Doesnt Support Generators,5,1,7,3,['Other']
92626,"GitHub Incident with Actions, Git Operations and Pages",0,0,0,1,['Other']
92622,Change PyPI installation instruction on getting started page,6,1,0,2,['Other']
92616,A precision error appears on Conv2D's bias,8,0,4,2,['Bug']
92606,Typo in CTCLoss RuntimeError - RuntimeError: target_lengths must be integral,0,0,0,0,['Other']
92602,GitHub issue: Failed to download action,0,0,0,1,['Other']
92586,Setting the `output.requires_grad` to `True` makes backward succeed,1,0,2,0,['Other']
92573,Unable to find MPI backend with Torch 2.0 nightly build from source,6,0,6,3,['Other']
92555,Disabled Tests Disable TestSuite instead of enumerating Each Individual Test,5,0,4,4,['enhancement']
92544,[Bug] repeat_interleave_cuda does not work for big tensors,0,0,1,0,['Other']
92541,state_dict['args'] empty when trying to load,1,0,1,0,['Other']
92540,Crash for ONNX export with masked setting,8,1,0,2,['Critical']
92537,non-deterministic and (sometimes) wrong results from `torch.linalg.lstsq`,1,0,2,3,['Other']
92526,DISABLED test_dict_reconstruct_keeps_original_order_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92524,DISABLED test_guard_failure_fn2_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92525,DISABLED test_release_module_memory_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92523,DISABLED test_range_input_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92522,DISABLED test_tensor_item_capture_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92521,DISABLED test_is_tensor_like2_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92520,DISABLED test_is_floating_point2_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,4,['Other']
92519,DISABLED test_not_dynamic_scope_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92517,DISABLED test_namedtuple2_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92516,DISABLED test_numel_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92514,DISABLED test_no_error_on_nested_fx_trace_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Bug']
92515,DISABLED test_torch_cudnn_is_acceptable_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92513,DISABLED test_dictcomp_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92512,DISABLED test_numpy_int_constant_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92511,DISABLED test_tensor_dict2_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92510,DISABLED test_tensor_data_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92509,DISABLED test_torch_cuda_is_available_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92508,DISABLED test_top_package_import_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92507,DISABLED test_matmul1_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92506,DISABLED test_nn_functional_reduction_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92505,DISABLED test_item_changes_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92504,DISABLED test_listcomp_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92503,DISABLED test_module_deepcopy_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92501,DISABLED test_setattr_mutation1_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92502,DISABLED test_optimize_on_module_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92500,DISABLED test_shape_unpack_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92499,DISABLED test_side_effects_codegen_update_mutated_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92498,DISABLED test_release_input_memory_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92497,DISABLED test_is_tensor2_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92496,DISABLED test_tensor_dot_grad_no_graph_break_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92495,DISABLED test_no_grad_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92494,DISABLED test_torch_nn_parameter_isinstance_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92493,DISABLED test_tensor_dict1_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92492,DISABLED test_tensor_is_contiguous_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92491,DISABLED test_tensor_types_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92490,DISABLED test_slice_input_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92489,DISABLED test_tensor_layout_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92488,DISABLED test_tensor_item_no_capture_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92487,DISABLED test_size_input_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92486,DISABLED test_is_compiling_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92485,DISABLED test_item_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92484,DISABLED test_list_append_return_none_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92483,DISABLED test_manual_seed_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92482,DISABLED test_item_changes_new_shape_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92481,DISABLED test_setattr_mutation3_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92480,DISABLED test_restore_graphstate_internals_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92479,DISABLED test_sample_input_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92478,DISABLED test_setattr_mutation2_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92477,DISABLED test_return_nested_function_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92476,DISABLED test_restore_graphstate_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92473,DISABLED test_rand_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92474,DISABLED test_recursive_inline_list_mutation_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92472,DISABLED test_raises_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92471,DISABLED test_python_slice_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92470,DISABLED test_pair_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92469,DISABLED test_onnx_shape_as_tensor_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92468,DISABLED test_object_staticmethod_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92467,DISABLED test_object_classmethod_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92466,DISABLED test_numpy_variable_isinstance_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92465,DISABLED test_nn_sequential_invocation_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92464,DISABLED test_nn_sequential_invocation_reposition_indices_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92463,DISABLED test_nested_optimize_run_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92462,DISABLED test_nested_optimize_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92461,DISABLED test_nested_optimize_decorator_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92460,DISABLED test_nested_closure_mutation_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92459,DISABLED test_nested_disable_decorator_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92458,DISABLED test_nested_closure_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92457,DISABLED test_nan_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92456,DISABLED test_namedtuple3_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92455,DISABLED test_is_tensor_like_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92454,DISABLED test_inline_dict_mutation_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92453,DISABLED test_is_tensor_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92452,DISABLED test_is_floating_point_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92451,DISABLED test_inplace_param_update_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92450,DISABLED test_inline_list_mutation_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92449,DISABLED test_inplace_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92448,DISABLED test_inline_func_jump_on_tensor_condition_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92446,DISABLED test_inference_mode_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92447,DISABLED test_if_cond_nn_mod_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92445,DISABLED test_id_of_nn_module_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92444,DISABLED test_guard_failure_fn_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92442,DISABLED test_graph_break_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92443,DISABLED test_generate_tensor_from_list_of_numpy_primitive_type_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92441,DISABLED test_grad_mode_guard_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92440,DISABLED test_grad_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92439,DISABLED test_get_device_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92438,DISABLED test_frozenset_torch_func_contains_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92437,DISABLED test_function_annotation_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92436,DISABLED test_fold_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92435,DISABLED test_error_on_nested_fx_trace_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Bug']
92434,DISABLED test_enum_no_graphbreaks_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92433,DISABLED test_empty_list_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92432,DISABLED test_dynamo_min_operator_with_shape_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92431,DISABLED test_duplicate_graph_break_warning_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92430,DISABLED test_dunder_methods_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92429,DISABLED test_disallow_in_graph_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92427,DISABLED test_dataclass_fields_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92428,DISABLED test_dict_mutation_side_effect_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92426,DISABLED test_config_log_level_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92425,DISABLED test_config_obj_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92424,DISABLED test_config_getattr_default_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92423,DISABLED test_change_backends_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92422,DISABLED test_cond_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92421,DISABLED test_cell_output2_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92420,DISABLED test_cell_output1_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92419,DISABLED test_callpacked_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92418,DISABLED test_call_parent_non_class_methods_from_child_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92417,DISABLED test_builtin_isinstance_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92416,DISABLED test_builder_for_class_with_metaclass_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92415,DISABLED test_build_tuple_unpack_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92414,DISABLED test_boolarg_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92413,DISABLED test_autograd_profiler_enabled_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92412,DISABLED test_autograd_profiler_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92411,DISABLED test_autograd_function_equivalence_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92410,DISABLED test_autocast_float64_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92409,DISABLED test_autocast_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92408,DISABLED test_autocast_device_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92407,DISABLED test_autocast_cpu_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92406,DISABLED test_cfgmod_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,2,3,['Other']
92405,DISABLED test_allow_in_graph_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92404,DISABLED test_namedtuple1_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,1,3,['Other']
92395,DISABLED test_user_property_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92394,DISABLED test_user_defined_class_name_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92393,DISABLED test_user_function_variable_supports_function_argument_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92392,DISABLED test_user_getattr2_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92391,DISABLED test_access_by_keys_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92390,DISABLED test_update_locals_and_stack_uses_shared_cache_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92389,DISABLED test_usr_cls_classmethod_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92388,DISABLED test_unpack4_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92387,DISABLED test_unpack5_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92386,DISABLED test_user_getattr1_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92385,DISABLED test_call_fn_with_non_const_inputs_safe_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92384,DISABLED test_user_function_variable_supports_type_abcmeta_argument_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92383,DISABLED test_usr_cls_staticmethod_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92382,DISABLED test_basicmodule1_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92381,DISABLED test_write_to_closures_in_inlining_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),0,0,3,3,['Other']
92368,`torch.compile` generates wrong profiling program for `randn_like`,8,1,1,2,['Other']
92343,Found many unit test failures (with cuda illegal memory access) in distributed/_tensor/test_dtensor_ops.py [v2],1,0,3,2,['Other']
92326,"Cannot build triton at pinned hash: TypeError: can only concatenate str (not ""NoneType"") to str",0,1,1,0,['Other']
92324,`torch.compile` failed on `torch.add` with a constant python number,1,0,1,3,['Other']
92316,DISABLED test_basicmodule2_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),1,0,1,3,['Other']
92301,Distributed tests failing with python 3.11,2,0,2,1,['Other']
92293,The shape inference of com.microsoft::MultiscaleDeformableAttnPlugin_TRT type is missing,6,1,1,2,['Other']
92286,"Torch 2.0 compile fails for EmbeddingBag with mode=""max""",1,0,3,3,['Other']
92233,"Potential bug in .half() - some fp32 numbers are exact in bf16, but not in fp16",0,0,1,0,['Other']
92210,DISABLED test_torch_size_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),4,0,11,1,['Other']
92209,ONNX Opset 16 GridSample Does Not Support 5D Volumetric Input Tensor,1,0,0,3,['Other']
92208,MPS M1 current_allocated_size() >= m_low_watermark_limit INTERNAL ASSERT FAILED,1,0,1,0,['Other']
92178,DISABLED test_type_copy_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),5,0,5,4,['Other']
92172,NameError: name 'sympy' is not defined - still exists in CPU build from source installation,0,0,2,0,['Other']
92166,Recent PyTorch nightly builds breaks DALLE2_pytorch model in Torchbench,7,0,24,2,['Other']
92283,Randomness 'different' results in weird behavior of Dropout,12,1,5,3,['Critical']
92140,jacobian computed with fwd and reverse strategy are conjugates (for complex input and complex output).,0,0,3,3,['Other']
92138,Fail to run quantized conv fused with add relu with oneDNN library ,3,1,1,2,['Other']
92129,AOT autograd - incorrect functionalization when requires_grad = False,0,0,1,1,['Other']
92123,"After pytorch encapsulates the custom operator, the output cannot be obtained。RuntimeError: CUDA error: an illegal memory access was encountered",0,0,4,3,['Bug']
92112,PyTorch 2.0:      KeyError: 'JUMP_ABSOLUTE'  when using torch.compile(),0,0,2,1,['Bug']
92108,"[inductor] `SyntaxError` due to invalid import alias when using `convolution = ""triton""`",11,1,0,2,['Bug']
92104,DISABLED test_torch_seed_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),6,0,3,4,['Other']
92098,"torch.eye(..., out=t) / nn.init.eye_ does not work on MPS for tensor slices",0,0,1,2,['Other']
92096,_preload_cuda_deps does not work if cublas and cudnn are in different nvidia folders,11,0,3,3,['Other']
92090,Cuda 11.8 add to CI. Cuda 11.6 deprecation,11,2,0,2,['Other']
92088,Report total channel sizes for anaconda,14,1,0,2,['Other']
92074,PYTORCH_NO_CUDA_MEMORY_CACHING=1 doesn't work,0,0,2,2,['Other']
92070,dynamo assertion error on dtype,0,0,2,1,['Bug']
92068,[Bug] dynamo tracing failure on dist.is_available(),0,0,2,1,['Bug']
92065,ModuleNotFoundError : Trying to verify the installation of PyTorch but not working even though 'torch - 1.13.1' installed in system,0,0,1,2,['Bug']
92046,DISABLED test_python_ref_executor__refs_mean_executor_nvfuser_cuda_float32 (__main__.TestCommonCUDA),14,0,2,4,['Other']
92043,Wrongly returns nan for complex numbers division,14,0,8,3,['Other']
92042,DISABLED test_torch_profiler_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),7,0,11,4,['Other']
92038,Padding op for integral inputs generates invalid inductor code,0,0,0,0,['Other']
92018,QMNIST dataset labels are all 0.,0,0,1,0,['Other']
92002,unable to install pytorch with conda on macOS 10.13,1,0,1,2,['Other']
91973,CUDA not available on RTX 4080,0,0,7,3,['Other']
91944,[Inductor] philox randn doesn't follow standard normal distribution,7,0,1,4,['Critical']
91933,`win-vs2019-cpu-py3 / build` workflows failing consistently with linker crash,2,1,14,2,['Critical']
91922,amax and amin should return the full tensor with dim=(),0,0,3,3,['Other']
91904,Nested Tensor MatMul for list of 3D tensors does not work,0,0,2,2,['Other']
91901,dynamo specializing the size of module's tensor attribute,2,1,3,1,['Other']
91894,Tensor copying not always detecting when src and dest refer to same memory location,0,0,1,0,['Other']
91882,Difference between aot_function and aot_module in AOT Autograd?,0,0,1,0,['Other']
91872,Batch Normalization with DDP,0,0,0,0,['Other']
91868,DISABLED test_torch_profiler (__main__.MiscTests),15,0,2,6,['Other']
91867,DISABLED test_torch_seed (__main__.MiscTests),15,0,2,5,['Other']
91866,DISABLED test_torch_size (__main__.MiscTests),16,0,2,5,['Other']
91851,"None Gradient, when multiplying tensor by constant",0,0,1,0,['Other']
91847,Further explanation about license using,0,0,1,0,['Other']
91843,logsumexp reference produces wrong results and doesn't follow references conventions,2,1,2,2,['Other']
91830,Resized compressed sparse tensor has wrong numel() result.,3,1,0,3,['Other']
91823,Tracemalloc giving wrong numbers for memory,2,0,1,0,['Other']
91817,[FSDP] clip_grad_norm_ always move total_norm to cpu,3,0,2,1,['Other']
91804,DISABLED test_op_has_batch_rule_ge_cpu_float32 (__main__.TestVmapOperatorsOpInfoCPU),14,0,2,4,['Other']
91797,"When the rocm environment is compiled using torch transcoding, packaging errors will occur.",7,0,0,2,['Bug']
91794,Tried to use torch.compile() to optimize model but didn't experience acceleration when running,11,0,6,1,['Other']
91793,torch.nn.BatchNorm3d get killed with large input arguments,3,0,4,0,['Other']
91791,Process killed when running torch.Tensor.repeat_interleave,4,0,4,0,['Other']
91778,"Update NLLLoss docs with ""soft targets"" aka class probabilities like in CrossEntropyLoss",0,0,1,0,['Other']
91777,"torch.compile burns-in device numbers, leading to errors when called with tensors on new device",13,0,1,2,['Bug']
91773,"Unable to import torchvision due to an error with the ""op"" function.",0,0,2,1,['Bug']
91765,OnceCycleLR Scheduler computes wrong learning rate in last step,9,0,4,2,['Other']
91764,TypeError: forward() missing 1 required positional argument: 'device',0,0,2,1,['Bug']
91762,KPI: Current distribution of issues by OS,0,1,1,1,['Other']
91758,C10_CUDA_KERNEL_LAUNCH_CHECK() becomes a no-op,11,1,2,3,['Critical']
91757,Build error: ‘LeakyReLU’ is not a member of ‘torch::jit::fuser::onednn::opkind’,0,0,2,1,['Bug']
91750,"[ONNX] exporting ONNX failed with error: ""Cannot insert a Tensor that requires grad as a constant""",0,0,0,0,['Other']
91725,Functionalization behavior change when handling indexed assignment.,0,0,2,0,['Other']
91707,"I found a solution, which is to use a context object in multiprocessing.",0,0,0,0,['Other']
91693,File location problem,5,0,11,3,['Other']
91690,narrow_copy : silently incorrect for non-contiguous inputs on CPU,4,1,1,3,['Critical']
91689,Add new field to PyTorch on Windows backlog,0,0,1,0,['Other']
91685,DISABLED test_operator_linalg_lu_factor_cuda_float32 (__main__.TestCompositeComplianceCUDA),14,0,2,4,['Other']
91683,"RuntimeError: ""logaddexp_cuda"" not implemented for 'Half'",5,1,6,1,['Bug']
91682,`torch.profiler.tensorboard_trace_handler` does not save trace with `torch.profiler.schedule`,4,0,4,1,['Other']
91659,Segmentation fault when running torch.nn.functional.fractional_max_pool2d on torch 1.13.1,0,0,5,0,['Other']
91654,Improve/relax type hints on `hook` parameter of `register_forward_hook` and `register_forward_pre_hook`,9,0,1,4,['Other']
91637,torch process kills when running torch.nn.ConvTranspose3d,6,0,5,4,['Critical']
91631,`<Sparse compressed>.conj()` fails with complex inputs (expects strided layout) and breaks complex autograd support.,7,0,0,5,['Other']
91619,Dense-sparse matrix multiplication,0,0,5,1,['Other']
91612,torch.nn.functional.conv1 return different values when the batch size of the input tensor is different,1,0,2,2,['Other']
91611,Segmentation when running torch.linalg.ldl_solve on torch 1.13.1,6,0,4,4,['Critical']
91610,DISABLED test_aot_autograd_exhaustive_svd_lowrank_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),15,0,3,2,['Other']
91598,A Hard-to-Describe Numerical Error in nn.Linear for Tensors with dim>2,0,0,1,0,['Other']
91595,Floating point exception when running torch.nn.functional.pixel_unshuffle,2,0,5,4,['Other']
91594,Floating point exception when running torch.nn.functional.conv1d,1,0,4,0,['Other']
91592,Floating point exception when running torch.nn.functional.conv3d,1,0,3,0,['Other']
91591,Segmentation fault when running torch.linalg.ldl_solve ,20,0,2,3,['Other']
91587,Floating point exception when running torch.nn.functional.conv_transpose1d,1,0,4,2,['Other']
91586,Double free or coruption when running torch.lu_solve,0,0,3,2,['Other']
91585,Segmentation fault when running torch.lu_solve with negative input tensor,0,0,3,2,['Other']
91571,Quantizing nn.MultiheadAttention does not copy batch_first attribute,16,1,1,1,['Other']
91568,torch.hub.load() fails to load from cache if there is no network and crashes,9,0,1,3,"['Critical', 'Bug']"
91567,NaN when calculating derivatives of torch.erf,17,0,2,3,['Other']
91563,New initialization functions - HeNormal and HeUniform,0,0,0,0,['Other']
91558,Floating point exception when running torch.nn.functional.conv2d,4,0,6,3,['Other']
91555,Crash when running torch.nn.functional.max_unpool3d in pytorch 1.8.0 and 1.12.0,2,0,3,2,['Critical']
91551,Pytorch 2.0 compiled model complains stride mismatch about pixel_shuffle,4,1,4,3,['Critical']
91550,Floating point exception when running torch.nn.functional.conv_transpose3d in pytorch 1.8.0 and 1.12.0 ,2,0,3,3,['Other']
91549,Floating point exception when running torch.nn.functional.conv_transpose2d in pytorch 1.8.0 and 1.12.0,4,0,5,0,['Other']
91529,The result obtained after an operation from a tensor obtained from pyTorch model does not have grad_fn and can not backward,4,0,3,2,['Other']
91528,"ONNX exporter: Float constant generated for module data member, even though it is explicitly declared as int",12,1,2,2,['Other']
91523,Insane memory usage when using gradient calculation,0,0,1,0,['Other']
91506,PyTorch 2.0 compiled torch.linspace crashes when given steps=1,4,0,0,3,['Critical']
91505,"PyTorch 2.0 torch.compile fails with unfold, unsqueeze, permute sequence for negative index",8,0,3,4,['Other']
91497,DISABLED test_tensor_requires_grad (test_jit.TestScript),14,0,3,3,['Other']
91496,DISABLED test_mm_batching (test_jit.TestScript),14,0,2,3,['Other']
91495,DISABLED test_rand (test_jit.TestScript),14,0,5,3,['Other']
91494,DISABLED test_optional_tensor (test_jit.TestScript),14,0,2,3,['Other']
91493,DISABLED test_prim_grad_undefined (test_jit.TestScript),14,0,2,3,['Other']
91492,DISABLED test_requires_grad_loop (test_jit.TestScript),14,0,2,3,['Other']
91491,DISABLED test_cat (test_jit.TestScript),14,0,2,3,['Other']
91490,DISABLED test_request_bailout (test_jit.TestScript),14,0,2,3,['Other']
91487,DISABLED test_canonicalize_tensor_iterator (jit.test_tracer.TestTracer),0,0,2,3,['Other']
91485,DISABLED test_torch_tensor_dtype (test_jit.TestScript),14,0,2,3,['Other']
91484,DISABLED test_optional_list (test_jit.TestScript),14,0,2,3,['Other']
91483,DISABLED test_stack (test_jit.TestScript),14,0,2,3,['Other']
91482,DISABLED test_tensor_as_tensor_shape_prop (test_jit.TestScript),14,0,2,3,['Other']
91480,DISABLED test_conv_dim_folding (jit.test_peephole.TestPeephole),0,0,2,3,['Other']
91451,Asymmetry in implementation of autograd.Function and functorch interaction,20,1,3,3,['Other']
91438,[JIT] Input variable is changed,11,0,3,1,['Other']
91431,"The float type is converted to the long type, and the gradient information is lost",7,0,5,0,['Other']
91420,stable `torch.sort` crash with expanded tensor,12,0,3,3,['Critical']
91404,vmap support for torch.trace,8,1,0,3,['Other']
91383,"Out of bounds error of wight[ignore_index] in torch.nn.fucntional.cross_entropy() only when using weight, label_smoothing, and reduction='mean'.",2,0,2,2,['Bug']
91382,Pytorch `tensor.dcp()` to be a shorthand for `my_tensor.detach().cpu().numpy()`,2,0,2,2,['Other']
91381,DISABLED test_sharded_tensor_to_cpu (__main__.TestShardedTensorEnumerable),3,0,2,3,['Other']
91380,concat layers/models to run them in parallel,0,0,5,0,['Other']
91378,Benchmark compare_ddp.py failed,9,0,4,3,['Other']
91373,torch.linalg.norm is greatly slower than numpy.linalg.norm,10,0,5,3,['Other']
91361,Input grad of LPPool error,3,0,2,0,['Other']
91357,[JIT] Difference in output between ONNX model created via torch.onnx.export and original PyTorch model,24,1,8,2,['Other']
91332,Many CI workflows are failing with KeyError: 'jobs',25,1,6,2,['Bug']
91313,torch fails to install inside macOs under python 3.11.0+,0,0,2,0,['Other']
91306,[Torch 2.0] Fake Tensor Fails for codegen model,0,0,6,2,['Bug']
91304,remove_weight_norm reverses the order of Orderd Dict in state_dict. (weight ⇔ bias),0,0,1,0,['Other']
91303,Exporting quantized model with `torch.cat` operators to onnx fails,32,1,0,2,['Other']
91302,RuntimeError: status != cudaStreamCaptureStatus::cudaStreamCaptureStatusInvalidated,18,0,5,2,['Bug']
91296,DISABLED test_python_ref_executor__refs_le_executor_nvfuser_cuda_int32 (__main__.TestCommonCUDA),3,0,2,3,['Other']
91294,Converting booleans into floats does not consistently yield exact 0 or 1,0,0,1,0,['Other']
91276,[RFC] [Inductor] decompose aten.exponential_,27,0,9,2,['Other']
91258,[RFC] Add support for distributed full-graph training and inference,7,0,2,1,['Other']
91246,First class dims doesn't work with python 3.11,23,0,3,2,['Other']
91242,torch.stack() is very slow compared numpy.stack(),19,0,5,2,['Other']
91240,ONNX conversion issue with data type,14,0,1,2,['Other']
91236,Two typos in `torch.distributed.distributed_c10d::broadcast_object_list`,0,0,1,3,['Other']
91225,Does Fx mode quantization support S8S8 perchannel quant,0,0,1,0,['Other']
91198,`torch.var` defaults are incorrect between CPU and MPS,0,1,0,2,['Other']
91186,torchaudio error: OSError: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory,0,0,4,2,['Bug']
91174,"vmap support for nansum, nanmean",8,0,1,3,['Other']
91161,Error on python object destruction in python 3.11,29,1,0,2,['Bug']
91107,Tensor.softmax() wasn't include in documentation,5,0,8,2,['Documentation']
91102,[Dynamo] Graph Re-compilation Invoked by Customized Operator,31,1,1,2,['Other']
91101,[Dynamo] Graph Re-compilation Invoked by `np.sqrt`,31,1,5,4,['Bug']
91097,PyTorch 1.13.1 Docker image has 1.13.0 installed,2,1,3,4,['Critical']
91095,"`torch.compile` with `""inductor""` backend is much slower than `torch._dynamo.optimize`",7,0,2,2,['Other']
91084,Pytorch 2.0: SSD from torchvision don't compile,36,1,6,3,['Other']
91080,Torch.optim Errata,1,0,1,2,['Other']
91062,A valid batch sparse compressed tensor select result does not pass validation,16,1,0,3,['Other']
91041,vmap errors when summing a 0-dim tensor within the vmap,10,1,0,3,['Bug']
91025,[FSDP] cannot find engine to run cudnn convolutions,3,0,9,4,['Other']
91010,`CSC->COO` produces `is_coalesced` outputs which are not,18,0,0,3,['Other']
91007,CSR with int32 indices to CSC conversion may produce an invalid tensor,1,2,2,2,['Other']
91005,Torch Dynamo/Inductor fails when `/tmp` is mounted `noexec`,18,0,6,3,['Critical']
91004,Mac arm64 conda builds are broken in nightly,41,0,3,1,['Other']
91003,torch.where signature mismatch,28,0,5,3,['Documentation']
91002,JIT doesn't obey __jit_unused_properties__ of modules inside a ModuleList,0,0,0,1,['Other']
90988,CUDA 12 Support,4,0,7,1,['Other']
90961,[FSDP][BE] Rename `prefixed_param_names` -> `fqns` in `_exec_order_utils.py`,31,1,0,3,['Other']
90960,Improve Test for DCP,35,1,2,2,['Other']
90951,Uninitialised access to member of torch::indexing::TensorIndex,12,0,4,4,['Other']
90940,ROCM runners timeout,43,0,11,3,['Other']
90928,Explain next steps to user once they sign EasyCLA,39,0,1,2,['Other']
90926,Log indices of dataloader during iteration,20,0,6,2,['Other']
90910,CSR to BSR conversion result has incorrect column indices and values ordering,1,1,2,3,['Other']
90882,PyTorch 2.0: RuntimeError: Inference tensors do not track version counter.,39,0,2,1,['Bug']
90851,Refactor mkldnn-specific parts out of _inductor/overrides,4,1,2,2,['Other']
90845,Cuda not available despite compatible installs,19,0,6,1,['Other']
90839,"dynamo.export does not provide node.meta[""tensor_meta""]",0,0,6,2,['Other']
90838,[FSDP] Investigate param dtype change after FSDP constructor,29,1,0,3,['Other']
90836,"`{CSR/CSC} @ {CSR/CSC}`: wrong zero result (orthogonal rows/columns, empty index intersection).",2,0,0,5,['Other']
90835,DISABLED test_return_nested_function (__main__.MiscTests),5,0,4,4,['Other']
90834,torch.compile: Warning for torch.distributions.Independent,37,1,2,2,['Other']
90833,Dead code in _sparse_coo_tensor_unsafe,27,1,0,4,['Other']
90819,"csr sparse_tensor cannot multiply by scalar. RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mask in method wrapper__sparse_mask)",8,1,1,2,['Bug']
90817,DISABLED test_sparse_triangular_solve_cuda_complex64 (__main__.TestSparseCSRCUDA),1,0,2,4,['Other']
90815,[Inductor] decompose aten.uniform_,27,1,15,2,['Other']
90794,FYI: script for counting external PRs,0,0,0,0,['Other']
90758,PR author cannot rebase PR using pytorchbot,0,1,2,3,['Other']
90756,DISABLED test_cpu_gpu_parity_nn_ConvTranspose2d_cuda_complex64 (__main__.TestModuleCUDA),8,0,2,4,['Other']
90696,Pytorch nightly conda builds for Linux and Windows failing,4,1,6,2,['Critical']
90693,`{CSR/CSC} @ {CSR/CSC}`: wrong results with empty arguments on the CPU.,15,0,2,4,['Other']
90692,libcusparse.so.11 not defined in file libcusparse.so.11 with link time reference,0,1,10,6,['Critical']
90690,Docstring for Adam optimizer argument `differentiable` is missing.,0,0,1,3,['Other']
90673,PyTorch 1.13.0 conda install failed during import due to undefined symbol,0,0,6,1,['Other']
90654,load pytorch weight file without  torch package,0,0,0,0,['Other']
90652,Assertion error triggered by CrossRefFakeMode,1,0,6,0,['Other']
90635,`torch.cumsum` is broken for integral datatypes on MPS backend,29,1,0,2,['Other']
90623,[Bug] torch.compile fails with broadcast_all in torch.distributions.utils,43,0,5,4,['Bug']
90606,Intel MKL ERROR with pytorch 1.10.0,2,0,3,4,['Bug']
90584,"[FSDP][BE] `MixedPrecision(param_dtype=torch.float32, ...)` support",3,1,1,3,['Other']
90573,[functionalization] functional tensors fail on torch.lstm,9,0,7,2,['Other']
90558,Dynamo needs support calling parent‘s non classmethod from child class ,3,1,0,3,['Other']
90550,`torch.compile` doesn't seem to work for flash attention,4,0,5,3,['Other']
90541,[FSDP][BE] Provide better error msg for training with CPU model,37,0,0,3,['Bug']
90534,TransformerEncoderLayer produce different result with padding,35,0,3,1,['Other']
90533,torch.onnx.errors.UnsupportedOperatorError: Exporting the operator 'quantized::elu' to ONNX opset version 14 is not supported,45,1,2,2,['Bug']
90532,tensor serialization on mps requires `detach()` (after `cpu()`),3,0,3,3,['Other']
90520,Tensor can not get grad_fn attribute in backward hook.,0,0,1,0,['Other']
90516,Composition of sparse `matmul` and `mul` produces wrong results.,31,0,6,4,['Other']
90504,[threaded pg] Allow test thread to terminate on detection of failure and clean shared resources on exit,0,0,0,0,['Other']
90500,nn.LSTM not working together with functional_call for calculating the gradient,13,0,1,7,['Critical']
90497,Saving and loading unallocated storage and tensor at the same time can result in incorrect dtype,18,1,0,2,['Other']
90488,as_strided gives wrong output for sliced tensors,0,0,1,2,['Other']
90486,macos-m1-12 nodes are down,0,0,4,1,['Other']
90480,"Failure in guard_fail_fn callback - raising here will cause a NULL Error on guard eval Traceback (most recent call last):   File ""/home/tiger/.local/lib/python3.7/site-packages/torch/_dynamo/guards.py"", line 897, in guard_fail_hook     guard_fn.guard_fail_fn(GuardFail(reason, orig_code_map[code])) ",0,0,1,5,"['Critical', 'Bug']"
90479,"torch.cat fails with ""INTERNAL ASSERT FAILED"" on MPS device/backend",0,0,1,2,['Other']
90467,"Adam's parameter ""differentiable"" is not documented",36,0,2,4,['Other']
90462,LibTorch (1.13.0) C++ Windows: exception in register_module() ,0,0,1,0,['Other']
90454,Inductor bug because of aten.clone lowering doesn't support memory_format,13,1,6,4,['Bug']
90453,`torch.linalg.solve` yields much lower precisions in `1.13.0` than previous versions,12,0,11,2,['Other']
90419,Tensorboard summaries can have overflows that are not well-defined,0,0,0,0,['Other']
90414,Cannot pickle 'WeakMethod' object when saving state_dict for CyclicLr,20,0,3,3,['Other']
90397,[dynamo] Accuracy minifier doesn't seem to catch bug,1,1,5,3,['Bug']
90377,Pytorch 2 error on provided docker but not on pip installation ,8,1,9,3,"['Critical', 'Bug']"
90375,PyTorch 2.0: AssertionError fake_mode is not None (possibly because of einops.rearrange),0,0,15,4,"['Critical', 'Bug']"
90361,"""dynamo"" failed for module with default args in ""forward"" function",35,1,2,4,['Bug']
90350,[PT-D][checkpoint] Remove torch/distributed/checkpoint/nested_tensor.py and move the private API to checkpoint utils,47,1,0,3,['Other']
90346,[PT-D][checkpoint] Rename init method for SavePlanner and LoadPlanner,48,1,0,3,['Other']
90343,DISABLED test_cond_export_single_arg (__main__.MiscTests),7,0,5,4,['Other']
90342,BatchNorm2d doesn't handle inf input in AMP training,47,0,9,4,['Other']
90325,[PT-D][Checkpoint][RFC] Consolidate loading optimizer state dict to load_state_dict of dist_cp directly,48,0,1,2,['Other']
90311,[MPS] test_median fails on Ventura,0,0,2,3,['Other']
90309,Torchtext nightly CPU version for Linux not available from December 01 (12/01/2022),2,0,1,0,['Other']
90285,KPI: Introduce backup/collaboration config of Grafana in Git,41,1,3,2,['Other']
90279,"'c10::Error'  what():  Expected Tensor but got Tuple, when calling multi-argument forward method of jit-traced model in cpp",1,0,2,1,['Bug']
90272,Problem with pytorch 2.0 installation: torchvision 0.15 compiled for CPU only,31,0,3,4,['Critical']
90268,torch.onnx.errors.UnsupportedOperatorError: Exporting the operator 'aten::zero' to ONNX opset version 14 is not supported.,31,1,0,2,['Bug']
90260,`unsqueeze` and `expand` metas produce wrong strides,1,0,1,6,['Critical']
90225,ctx.mark_dirty not supported with functorch,22,0,0,2,['Other']
90224,autograd.Function <-> functorch interaction followup items,43,1,2,3,['Other']
90213,"[Dynamo] TVM's meta schedule throwing TVMError: Target does not have attribute ""num-cores"", physical core number must be defined!",1,0,2,2,['Bug']
90209,autograd.Function should be consistent about returning the same Tensor object if mark_dirty was used.,16,0,0,3,['Other']
90203,Godel Model fails to compile (python 3.11),23,0,6,3,['Other']
90187,Confidential and proprietary notices on several files,9,1,2,1,['Other']
90178,torch.compile(model) error during training: no file cuda.h,3,0,5,2,['Bug']
90175,Different memory in torch2onnx from differ version.,49,0,1,3,['Other']
90170,Trying pytorch 2.0 snippet from the website - sm89 error,36,0,16,4,"['Critical', 'Bug']"
90168,Dropout makes LSTM non-deterministic,1,0,2,0,['Other']
90165,Optimizer operations as a graph,13,2,8,4,['Other']
90164,L1 regularization for PyTorch optimizers.,1,0,1,3,['enhancement']
90158,loss.backwards() cannot handle addition?,0,0,4,0,['Other']
90155,Problem with ResNet18,0,0,1,0,['Other']
90141,Compiled model cannot forward for pytorch 2.0 ,11,0,3,3,['Critical']
90137,pytorch 2 on CPU ,4,0,4,3,['Other']
90136,[Dynamo]  torch._dynamo.exc.BackendCompilerFailed: _compile_fn raised RuntimeError: `ptxas`,4,0,2,3,['Bug']
90135,Can Pytorch2.0(the current nightly build) be installed on CUDA11.4? I got the errors when built from source,3,0,5,3,['Bug']
90125,[Inductor] Codegen bug due to a custom pretty-printer,1,1,1,1,['Bug']
90116,I wonder why i cannot build the project with MinGW and Libtorch in CUDA11.7,3,0,2,0,['Other']
90102,TorchInductor: execute fails on compiled model,0,0,3,0,['Other']
90097,dynamo/torchxla integration handle dropout incorrectly for training,6,0,3,6,['Critical']
90073,DISABLED test_backward_symeig_cuda_float32 (__main__.TestCompositeComplianceCUDA),12,0,4,4,['Other']
90072,[ReduceOP] Type bug since Torch 1.13 ,3,0,1,2,['Bug']
90067,forward-mode AD on autograd.Function internal asserts if any output is non-differentiable,11,1,0,5,['Other']
90064,DISABLED test_cond_export (__main__.MiscTests),17,0,2,4,['Other']
90062,The torch.special.multigammaln operator can still run if the parameters are out of range.,1,0,2,2,['Other']
90059,All Windows conda builds are broken right now,0,1,1,6,['Critical']
90054,[ONNX] Will symbolic of custom autograd.Function be deprecated?,0,0,1,0,['Other']
90050,ShardingStrategy is ignored by FSDP when process group of size 1 is passed in,1,1,0,2,['Other']
90047,DISABLED test_cond_export_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),47,0,3,4,['Other']
90040,An error is reported when saving with a Chinese file name,2,0,6,2,['Bug']
90016,libtorch_python.so: undefined symbol: PyInstanceMethod_Type,11,0,6,3,['Other']
90011,'RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR' when using torch.nn.GRU,1,0,5,3,['Bug']
90006,torch.multinomial on CUDA tensors advances RNG based on tensor size,0,0,8,3,['Other']
89996,windows-binary-conda / conda-py3_10-cuda11_6 and conda-py3_10-cuda11_7 fails on MKL smoke test,0,1,4,0,['Other']
89995,pointnet2_batch_cuda.cpython-38-x86_64-linux-gnu.so: undefined symbol: ,0,0,1,1,['Other']
89957,"[libtorch] error LNK2001: unresolved external symbol ""const c10::intrusive_ptr_target::`vftable'""",0,0,1,0,['Other']
89941,[threaded pg] tracking MultithreadedTestCase/threaded pg related issues,54,6,3,2,['Other']
89935,Nightly Windows+CUDA+Conda+Py-3.10 tests fail,13,1,9,5,['Critical']
89920,Please verify 1.13.0 ONNX release candidate on TestPyPI,11,1,1,2,['Other']
89895,Batching rule for prelu does not handle case when input is 1-D or scalar and weight is non-scalar,30,0,1,3,['Other']
89875,Getting wrong warning for integer division,1,0,2,3,['Other']
89857,Take slices that maintain gradient information,28,0,3,3,['enhancement']
89855,[v.1.13.1] Release Tracker,16,0,26,1,['Other']
89836,F.grid_sampling with half precision type has very large numeric error,15,0,5,3,['Bug']
89823,part of the module that I create in cpp extension code don't auto backward,0,0,0,0,['Other']
89801,Allowing List types in torch.autograd.Function,0,0,2,0,['Other']
89761,Shape error in torch.linalg.solve backend,31,1,0,2,['Bug']
89753,performance problem on  dataloader with pinned memory,30,0,9,3,['Other']
89752,OSError: [WinError 182] Operating system can't execute %1,57,1,6,3,['Bug']
89734,Masked Tensor documentation is missing,0,0,1,4,['Documentation']
89727,[typing] torch.norm and Tensor.norm `p` type hint ,1,0,3,3,['Other']
89725,virtual memory exhausted: Cannot allocate memory ,0,0,2,0,['Other']
89705,"C++ libtorch ""rot 90()"" has performance problems in the loop",2,0,1,0,['Other']
89704,"RuntimeError: isDifferentiableType(variable.scalar_type()) INTERNAL ASSERT FAILED at ""/opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/autograd/functions/utils.h"":64, please report a bug to PyTorch. ",3,0,1,0,['Other']
89693,Hangs at tensor.float() in child process only if tensor.float() is called in main process ,2,0,2,0,['Other']
89683,Add helpful message to MultiheadAttention module,0,0,2,0,['Other']
89681,"Failed to build from source - third-party build with default /usr/bin/c++, not with gcc-11",3,0,2,2,['Other']
89677,"`torch.nn.functional.embedding_bag` Trigger ""IOT instruction"" Failure",20,1,13,4,['Critical']
89676,DISABLED test_cond_nested_dynamic_shapes (torch._dynamo.testing.make_test_cls_with_patches.<locals>.DummyTestClass),54,0,16,4,['Other']
89648,`torch._C._nn.fractional_max_pool3d` Trigger Segmentation Fault,13,0,6,5,['Bug']
89633,[dynamo] RuntimeError: Failed running call_function aten._to_copy(*(FakeTensor(FakeTensor(...,62,0,1,2,['Bug']
89632,[dynamo] RuntimeError: Failed running call_function aten.ScalarImplicit(*(FakeTensor(FakeTensor(...,0,0,1,0,['Other']
89628,[dynamo] RuntimeError: Failed running call_function aten.bincount(*(FakeTensor(FakeTensor(...,0,0,1,0,['Other']
89626,`make_fx` makes tensors unpickleable,20,0,1,6,['Critical']
89624,IndexError when using F.pad with MPS backend (Mac m1),19,0,1,2,['Bug']
89622,test issue,0,0,0,0,['Other']
89615,convert LSTM to onnx BUG,60,1,2,2,['Bug']
89577,PyTorch not compiling on Windows with C++17,18,1,4,2,['Other']
89565,dtype conversion failure when adding tensors without dimension,5,0,4,2,['Other']
89560,Meta PReLU failing when input shape is 1D,19,1,1,3,['Other']
89558,KLDivLoss backward computation error,6,0,8,4,['Bug']
89556,cuFFT error raised after trying FFT,5,0,1,5,"['Critical', 'Bug']"
89555,"RuntimeError: isDifferentiableType(variable.scalar_type()) INTERNAL ASSERT FAILED at ""/opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/autograd/functions/utils.h"":64, please report a bug to PyTorch. ",6,0,2,0,['Other']
89550,"when inferencing the model, it reports ""RuntimeError: Could not run 'aten::empty_strided' with arguments from the 'QuantizedCPU' backend.",5,0,4,1,['Bug']
89539,Prims Suggest Memory Format Divergence From Eager,6,0,0,2,['Other']
89529,Use AVX512/AVX2 intrinsics where `-O2` compilation flag doesn't auto-vectorize,22,1,1,3,['Other']
89497,pickle fails on sparse CSC/BSR/BSC tensors,1,1,2,3,['Other']
89481,OSError when there are too many concurrent processes,6,0,5,2,['Bug']
89478,torch.renorm gets different results in different pytoch versions.,1,0,3,2,['Other']
89450,@torch.no_grad causes pickling error when using more than one GPU,1,0,4,4,['Bug']
89412,"torch.nn.functional.conv1 passes in the same parameters, but gets different results on CPU and GPU.",2,0,2,4,['Bug']
89411,"RuntimeError: ""min_all_cuda"" not implemented for 'ComplexFloat'",0,0,1,0,['Other']
89404,nn.NLLLoss behaves differently on CPU and GPU.,0,0,2,2,['Other']
89403,Edge case: complex torch.nn.PoissonNLLLoss has inconsistent NaN behavior between CPU and CUDA,3,0,7,5,['Other']
89402,The exception thrown by torch.sparse_coo_tensor running on GPU is confusing.,9,1,3,2,['Other']
89400,torch.triu、torch.tril: gives different results under different devices.,0,0,1,2,['Bug']
89380,torch.nn.LPPool1d throws different exceptions on CPU and GPU,1,0,2,3,['Other']
89379,torch.nn.Linear gives different results on CPU and GPU.,1,0,4,2,['Other']
89366,"RuntimeError: ""log_softmax_lastdim_kernel_impl"" not implemented for 'Half'",0,0,3,0,['Other']
89353,cat with channels-last memory layout is incorrect on MPS,47,1,2,2,['Other']
89352,Dataloader hanging when num_workers >0 ,1,0,6,3,['Other']
89348,torch.where: The exception information thrown differs from the official documentation,2,0,2,1,['Documentation']
89347,torch.nn.ConstantPad1d: An exception exists in the case of a particular parameter,3,0,2,3,['Other']
89345,Edge case: torch.nn.AvgPool1d's error message incorrectly describes what's wrong when giving an unexpected type,3,0,2,4,['Bug']
89341,torch.matrix_rank: An inaccurate description of the input dimension,3,0,3,3,['Other']
89339,torch.matrix_power: Exceptions thrown on the CPU and GPU are inconsistent,3,0,8,2,['Other']
89338,torch.matmul: The results on the CPU and GPU were inconsistent,2,0,1,2,['Other']
89335,torch.cholesky_inverse: The result accuracy was inconsistent on the CPU and GPU,1,0,0,0,['Other']
89296,DISABLED test_pickle_cuda_float64 (__main__.TestSparseCUDA),34,0,4,4,['Other']
89285,test_jit_cuda_fuser often crashes with SIGIOT,26,0,18,4,['Critical']
89276,"torch.addcdiv: input, tensor1, and tensor2 parameters should be of the same type",0,0,0,0,['Other']
89261,Unconvertible op `aten::relu_` for torchvision resnet18 on torch 1.13,3,0,5,2,['Other']
89224,Deprecation warning in `Tensor.storage()` should suggest alternate API,41,1,2,3,['Other']
89190,[ONNX] OnnxExporterError when exporting SAGEConv with dynamic_axes,42,1,15,3,['Bug']
89179,The operator 'aten::cumsum.out' is not current implemented for the MPS device.,0,0,1,1,['Other']
89168,DISABLED test_dispatch_meta_outplace_fft_fft_cuda_bool (__main__.TestMetaCUDA),27,0,4,3,['Other']
89156,DISABLED test_dispatch_meta_outplace_fft_ifft_cuda_float64 (__main__.TestMetaCUDA),29,0,4,4,['Other']
89104,"[OneDNN] Error ""could not create a primitive"" on AMD CPU",22,1,7,5,['Bug']
89092,Mac OS workflows are getting cancelled,0,0,0,1,['Other']
89088,empty_like_quantized silently drops is_pinned parameter,0,0,1,0,['Other']
89087,DISABLED test_conv1d_vs_scipy_mode_same_cuda_complex64 (__main__.TestConvolutionNNDeviceTypeCUDA),2,1,2,5,['Critical']
89082,Cannot import torch after installation,0,0,1,0,['Other']
89053,Missing commonly used parameters in AdaptiveLogSoftmaxWithLoss,0,0,1,0,['Other']
89040,`c10/util/safe_numerics.h` fails to compile targeting ARM with MSVC,1,0,0,4,['Other']
89021,Cleanup optimizer handling of complex numbers for LBFGS and SparseAdam,0,0,2,4,['Other']
89012,ROCm runner only shows 3 GPUs,0,0,1,1,['Other']
88986,Results differ using Conv2d + bias=False,0,0,3,0,['Other']
88985,`torch.fft.hfft` Trigger RuntimeError under UndefinedBehaviorSanitizer,9,0,3,2,['Bug']
88978,Input type (MPSByteType) and weight type (MPSFloatType) should be the same,56,0,2,2,['Other']
88977,"Windows Install ""ERROR: torch has an invalid wheel, .dist-info directory not found"" Without Anaconda",0,0,1,0,['Other']
88967,[build] libtorch_cuda.so: undefined reference to `std::condition_variable::wait(std::unique_lock<std::mutex>&)@GLIBCXX_3.4.30',2,0,2,2,['Other']
88965,Low precision of division by scalar in CPU mode.,1,0,4,0,['Other']
88958,Invalid Function Signatures for pybind modules,3,0,8,3,['Other']
88954,DDP multithreading SIGTERM crash,9,0,4,1,['Critical']
88953,"Tensor slicing within loop silently fails assignment, vs effective same slice assignments out of loop works as expected",1,0,4,0,['Other']
88939,`torch.nn.functional.interpolate` Trigger heap-buffer-overflow with AddressSanitizer ,5,1,6,4,['Other']
88929,Automatic Mixed Precision (AMP) doesn't run BatchNorm in FP32,0,0,6,1,['Other']
88916,DISABLED test_fft_round_trip_cuda_float32 (__main__.TestFFTCUDA),38,0,7,2,['Other']
88910,Error in scoring a loaded model in C++,2,0,1,0,['Other']
88900,AttributeError: 'Encoder' object has no attribute 'norm_pre',2,0,1,0,['Other']
88873,torch\utils\cpp_extension.py should be fixed,0,0,1,3,['Other']
88869,On CPU-only machine received OSError from importing: libcublas.so.11: cannot open shared object file,26,3,8,4,"['Critical', 'Bug']"
88868,`torch.jit.annotations.parse_type_line` is not safe (command injection) even it seems already deprecated.,6,1,16,4,['Critical']
88865,DISABLED test_extract_gradients_from_module (__main__.TestIdentifyGradients),40,0,2,3,['Other']
88843,"Fix dynamo handling of `.T`, `.H`, `.mT`, `.mH`",59,1,0,2,['Other']
88840,DISABLED test_embedding_dense_backward (__main__.TestNLLLoss),0,0,3,1,['Other']
88839,module 'torch.cuda' has no attribute '_UntypedStorage',0,1,7,0,['Other']
88836,Weight decay handled differently in torch.optim.radam compared to original implementation,13,0,4,2,['Other']
88835,Error in installing C++ Distribution of PyTorch,41,1,4,4,['Bug']
88834,torch.load is slow for CUDA models with _use_new_zipfile_serialization=True,0,0,4,0,['Other']
88833,docker: pytorch-nightly latest tag hasn't been published in 18 days,4,0,3,2,['Other']
88824,Cannot install VSIXTorch,55,1,5,3,['Other']
88809,INTERNAL ASSERT when saved input detached inplace,2,0,0,2,['Other']
88808,`median` INTERNAL ASSERT FAILED with `dims < 25` on CUDA,53,0,2,3,['Other']
88806,Fast path for MultiheadAttention does not work with instances with dropout despite being in eval mode,0,1,5,2,['Other']
88793,torch.CharStorage cause abort when called with torch.save,1,1,4,2,['Other']
88738,test_make_fx_symbolic_exhaustive fails for scalar_tensor,19,0,1,1,['Other']
88734,[Inductor] invalid argument from running resnet18 with torchbench.py,13,0,4,2,['Other']
88724,`MultiMarginLoss` Trigger out-of-bound Read under Compute Sanitizer,6,1,2,3,['Critical']
88708,torch._dynamo.allow_in_graph does not work for python built-in operators,8,0,0,3,['Bug']
88685,distributed.scatter_object_list shows RuntimeError: Tensors must be CUDA and dense,7,0,2,1,['Bug']
88684,CylicLR is unpickle-able due to WeakMethod defined in `_scale_fn_ref` attribute,65,0,6,3,['Other']
88680,Inversing a 0-determinant matrix led to no error,2,0,3,3,['Bug']
88679,MPS test_embedding_dense_backward is possibly flaky?,2,0,7,3,['Other']
88669,"Runtime Error raised by `torch.nn.modules.activation.MultiheadAttention` when `bias=False, batch_first=True`",35,0,9,2,['Bug']
88659,PyTorch conda install : really slow CUDA download,1,0,19,4,['Critical']
88652,linspace behave differently than numpy linspace,41,0,4,7,['Critical']
88650,`lobpcg` will randomly fail for the same input on CPU,6,0,2,3,['Other']
88586,"functorch.dim breaks split of ""big"" tensors on cpu",32,0,0,2,['Other']
88568,miniconda3/envs/proj1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead,17,1,3,1,['Other']
88567,"How Can I Know Which Convolution Algo Was Used When I Set ""torch.backends.cudnn.benchmark = True""?",1,0,3,3,['Other']
88556,`torch.cumprod` produces `nan` unexpectedly on GPU,3,0,8,3,['Other']
88543,Out of bounds read in `copy_impl` due to unsafe `fbgemm` APIs,10,1,4,6,"['Critical', 'Bug']"
88519,allow torch.bmm on nested_tensors of dim == 3 or (dim==4 and size(1)==1),3,0,14,2,['Other']
88518,PyTorch is not compatible with Python 3.11.0,1,0,2,0,['Other']
88493,`Tensor.type` doesn't return the original object when the type is correct on CUDA,0,0,2,0,['Other']
88487,[MPS] Add support for aten::unique_consecutive for MPS backend ,61,0,1,2,['Other']
88485,DISABLED test_fn_grad_linalg_lu_factor_cuda_complex128 (__main__.TestBwdGradientsCUDA),38,0,2,6,['Other']
88476,DISABLED test_forward_mode_AD_linalg_lu_factor_cuda_float64 (__main__.TestFwdGradientsCUDA),38,0,2,7,['Other']
88470,`Tensor.where` inconsistent with `torch.where`,81,0,9,3,['Other']
88469,DISABLED test_fn_gradgrad_linalg_lu_factor_cuda_complex128 (__main__.TestBwdGradientsCUDA),38,0,2,6,['Other']
88463,torchaudio 0.13.1 patches,39,1,6,1,['Other']
88446,[RFC] Implement hooks for Optimizer.step,28,1,1,3,['Other']
88438,`torch.load` overwrites `pickle_module` parameter indescriminately,5,0,2,2,['Other']
88419,`BSR/BSC`: impossible to use `.to(dtype)` because `empty_sparse_compressed` does not support block formats.,13,0,2,2,['Other']
88416,Manual implementation of var does not give the same value as torch.var,0,0,2,0,['Other']
88390,Whether to support libtorch source code compilation of C++11 ？,0,0,1,0,['Other']
88368,DISABLED test_vmap_autograd_grad_linalg_lu_cuda_float32 (__main__.TestOperatorsCUDA),39,0,2,4,['Other']
88363,NVIDIA driver issue,0,0,2,1,['Other']
88352,Failed to install NVIDIA driver,40,1,10,3,['Critical']
88331,"[MPS] [1.13.0 regression] autograd returns NaN loss, originating from NativeGroupNormBackward0",49,0,17,5,['Critical']
88326,ATen incompatible with CUDA 11 arch 8.7+PTX,43,0,2,3,['Other']
88312,Double-backward with `full_backward_hook` causes `RuntimeError` in PyTorch 1.13,14,1,3,5,"['Critical', 'Bug']"
88299,[ONNX] support extra parameters for Bernoulli when exporting,14,0,1,5,['enhancement']
88296,DISABLED test_comprehensive_cholesky_solve_cuda_complex64 (__main__.TestDecompCUDA),26,0,2,5,['Other']
88294,Lost conjugate information when transferring a tensor in RPC,0,0,2,1,['Other']
88290,lib/python3.8/site-packages/torch/include/torch/csrc/jit/serialization/export_bytecode.h:11:10: fatal err or: torch/csrc/jit/mobile/function.h: No such file or directory  #include <torch/csrc/jit/mobile/function.h>,12,0,2,2,['Other']
88258,Adam(fused=True) unexpected behaviour (massively decreased accuracy),1,0,5,5,['Critical']
88236,Improve SSH experience by moving env vars into docker image,35,1,5,2,['Other']
88231,[Dr. CI] Add a way to refresh Dr. CI results from HUD,9,1,0,2,['Other']
88214,Symmetric quantization ignored during learning,5,0,2,1,['Other']
88206,HUD sometimes doesn't show any/most of the tests,0,0,1,0,['Other']
88205,"Fake tensor RuntimeError: !grad_fn INTERNAL ASSERT FAILED at ""../torch/csrc/autograd/variable.cpp"":792",1,1,3,2,['Bug']
88201,Dynamo C++ compile error,7,1,3,2,['Bug']
88187,Permute method of Tensor with first-class dims inconsistent with `torch.Tensor.permute`,1,0,2,1,['Other']
88184,`torch.topk` function giving incorect output,0,0,5,0,['Other']
88181,When will pytorch be supported by python 3.11?,0,0,1,0,['Other']
88166, ImportError: cannot import name ‘_set_torch_function_mode’ from ‘torch._C’ (/Users/davidlaxer/anaconda3/envs/AI-Feynman/lib/python3.10/site-packages/torch/_C.cpython-310-darwin.so),0,0,2,2,['Bug']
88126,`clflow/inductor` label is auto-removed after a push to a PR,0,1,4,2,['Other']
88118,[ONNX] Adopt OpInfo testing,45,0,2,4,['Other']
88111,Formalize instructions for customers to make request to the DevX team,9,1,1,2,['Other']
88105,test_fn_grad should pass for as_strided_scatter operator,1,0,1,4,['Other']
88101,`torch.linalg.lstsq` gives wrong result on GPU,0,0,4,4,['Other']
88097,No backward implementation for Scatter Multiply (or add) reduction ,0,0,3,3,['Other']
88094,`torch.bitwise_left_shift` crash with segmentation fault when out is torch.Tensor,0,0,3,4,['Critical']
88087,Cannot print in fake tensor mode,8,1,3,2,['Other']
88082,Crash with `numpy >=1.23.4` and `torch 1.13.0` due to `DLpack` interaction,58,0,18,4,['Critical']
88079,Indexing Tensor with One Value in torch.where Gives Shape Mismatch,0,0,0,0,['Other']
88077,AttributeError: 'BertModel' object has no attribute 'save',7,0,8,1,['Bug']
88074,Datapipes: Batcher and ShardingFilter interaction leads to wrong `__len__`,39,0,4,3,['Other']
88073,"How to export pytorch model to onnx, with input of List[Tuple[Tensor,Tensor]] and output of List[Tuple[Tensor,Tensor]]",21,1,3,4,['Other']
88050,UserWarning: FALLBACK path has been taken inside: torch::jit::fuser::cuda::runCudaFusionGroup,84,2,7,3,['Other']
88049,PyTorch 1.13 cannot be installed using `poetry` on Mac M1,19,0,12,3,['Other']
88042,CI ASAN doesn't appear to be running UBSAN,2,0,6,2,['Other']
88038,CUFFT_INTERNAL_ERROR on RTX 4090,66,0,11,4,['Bug']
88035,Segment Fault in fbgemm_linear_quantize_weight,4,0,3,1,['Other']
88021,SyncBatchNorm 3D is slow with torch.channels_last_3d format in DDP on GPU,17,0,3,1,['Other']
88013,DISABLED test_operator_nn_functional__scaled_dot_product_attention_cuda_float32 (__main__.TestCompositeComplianceCUDA),44,0,4,3,['Other']
88010,slow-gradcheck tests take > 4 hrs and time out,5,1,1,3,['Critical']
88000,ProcessGroupNCCL watchdog timeout not working,2,0,1,4,['Critical']
87997,Crash while handling `torch.save` exception,3,1,3,4,['Critical']
87994,Mergebot doesn't always fail early when some have failed,89,1,0,2,['Other']
87991,"Faulty Pytorch 1.13 GPU conda package causes CPU to be installed, when using official install command from Pytorch website",2,0,4,2,['Other']
87990,Dispatch mode and torch function disable are inconsistent,12,1,1,3,['Other']
87978,The memory usage of libtorch algorithm model is different on different hardware,3,0,1,2,['Other']
87976,is there a Maxpool2dwithargmax in pytorch nn layers?,2,0,1,0,['Other']
87968,[PT 1.13] resize bilinear yields different results in newer versions,10,1,5,4,['Other']
87963,`torch.overrides.has_torch_function` crash with segmentation fault,14,0,3,2,['Critical']
87962,`lu_unpack` crash with free(): invalid pointer,3,0,1,3,['Critical']
87958,INTERNAL ASSERT FAILED t.defined() && (t.dim() == 1 || t.dim() == 0),12,0,2,2,['Other']
87953,NotImplementedError: The operator 'aten::index_add.out' is not current implemented for the MPS device.,7,0,3,2,['Bug']
87944,CUDA will cast `-1` to `0` when casting to `int64` in some cases,0,0,1,2,['Other']
87894,[CUDAGraph] Silent failure when graphs capture attempted on wrong device ,32,0,0,2,['Other']
87881,Need magma-cuda118 to Build from source on CUDA 11.8,0,0,4,0,['Other']
87868,Dr. CI is sometimes out of date,47,1,5,2,['Other']
87865,PR Label enforcer: Make notice disappear once labels are added,4,1,2,1,['Other']
87862,torch.where: `out` kwarg support is undocumented,0,0,2,3,['Other']
87850,PyTorch Build Error with Undefined Behavior Sanitizer,4,0,1,0,['Other']
87843,AttributeError: 'torch.dtype' object has no attribute 'numel',6,0,3,1,['Bug']
87842,torch._refs.add/sub/mul/div returns incorrect dtype for scalar only inputs ,0,0,3,1,['Other']
87835,"*** RuntimeError: CUDA error: device-side assert triggered for this : tmp = torch.ones([3, 8]).cuda()",0,0,2,0,['Other']
87815,"[FSDP] Full State Dict unable to save models, assert failure fqn in state dict. 10/23+ nightlies",4,1,4,4,['Critical']
87789,Any ideas on how we can convert a model from huggingface (transformers library )to tensorflow lite?,0,0,1,0,['Other']
87784,Unable to see the weight files after quantization,5,0,2,1,['Other']
87780,MPS throws error when using Softplus activation,14,0,0,2,['Bug']
87778, Is there any mismatch for hardswish_backend when input x equal to 3,2,0,3,5,['Other']
87774,"`log2`, `LSTM.forward` raise SIGFPE on some args and environments",5,0,4,5,['Critical']
87771,TorchDynamo: reduce memory copy which introduced by max_pool2d for cpu backend,53,1,3,2,['Other']
87749,DISABLED test_backward_linalg_lu_cuda_float32 (__main__.TestCompositeComplianceCUDA),47,0,2,5,['Other']
87738,[ONNX] Shape inference is not working for some contrib operators,24,1,7,4,['Other']
87723,Python3.11 Support,0,0,2,0,['Other']
87721,Minor typo in torch.flip and torch.rot90,0,0,2,2,['Minor']
87713,Custom Autograd Functions Don't Work If Forward Pass Outputs a List of Tensors,7,0,27,3,['Other']
87711,CMake Error: Error: generator : Ninja,0,0,1,2,['Bug']
87708,Can't quantize model when using int8 datatype for operations ,2,1,11,1,['Other']
87703,KPI: Number of issues closed,34,1,1,2,['Other']
87702,"KPI: Distribution of issues by Type, Kind, Severity and T-Shirt Size",77,1,0,3,['Other']
87700,KPI: Create KPI dashboard with first metric,34,1,2,2,['Other']
87699,"KPI: Average time to first response, average time to respond to any turn over message",42,1,1,2,['Other']
87698,KPI: Average age of issues,41,2,1,2,['Other']
87685,AssertionError: Dequantize index 1 exceeded reference node's arg length 1,0,0,0,0,['Other']
87684,Eager mode CPU Autocast implementation for `torch.cat` seems to be broken,3,0,4,3,['Other']
87681,"error: ""caffe2::cuda"" is ambiguous",0,0,1,3,['Bug']
87679,fuse qat model using `fuse_modules_qat` instead of `fuse_modules`,8,0,1,1,['Other']
87677,[ONNX] Dynamic shape is not respected for Tensor.expand,21,0,5,3,['Other']
87672,INTERNAL ASSERT FAILED source.dtype() == self.dtype() ,16,0,6,3,['Other']
87671,DISABLED test_comprehensive_diagflat_cpu_float16 (__main__.TestDecompCPU),58,0,2,5,['Other']
87659,Preserve module hierarchy information in torch.FX graph.nodes,38,0,3,2,['Other']
87658,Inconsistent result from order of operations,0,0,1,0,['Other']
87657,`histc` return inconsistent value on CPU and CUDA,24,0,0,2,['Other']
87626,Test that `import torch` does not change global logging state,1,0,0,1,['Other']
87609,[ONNX] Converter did not consider the implicit casting specifically for `Max`,27,1,2,5,['Bug']
87607,DISABLED test_comprehensive_diagflat_cpu_bfloat16 (__main__.TestDecompCPU),57,0,2,5,['Other']
87595,nvrtc: error: invalid value for --gpu-architecture (-arch),0,1,16,4,"['Critical', 'Bug']"
87592,Last activation not quantized,1,0,2,1,['Other']
87587,Feature Request: FP8 multiplication with BF16 accumulation,7,0,1,2,['enhancement']
87584,stft output shape is not right,9,0,2,2,['Other']
87581,DISABLED test_module_and_optimizer_ids (__main__.TestTorchTidyProfiler),53,0,7,3,['Other']
87565,CPU and CUDA overflow in an inconsistent way,0,0,2,3,['Other']
87564,Meta impl for pirms.where is incorrect,2,0,2,3,['Other']
87557,`InstanceNorm3d` returns different value on cpu and cuda for the same input,0,0,1,2,['Other']
87552,torch.Tensor.get_device would not be updated for CPU tensors behavior,8,1,2,2,['Other']
87546,Fatal error: sleef.h: No such file or directory,24,1,3,3,['Bug']
87544,Dropout2d Changes Values of Input Tensor,0,0,1,0,['Other']
87540,"`register_full_backward_hook` doesn't fire on module returning `List[Tensor]` or `Dict[Any , Tensor]`",88,1,3,2,['Other']
87511,build: failure when building pytorch with TBB ,3,0,0,3,['Other']
87500,"Lots of our builds are failing with ""Runner shutdown""",0,1,2,1,['Other']
87476,Build Error:  no member named 'LeakyReLU' in 'dnnl::graph::op::kind',0,0,3,3,['Bug']
87466,dynamo emits warning when using `min()`/`max()`,0,0,1,1,['Other']
87428,Unable to use pytorch docker image on GPU enabled AWS instance,0,0,3,3,['Other']
87410,Wrong backend check for DebugLevel.DETAIL,5,0,3,2,['Bug']
87401,FSDP.clip_grad_norm_'s behavior is different from documentation,6,1,1,3,['Documentation']
87398,Model outputs different values after ONNX export,94,1,6,3,['Other']
87372,"[torchscript] Dictionary with str key and heterogenous value is not matched with Dict[str, Any]",0,0,1,1,['Other']
87368,TorchScript bug: torch.nn.transformer gives inconsistent results after conversion to TorchScript,8,0,2,1,['Bug']
87363,"Moving a tensor across CUDA devices gets zero tensor, CUDA 11.0",0,0,6,0,['Other']
87360,[C++] There's no way to put a model on the CUDA device that will process a tensor already on the CUDA device,0,0,0,0,['Other']
87359,Use after free in TensorPipeAgent,4,1,3,3,['Critical']
87355,[torch.float16] Tensor product @ produces different output when batch size is changed,0,0,5,1,['Other']
87354,All zero output when giving nn.Conv3D a large size tensor,4,0,4,6,['Critical']
87347,DISABLED test_comprehensive_addcmul_cuda_complex64 (__main__.TestDecompCUDA),39,0,2,5,['Other']
87346,DISABLED test_comprehensive_cholesky_solve_cuda_complex128 (__main__.TestDecompCUDA),39,0,5,5,['Other']
87344,"Torch Quantize aware training. The function prepare_qat_fx(),  should support parameter of 'concrete_args'.",4,0,1,2,['Other']
87336,Unexpected segmentation fault encountered in worker when using Pytorch Geometric to load dataset,4,0,3,2,['Other']
87332,DISABLED test_complex_half_reference_testing_nn_functional_conv_transpose2d_cuda_complex32 (__main__.TestCommonCUDA),42,1,2,6,['Other']
87323,DISABLED test_comprehensive_addmm_cuda_complex64 (__main__.TestDecompCUDA),40,0,2,5,['Other']
87321,[ONNX] Refactor on torch.onnx.export_to_pretty_string,1,1,1,2,['Other']
87320,[ONNX] Move all torch.onnx.export related tests into test/onnx,9,1,1,3,['Other']
87313,Improper model conversion from PyTorch to ONNX with torch.onnx.OperatorExportTypes.ONNX_ATEN flag ,13,3,5,2,['Other']
87287,Deterministic indexing operation fails in indices size check / missing broadcast (CUDA Tensor broadcasting),0,0,1,0,['Other']
87280,DDP cannot handle Linear(output_features=0),13,1,1,1,['enhancement']
87279,ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.30' not found (required by /home/***/lib/python3.10/site-packages/torch/lib/libtorch_python.so),0,0,0,0,['Other']
87277,RuntimeError using torch.nn.functional.pad only when using MPS,55,1,3,2,['Bug']
87265,pypi in no torchaudio with torch1.1.0 match,2,0,2,1,['Other']
87220,[MPS] Add support for aten::median for MPS backend,30,1,4,3,['Other']
87210,Actions might queue/get cancelled/not get scheduled,0,0,1,1,['Other']
87208,Run Simulator Tests fails with Segmentation Fault #87207,0,0,9,1,['Other']
87207,dupe,0,0,1,0,['Other']
87206,torch.masked_select outputs a too large tensor filled with trash when the mask is obtained from PIL,0,0,4,1,['Other']
87191,Warning and breaking changes around ReduceOP in 1.13,3,0,7,3,['Other']
87175,DISABLED test_vjpvmap_linalg_lu_factor_cuda_float32 (__main__.TestOperatorsCUDA),55,0,2,4,['Other']
87173,torch/csrc/distributed/c10d/Types.hpp: No such file or directory,6,0,15,5,['Other']
87171,`torch.std` output is not zero for an array of the same values,3,0,2,0,['Other']
87168,DISABLED test_vjpvjp_linalg_lu_factor_cuda_float32 (__main__.TestOperatorsCUDA),55,0,2,4,['Other']
87169,DISABLED test_comprehensive_addcmul_cuda_complex128 (__main__.TestDecompCUDA),41,0,2,5,['Other']
87167,DISABLED test_comprehensive_cartesian_prod_cuda_complex64 (__main__.TestDecompCUDA),41,0,3,5,['Other']
87166,DISABLED test_comprehensive_addmv_cuda_float16 (__main__.TestDecompCUDA),59,0,2,5,['Other']
87165,DISABLED test_comprehensive_cdist_cuda_float64 (__main__.TestDecompCUDA),59,0,2,5,['Other']
87164,DISABLED test_comprehensive_linalg_multi_dot_cuda_complex64 (__main__.TestDecompCUDA),41,0,3,5,['Other']
87154,DISABLED test_acquire_release (__main__.LocalTimerServerTest),55,0,2,4,['Other']
87148,Conda ChecksumMismatchError error blocking CI jobs,0,0,12,1,['Bug']
87139,DISABLED test_comprehensive_lerp_cuda_float32 (__main__.TestDecompCUDA),62,0,2,5,['Other']
87138,DISABLED test_comprehensive_cholesky_solve_cuda_float64 (__main__.TestDecompCUDA),64,0,2,5,['Other']
87137,`torch.lstsq` gives wrong result on GPU,0,0,1,3,['Other']
87134,Jobs randomly fail with connection to the runner broken,1,1,4,2,['Other']
87121,torchdynamo erroring with this code pattern,0,0,0,0,['Other']
87111,DISABLED test_comprehensive_baddbmm_cuda_float64 (__main__.TestDecompCUDA),42,0,2,5,['Other']
87110,DISABLED test_comprehensive_addr_cuda_float32 (__main__.TestDecompCUDA),42,0,2,5,['Other']
87098,"Another fully reproducible ""CUDA error: an illegal memory access was encountered"" error",0,0,0,0,['Other']
87078,ib/python3.9/site-packages/torch/include/ATen/core/interned_strings.h:345:1: error: expected unqualified-id FORALL_NS_SYMBOLS(DEFINE_SYMBOL) ^,0,0,3,1,['Bug']
87075,torchaudio+cu117 is incompatible with torch+cu117,0,0,0,0,['Other']
87071,trace_model.py,0,0,0,0,['Other']
87070,DISABLED test_variant_consistency_jit_linalg_lu_cuda_complex64 (__main__.TestJitCUDA),56,0,2,5,['Other']
87069,`split()` method with `torch.ao.quantization.prepare()` or `torch.ao.quantization.prepare_qat()` brokes ONNX export,1,0,1,1,['Other']
87059,Enabling arbitrary monkey-patching of Tensor base class functions analogous to using __torch_function__ for subclasses?,0,0,1,0,['Other']
87055,model.cpu(),0,0,1,0,['Other']
87052,DISABLED test_reflection_pad2d (quantization.core.test_quantized_op.TestPadding),65,0,2,3,['Other']
87051,DISABLED test_forward_ad_linalg_lu_cuda_float32 (__main__.TestCompositeComplianceCUDA),56,0,2,5,['Other']
87036,record_param_comms function has significant impact on training performance,1,0,1,0,['Other']
87034,Add tensor.to()/tensor._to_copy() support to nested_tensor,5,0,3,2,['Other']
87029,"how to add adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True)'",0,0,1,0,['Other']
87027,"how to add adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True)'.",0,0,1,0,['Other']
87016,AttributeError: Can't get attribute 'ChatDataset' on <module '__mp_main__' from 'c:\\Users\\hp\\Desktop\\Pytorch\\train.py'> Traceback (most recent call last):,3,0,5,2,['Bug']
87015,Direct approach to free up GPU memory allocated to a tensor,1,0,2,0,['Other']
87014,"[MPS] Inconsistent output between cpu, cuda and mps.",0,0,2,1,['Other']
87010,"[MPS] einsum 42x slower since 1.13.0.dev20220925 — on (16, 4096, 40)*(16, 40, 4096) matmul",3,1,5,3,['Other']
87001,DISABLED test_vmapjvpall_linalg_lu_factor_cuda_float32 (__main__.TestOperatorsCUDA),58,0,5,4,['Other']
87000,DISABLED test_vmap_autograd_grad_linalg_lu_factor_cuda_float64 (__main__.TestOperatorsCUDA),58,0,4,4,['Other']
86999,DISABLED test_binary_op_scalar_fastpath__foreach_div_cuda_uint8 (__main__.TestForeachCUDA),62,0,4,4,['Other']
86998,DISABLED test_binary_op_scalarlist_fastpath__foreach_add_cuda_int8 (__main__.TestForeachCUDA),59,0,4,4,['Other']
86997,DISABLED test_binary_op_scalar_fastpath__foreach_sub_cuda_int8 (__main__.TestForeachCUDA),60,0,4,4,['Other']
86996,DISABLED test_binary_op_scalar_fastpath__foreach_mul_cuda_bfloat16 (__main__.TestForeachCUDA),59,0,4,4,['Other']
86982,DISABLED test_embedding_bag_device_cpu_int32_int64_float16 (__main__.TestEmbeddingNNDeviceTypeCPU),65,0,3,5,['Other']
86978,Add CUDA suppoort for sparse CSR tensors,3,0,2,2,['Other']
86975,Unpredictable behavior between tensors on separate devices (mps and cpu),9,1,2,2,['Other']
86974,Pytorch Windows installation failure,24,0,8,3,['Other']
86964,lerp_ is x5 slow on CPU than a trivial implementation,0,1,4,3,['Other']
86963,Derivaties with respect to CSR matrices in torch.sparse.mm,3,0,11,2,['Other']
86952,DISABLED test_out_linalg_lu_factor_ex_cuda_float32 (__main__.TestCommonCUDA),59,0,2,5,['Other']
86937,[MPS] torch.matmul produces transposed multiplication result,0,0,2,1,['Other']
86931,`narrow_copy` needs to be tested with sparse inputs,0,0,4,4,['Other']
86929,DISABLED test_vmapvjpvjp_linalg_lu_cuda_float32 (__main__.TestOperatorsCUDA),60,0,2,4,['Other']
86896,Unable to use torch.save() for saving model of format torch.script,0,0,5,2,['Other']
86894,DISABLED test_dtypes__refs_sinh_cuda (__main__.TestCommonCUDA),61,0,4,5,['Other']
86893,DISABLED test_vmapvjp_linalg_lu_cuda_float32 (__main__.TestOperatorsCUDA),60,0,2,4,['Other']
86892,DISABLED test_binary_op_scalar_fastpath__foreach_div_cuda_int64 (__main__.TestForeachCUDA),61,0,4,4,['Other']
86889,Support negation/subtraction of nested_tensor,18,0,1,2,['Other']
86886,DISABLED test_comprehensive_broadcast_tensors_cuda_complex64 (__main__.TestDecompCUDA),46,0,2,6,['Other']
86885,DISABLED test_vmapjvpvjp_linalg_lu_factor_ex_cuda_float32 (__main__.TestOperatorsCUDA),60,0,2,5,['Other']
86884,DISABLED test_comprehensive_linalg_matrix_norm_cuda_complex128 (__main__.TestDecompCUDA),46,0,2,6,['Other']
86883,DISABLED test_comprehensive_fft_ihfft2_cuda_float64 (__main__.TestDecompCUDA),46,0,2,6,['Other']
86882,DISABLED test_comprehensive_index_reduce_cuda_float32 (__main__.TestDecompCUDA),46,0,2,6,['Other']
86879,DISABLED test_out_linalg_lu_factor_cuda_float32 (__main__.TestCommonCUDA),60,0,3,4,['Other']
86878,DISABLED test_comprehensive_add_cuda_float64 (__main__.TestDecompCUDA),46,0,2,6,['Other']
86870,DISABLED test_quick_nn_functional_prelu_cuda_float64 (__main__.TestDecompCUDA),67,0,3,5,['Other']
86869,DISABLED test_comprehensive_addr_cuda_complex64 (__main__.TestDecompCUDA),64,0,7,5,['Other']
86868,DISABLED test_comprehensive_addmm_cuda_float32 (__main__.TestDecompCUDA),68,0,2,5,['Other']
86867,DISABLED test_comprehensive_addmv_cuda_float64 (__main__.TestDecompCUDA),70,0,2,5,['Other']
86866,DISABLED test_comprehensive_addcdiv_cuda_complex64 (__main__.TestDecompCUDA),67,0,2,5,['Other']
86865,DISABLED test_comprehensive_addbmm_cuda_float16 (__main__.TestDecompCUDA),70,0,2,5,['Other']
86863,DISABLED test_undefined_grad_parity_unused_parameters (__main__.TestDistBackendWithSpawn),1,0,2,3,['Other']
86862,DISABLED test_DistributedDataParallel_SyncBatchNorm_Diff_Input_Sizes_gradient (__main__.TestDistBackendWithSpawn),1,0,2,3,['Other']
86846,Python Meta Registration Adding Extra Kwarg,1,0,0,3,['Other']
86840,DISABLED test_self_remote_rref_as_rpc_arg_sparse (__main__.TensorPipeTensorPipeAgentRpcTest),5,0,2,3,['Other']
86839,DISABLED test_variant_consistency_jit_linalg_lu_factor_cuda_float32 (__main__.TestJitCUDA),60,0,2,4,['Other']
86832,[ONNX] Add support for onnx-script as custom op,35,1,0,3,['Other']
86817,DISABLED test_adagrad (__main__.TestOptim),0,0,1,5,['Other']
86801,support bfloat16 for torch.nn.functional.fold,0,0,1,2,['Other']
86793,UserWarning operator() profile_node %135 : int = prim::profile_ivalue(%121)  does not have profile information,58,0,6,1,['Other']
86790,RuntimeError caused by batchnorm,1,0,4,2,['Bug']
86789,ONNX export ShapeInferenceError with 0-sized tensors,13,1,4,3,['Bug']
86787,libtorch c++ tensor / weights on cuda:0 but type CPULongType,0,0,2,3,['Other']
86785,"That's a numerical issue. Doing an exact comparison `==` on floating point numbers will often fail, because 3.000000000001 is not equal 3.0. Change your comparison code to:",0,0,0,0,['Other']
86783,GPU memory leak after running simple model forward,53,0,4,4,['Other']
86781,"why torch.nn.SiLU gets the different result, compared with input * torch.sigmoid(input)",0,0,2,0,['Other']
86780,Put tensor on different devices does not reduce GPU memory use,0,0,0,0,['Other']
86778,DISABLED test_dlpack_conversion_with_streams_cuda_complex64 (__main__.TestTorchDlPackCUDA),71,0,4,4,['Other']
86777,DISABLED test_out_linalg_lu_cuda_float32 (__main__.TestCommonCUDA),61,0,2,4,['Other']
86776,DISABLED test_binary_ops (__main__.TestTensorExprFuser),72,0,2,3,['Other']
86773,DISABLED test_forward_nn_LSTM_eval_mode_cuda_float32 (__main__.TestModuleCUDA),62,0,3,5,['Other']
86772,DISABLED test_forward_nn_RNN_eval_mode_cuda_float64 (__main__.TestModuleCUDA),62,0,3,5,['Other']
86771,DISABLED test_memory_format_nn_RNN_eval_mode_cuda_float64 (__main__.TestModuleCUDA),71,0,4,4,['Other']
86770,DISABLED test_vmapjvpall_linalg_lu_cuda_float32 (__main__.TestOperatorsCUDA),61,0,2,4,['Other']
86765,DISABLED test_aot_autograd_symbolic_exhaustive_nn_functional_feature_alpha_dropout_with_train_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),70,0,2,3,['enhancement']
86764,DISABLED test_vjpvmap_linalg_lu_cuda_float32 (__main__.TestOperatorsCUDA),61,0,2,4,['Other']
86763,DISABLED test_asgd (__main__.TestOptim),71,0,3,5,['Other']
86762,DISABLED test_DistributedSampler_padding (__main__.TestDistBackendWithSpawn),0,0,2,3,['Other']
86761,DISABLED test_operator_linalg_lu_cuda_float32 (__main__.TestCompositeComplianceCUDA),61,0,2,4,['Other']
86744,[MPS] Add support for aten::expm1.out for MPS backend,14,1,5,3,['Other']
86743,"TestReductionsCUDA.test_reductions_large_half_tensors_cuda_complex32 fails with ""mean_cuda"" not implemented for 'ComplexHalf'",0,0,1,0,['Other']
86734,DISABLED test_vjpvjp_linalg_lu_cuda_float32 (__main__.TestOperatorsCUDA),61,0,3,4,['Other']
86733,DISABLED test_vmapjvpvjp_linalg_lu_cuda_float32 (__main__.TestOperatorsCUDA),61,0,2,4,['Other']
86732,DISABLED test_variant_consistency_jit_linalg_lu_factor_cuda_complex64 (__main__.TestJitCUDA),61,0,3,4,['Other']
86711,DISABLED test_variant_consistency_jit_linalg_lu_cuda_float32 (__main__.TestJitCUDA),62,0,3,4,['Other']
86698,[PrimTorch] Assertion error in partitioner,0,1,1,0,['Other']
86696,DISABLED test_dlpack_conversion_with_streams_cuda_uint8 (__main__.TestTorchDlPackCUDA),71,0,4,4,['Other']
86690,Circular padding has incorrent implementaion in ONNX module,14,1,0,3,['Other']
86688,MPS tests are failing while importing numpy,0,0,1,2,['Other']
86681,Accuracy mismatch for test_block_addmm for float16 and bfloat16,0,1,1,4,['Other']
86675,DISABLED test_transformer_offload_true_no_shard_norm_type_None (__main__.TestParityWithDDP),22,1,16,4,['Other']
86670,DISABLED test_gather_object (__main__.TestDistBackendWithSpawn),1,0,2,3,['Other']
86669,DISABLED test_periodic_model_averager_param_group (__main__.TestDistBackendWithSpawn),1,0,2,3,['Other']
86664,RuntimeError: could not construct a memory descriptor using a format tag,100,0,2,4,"['Critical', 'Bug']"
86663,nn.Embedding.from_pretrained accept tensor of type Long,2,0,2,3,['Other']
86654,DISABLED test_embedding_bag_half_cpu_int32_int32 (__main__.TestEmbeddingNNDeviceTypeCPU),66,0,2,4,['Other']
86639,DISABLED test_reduce_sum_cuda (__main__.TestDistBackendWithSpawn),2,0,2,3,['Other']
86638,DISABLED test_embedding_bag_device_cpu_int64_int64_float16 (__main__.TestEmbeddingNNDeviceTypeCPU),66,0,5,4,['Other']
86637,DISABLED test_pickle_nn_LSTM_train_mode_cuda_float64 (__main__.TestModuleCUDA),71,0,2,5,['Other']
86636,DISABLED test_pickle_nn_GRU_eval_mode_cuda_float64 (__main__.TestModuleCUDA),63,0,3,5,['Other']
86635,DISABLED test_memory_format_nn_RNN_train_mode_cuda_float64 (__main__.TestModuleCUDA),63,0,3,5,['Other']
86634,DISABLED test_memory_format_nn_LSTM_train_mode_cuda_float64 (__main__.TestModuleCUDA),63,0,3,5,['Other']
86633,DISABLED test_memory_format_nn_RNN_eval_mode_cuda_float32 (__main__.TestModuleCUDA),63,0,8,5,['Other']
86624,DISABLED test_vmap_autograd_grad_linalg_lu_factor_ex_cuda_float64 (__main__.TestOperatorsCUDA),63,0,2,5,['Other']
86620,[RFC] Move distributed checkpointing from torch.distributed._shard.checkpoint to torch.distributed.checkpoint,38,0,2,2,['Other']
86588,DISABLED test_ddp_build_debug_param_to_name_mapping_requires_grad (__main__.TestDistBackendWithSpawn),2,0,2,3,['Bug']
86587,DISABLED test_ddp_inference (__main__.TestDistBackendWithSpawn),2,0,2,3,['Other']
86584,DISABLED test_nested_always_wrap_model_offload_true_no_shard_norm_type_None (__main__.TestParityWithDDP),23,1,6,4,['Other']
86580,[ONNX] small eps of LayerNorm will be exported as 0.0 in fp16 mode,58,1,7,3,['Other']
86579,DISABLED test_cuda_simple (__main__.TestMultiprocessing),65,0,4,5,['Other']
86578,DISABLED test_comprehensive_addmv_cuda_complex128 (__main__.TestDecompCUDA),37,0,2,6,['Other']
86576,Confusing error message for RNN/LSTM (incorrect input dimension),11,0,2,3,['Bug']
86575,DISABLED test_comprehensive_amin_cuda_float32 (__main__.TestDecompCUDA),49,0,4,5,['Other']
86574,DISABLED test_comprehensive_addbmm_cuda_float64 (__main__.TestDecompCUDA),49,0,3,5,['Other']
86573,DISABLED test_comprehensive_amax_cuda_float64 (__main__.TestDecompCUDA),49,0,3,5,['Other']
86571,DISABLED test_comprehensive_baddbmm_cuda_complex64 (__main__.TestDecompCUDA),49,0,2,5,['Other']
86570,DISABLED test_comprehensive_addcdiv_cuda_float64 (__main__.TestDecompCUDA),49,0,3,5,['Other']
86556,"`optimize_for_inference` leads to wrong results for model with conv2d, max and clip",4,0,2,3,['Other']
86549,NotImplementedError: The operator 'aten::_linalg_slogdet.sign' is not currently implemented for the MPS device.,1,0,1,2,['Bug']
86542,Failed to compile gloo,8,0,2,3,['Other']
86536,pytorch_jni.dll and pytorch_jni.lib missing from LibTorch Windows zip archives after 1.10.2,110,1,2,3,['Other']
86535,SIGIOT when running model with conv2d and avgpool2d after `optimize_for_inference`,11,0,4,6,['Critical']
86533,JIT model with `pow + sin` will crash with assertion failed in `/llvm/lib/IR/Instructions`,46,2,8,1,['Critical']
86531,[NvFuser] INTERNAL ASSERT FAILED for `std` and `var`,25,1,1,2,['Other']
86530,"[NvFuser] INTERNAL ASSERT FAIL ""CudaFusionGuard expects at least one tensor input""",24,1,6,2,['Other']
86527,wrong results after `optimize_for_inference`,6,0,4,2,['Other']
86505,DISABLED test_forward_nn_LSTM_train_mode_cuda_float32 (__main__.TestModuleCUDA),66,0,3,5,['Other']
86503,DISABLED test_cpu_gpu_parity_nn_LSTM_train_mode_cuda_float32 (__main__.TestModuleCUDA),66,0,3,5,['Other']
86502,DISABLED test_pickle_nn_GRU_train_mode_cuda_float32 (__main__.TestModuleCUDA),66,0,3,5,['Other']
86500,DISABLED test_forward_nn_LSTM_eval_mode_cuda_float64 (__main__.TestModuleCUDA),66,0,3,5,['Other']
86501,DISABLED test_pickle_nn_GRU_eval_mode_cuda_float32 (__main__.TestModuleCUDA),66,0,3,5,['Other']
86499,DISABLED test_memory_format_nn_LSTM_eval_mode_cuda_float64 (__main__.TestModuleCUDA),66,0,4,4,['Other']
86498,DISABLED test_cnn_model_sum_cuda (__main__.TestExpandedWeightFunctionalCUDA),76,0,3,5,['Other']
86477,DISABLED test_periodic_model_averager (__main__.TestDistBackendWithSpawn),5,0,2,3,['Other']
86476,DISABLED test_ddp_multiple_nested_unused_params_error (__main__.TestDistBackendWithSpawn),5,0,2,3,['Bug']
86475,DISABLED test_ddp_build_debug_param_to_name_mapping (__main__.TestDistBackendWithSpawn),5,0,2,3,['Bug']
86473,DISABLED test_noncontiguous_samples_linalg_lu_cuda_complex64 (__main__.TestCommonCUDA),66,0,4,6,['Other']
86474,DISABLED test_adamax (__main__.TestOptim),72,0,4,4,['Other']
86472,DISABLED test_ddp_join_model_equivalence (__main__.TestDistBackendWithSpawn),5,0,2,3,['Other']
86466,Mac M1 queue build up,0,0,8,3,['Critical']
86457,`flatten_parameters()` does not work with normed LSTM,3,0,1,1,['Other']
86454,torch.optim.lr_scheduler.LinearLR start_factor should be greater than 0,6,0,1,5,['Other']
86448,Mac builds broken when USE_DISTRIBUTED=0,3,0,12,5,['Critical']
86447,Allow casting (instead of converting) tensors to/from channels_last to enable mixing Conv2d & Attention,0,0,1,0,['Other']
86442,DISABLED test_stateless_api_with_ddp (__main__.TestDistBackendWithSpawn),5,0,1,3,['Other']
86441,DISABLED test_variant_consistency_jit_linalg_lu_factor_ex_cuda_float32 (__main__.TestJitCUDA),66,0,2,5,['Other']
86440,DISABLED test_gather_cuda (__main__.TestDistBackendWithSpawn),5,0,2,3,['Other']
86439,DISABLED test_reduce_multigpu (__main__.TestDistBackendWithSpawn),7,0,3,3,['Other']
86436,DISABLED test_vmapvjp_linalg_lu_factor_cuda_float32 (__main__.TestOperatorsCUDA),66,0,2,5,['Other']
86435,DISABLED test_adamw (__main__.TestOptim),76,0,3,4,['Other']
86433,DISABLED test_rmsprop (__main__.TestOptim),75,0,3,4,['Other']
86432,DISABLED test_adam (__main__.TestOptim),0,0,2,4,['Other']
86420,DISABLED test_DistributedDataParallel_SyncBatchNorm_Channels_Last (__main__.TestDistBackendWithSpawn),5,0,1,3,['Other']
86419,DISABLED test_monitored_barrier_allreduce_hang (__main__.TestDistBackendWithSpawn),5,0,1,3,['Other']
86418,DISABLED test_ddp_logging_data_gpu (__main__.TestDistBackendWithSpawn),5,0,1,3,['Other']
86417,DISABLED test_serialization_backwards_compat (__main__.TestOldSerialization),7,0,2,4,['Other']
86416,DISABLED test_DistributedDataParallel_SyncBatchNorm_Diff_Input_Sizes_Running_Value (__main__.TestDistBackendWithSpawn),8,0,3,3,['Other']
86415,DISABLED test_ddp_forward_backward_hook (__main__.TestDistBackendWithSpawn),5,0,1,3,['Other']
86414,DISABLED test_noncontiguous_samples_nn_functional_conv_transpose2d_cuda_float32 (__main__.TestCommonCUDA),20,0,6,5,['Other']
86413,DISABLED test_no_cyclic_references_in_step (__main__.TestLRScheduler),0,0,3,4,['Other']
86412,DISABLED test_vjp_nn_functional_conv_transpose2d_cuda_float32 (__main__.TestOperatorsCUDA),66,0,3,5,['Other']
86411,DISABLED test_grad_linalg_lu_cuda_float32 (__main__.TestOperatorsCUDA),66,0,2,5,['Other']
86410,Print tensor allocated in MPS device fails with the C++ API,2,1,1,2,['Other']
86404,Use better default QEngine based on the environment,56,0,0,1,['Other']
86398,DISABLED test_ddp_hook_with_optimizer_parity_adam_optimize_subset_False (__main__.TestDistBackendWithSpawn),6,0,1,3,['Other']
86397,DISABLED test_ddp_broadcast_buffer (__main__.TestDistBackendWithSpawn),6,0,1,3,['Other']
86396,DISABLED test_ddp_new_tensor_in_fwd (__main__.TestDistBackendWithSpawn),6,0,3,3,['Other']
86395,DISABLED test_ddp_broadcast_buffer_via_hook (__main__.TestDistBackendWithSpawn),6,0,2,3,['Other']
86394,DISABLED test_ddp_hook_parity_post_localSGD (__main__.TestDistBackendWithSpawn),6,0,2,3,['Other']
86393,DISABLED test_ddp_hook_parity_allreduce_process_group (__main__.TestDistBackendWithSpawn),6,0,2,3,['Other']
86392,DISABLED test_DistributedDataParallel_SyncBatchNorm_No_Affine (__main__.TestDistBackendWithSpawn),6,0,2,3,['Other']
86391,DISABLED test_DistributedDataParallel_SyncBatchNorm_Single_Input_Per_Process (__main__.TestDistBackendWithSpawn),6,0,1,3,['Other']
86390,DISABLED test_ddp_hook_pickling_powerSGD (__main__.TestDistBackendWithSpawn),6,0,1,3,['Other']
86389,DISABLED test_radam (__main__.TestOptim),75,0,5,5,['Other']
86388,DISABLED test_sparse_add_cuda_complex128 (__main__.TestSparseCSRCUDA),75,0,3,4,['Other']
86387,DISABLED test_forward_nn_LSTM_train_mode_cuda_float64 (__main__.TestModuleCUDA),68,0,4,5,['Other']
86386,DISABLED test_dlpack_conversion_with_streams_cuda_bfloat16 (__main__.TestTorchDlPackCUDA),77,0,4,4,['Other']
86384,Functionalization doesn't work with torch.nn.functional.ctc_loss,3,0,2,3,['Other']
86376,M1 runner i-0ea74b8b580d2fd5a is low on disk space,0,0,7,1,['Other']
86373,[functorch] AOT module does not run custom backwards pass compiler,36,0,6,2,['Other']
86370,"Make validation jobs easier to read by including platform-channel-python-cuda configuration in the name of validation, just like nightlies",88,0,1,2,['Other']
86363,Discrepancy in batched psuedo inverse,101,0,2,2,['Other']
86362,torch.autograd.detect_anomaly stops tracing back further into the code,0,0,2,2,['Other']
86332,col2im decomposition breaks,1,0,6,2,['Other']
86328,[Checkpoint] CheckpointSequential to support non-reentrant checkpoint,1,1,1,5,['Critical']
86325,[ONNX] onnx.export fails on frozen top-level ScriptedModule,8,1,4,2,['Other']
86322,[ONNX][Ignore] test issue for automating workflow,0,1,1,3,['Other']
86320,as_strided returns different outputs with identical inputs,39,0,1,2,['Other']
86319,TypeError: Operation 'neg_out_mps()' does not support input type 'int64' in MPS backend.,6,1,6,2,['Bug']
86312,[v.1.13.0] Release Tracker,27,0,60,2,['Other']
86305,`torch.linalg.inv` outputs wrong results for singular matrix on CUDA,101,0,4,3,['Other']
86294,Replace signature in autocast registrations ,1,0,2,3,['Other']
86284,primtorch view op meta kernels don't respect aliasing info,7,0,1,2,['Other']
86283,JIT model with `mul+atan+sgn` will access illegal memory on cuda when computing gradient,5,2,0,2,['Other']
86281,Error when applying CUDA Graph to a Recommendation System called DLRM,1,0,7,2,['Bug']
86277,CI/MergeBot actions are delayed due to GitHub Incident,0,0,1,1,['Other']
86267,The derivative for 'ormqr' is not implemented,12,1,8,4,['enhancement']
86264,"to(""cpu"", non_blocking=True) work weird",1,0,2,0,['Other']
86252,The JIT model with `pow` + `sin` will crash with fail in `/llvm/lib/IR/Instructions`,5,0,0,1,['Critical']
86251,[NvFuser] The JIT model with `mean` will crash when computing the gradients on nvfuser,5,0,4,1,['Critical']
86249,The `jit.trace` `conv2d` will crash ,5,0,0,1,['Critical']
86239,`torch.where` on MPS fails to broadcast identically to other backends / numpy,2,1,4,2,['Other']
86234,SVD with `full_matrices=False` slower than `full_matrices=True` & `full_matrices=False` on GPU 500x slower than CPU,34,0,10,3,['Other']
86227,`numel` + `div` + `mul` will trigger INTERNAL ASSERT FAILED in JIT on cuda,0,0,2,1,['Other']
86224,"`dtype` arg in `cumsum` is passed around in the implementation, but it's not used.",2,0,7,5,['Other']
86222,`resize_as_` will return incorrect values in JIT after the first run in some cases,5,0,1,1,['Other']
86209,SparseAdam consume iterator in arg checking,2,0,0,0,['Other']
86208,[doc] LR scheduler example is terrible,9,0,4,5,['Other']
86205,How to save only parts of the state_dict(),8,0,6,2,['Other']
86197,TorchDynamo + AoTAutograd Graph behavior with Softmax causing slowdown,1,1,6,1,['Other']
86195,[MPS] PYTORCH_ENABLE_MPS_FALLBACK=1 has no effect?,0,0,2,1,['Other']
86193,test,0,0,0,0,['Other']
86179,DISABLED test_nvfuser_extremal_values_native_batch_norm_cuda_bfloat16 (__main__.TestCudaFuserOpInfoCUDA) ,9,0,1,1,['Other']
86178,DISABLED test_nvfuser_extremal_values_native_batch_norm_cuda_float16 (__main__.TestCudaFuserOpInfoCUDA) ,9,0,1,1,['Other']
86177,DISABLED test_nvfuser_extremal_values_native_batch_norm_cuda_float32 (__main__.TestCudaFuserOpInfoCUDA) ,9,0,1,1,['Other']
86176,DISABLED test_nvfuser_extremal_values_native_batch_norm_cuda_float64 (__main__.TestCudaFuserOpInfoCUDA),9,0,1,1,['Other']
86175,DISABLED test_forward_mode_AD_native_batch_norm_cuda_float64 (__main__.TestGradientsCUDA),7,0,1,1,['Other']
86164,JIT will return different values for `sinh` + `cos`,6,0,1,1,['Other']
86159,[PrimTorch] Invalid partition found when running TIMM hrnet_w18,7,1,6,2,['Other']
86153,Unexpected behavior when using MPS (M1),0,0,2,2,['Other']
86136,torch.clear_autocast_cache() doesn't actually clear every cache,51,0,6,3,['Critical']
86118,JIT model with `relu+div+sgn` will crash when computing the gradient ,7,0,0,1,['Critical']
86113,`max_unpool` will trigger INTERNAL ASSERT FAIL in JIT,7,0,0,1,['Other']
86109,`AttributeError: module 'torch.quantization' has no attribute 'get_default_config'`,0,0,4,1,['Bug']
86108,CapabilityBasedPartitioner doesn't merge subgraphs for several outputs,8,1,5,3,['Other']
86106,"Error in tutorial ""EXTENDING PYTORCH"" ",0,0,1,0,['Other']
86093,SIGSEGV when running XLA test due to time bomb issue on XLA apply_patches script,0,0,4,2,['Other']
86063,PyTorch don't have an op for aten::constant_pad_nd but it isn't a special case.,0,0,3,2,['Other']
86060,[MPS] Pin_memory on MPS backend raises exception of setting wrong device storage,4,1,1,2,['Other']
86059,DISABLED test_fake_crossref_backward_amp_linalg_lstsq_cuda_float32 (__main__.TestFakeTensorCUDA),60,0,9,4,['Other']
86052,[MPS] tensors loaded via torch.load() -- when transferred to GPU -- do not honour indices/views,13,0,6,2,['Other']
86051,Understanding register_full_backward_hook method,12,0,5,2,['Other']
85978,test_reference_numerics_large fails on PPC,53,0,0,2,['Other']
85973,Exception on aten.index_put_(accumulate=True) with mixed types of indices,1,0,1,1,['Other']
85967,MPS Tensor from sliced numpy array indexing error,2,1,2,1,['Bug']
85962,'result_of': is not a member of 'std' C++20 build,0,1,1,0,['Other']
85956,Pytorch fails to compile on Intel Mac,2,0,5,3,['Other']
85954,Extend math functions to ArrayRef,0,0,2,0,['Other']
85952,functorch import messed up python logging module,17,0,11,4,['Critical']
85950,`eigvals` will crash with `inf`,38,0,19,4,['Critical']
85935,[ONNX] Support torch.bucketize,6,1,7,2,['Other']
85929,NotImplementedError: The operator 'aten::l1_loss_backward.grad_input' is not current implemented for the MPS device. ,0,0,1,2,['Bug']
85923,Multiple `conftest.py` seemed to be loaded when `python run_test.py --include test_ops`,54,0,4,2,['Other']
85917,NVidia CUDA support is outdated,0,0,2,0,['Other']
85912,load model fails on windows with non-debug version of libtorch-1.12.1 ,108,1,5,3,['Bug']
85905,PyTorch Profiler table output empty on TorchBench runs,46,0,1,1,['Other']
85872,"NvFuser INTERNAL ASSERT FAIL ""CudaFusionGuard expects at least one tensor input""",33,1,12,2,['Other']
85869,DISABLED test_fake_crossref_backward_amp_linalg_lstsq_grad_oriented_cuda_float32 (__main__.TestFakeTensorCUDA),74,0,2,4,['Other']
85862,[Quant] Default qnnpack per_channel observers/fake_quant cannot be instantiated,4,1,4,1,['Other']
85853,`torch.histc` handles NaN inconsistently on cpu and cuda,7,0,1,5,['Critical']
85837,Parameter Registration Hook,14,0,1,4,['enhancement']
85826,Tensor subclasses as parameters: wrapped tensor does not move to cuda,19,0,7,2,['Other']
85821,`norm` fails to compute grad in forward mode unexpectedly,108,0,2,3,['Other']
85812,Can't run test_ops test suite,5,0,2,3,['Other']
85803,`squeeze_` fails with JIT,12,0,0,1,['Other']
85796,RuntimeError: CUDA error: device not ready,0,0,2,0,['Other']
85786,The CUDA kernel of torch.nn.CrossEntropyLoss fails when the input tensor is too large,0,0,3,0,['Other']
85778,CI flakiness when using shared Linux runners across PyTorch org,103,0,6,2,['Other']
85777,torch.bincount crash with segmentation fault,1,0,0,0,['Other']
85755,DISABLED test_vjpvjp_matrix_exp_cuda_float32 (__main__.TestOperatorsCUDA),76,0,4,4,['Other']
85731,`torch.poisson()` does not report negative input on CUDA as it does on CPU,2,0,0,1,['Bug']
85728,`torch.nn.BCELoss` triggers CUDA error: device-side assert triggered when inputs are negative,2,0,2,0,['Other']
85712,max_pool1d error messages diverge between CPU and CUDA,78,0,6,4,['Bug']
85704,"INTERNAL ASSERT FAILED at alias_analysis.cpp:614 when tracing a model that uses bitwise_or(tensor, bool)",6,0,7,1,['Other']
85700,It currently rounds toward 0 (like the 'trunc' function NOT 'floor').,10,0,3,2,['Other']
85697,create swin-block in torchvision,6,0,2,3,['enhancement']
85696,TorchFunctionMode inside backward call is ignored when outer mode is present,0,1,2,2,['Other']
85695,How to load checkpoint from .pt file,2,0,3,0,['Other']
85694,[arm] conv2d output does not match the output on linux (x86-64),6,1,8,5,['Critical']
85687,[ONNX] Parameterize test_utility_functions,18,0,1,3,['Other']
85675,mps backend does not ensure contiguity before concatenation,0,1,1,3,['Other']
85650,operator 'aminmax' behaves incorrectly on CPU for 0d tensors when keepdims=True,0,0,1,0,['Other']
85649,Add new wheel test cudnn pypi,24,0,2,2,['Other']
85647,Fix torchaudio smoke test before release ,3,0,1,2,['Other']
85631,Batch collation is slow/hangs when done outside DataLoader,1,0,1,0,['Other']
85627,Will the observer(for activation) be synchronized across GPUs in DDP?,31,0,4,2,['Other']
85626,TORCH_WARN does not throw a warning on the backward.,9,1,6,2,['Other']
85615,PyTorch Testing ArgumentParser Instance Args Can Unnecessarily Conflict with System Args,0,0,0,2,['Other']
85611,[MPS] `torch.bernoulli` always returns zeros on MacOS Ventura,5,1,0,5,['Critical']
85608,[ONNX] Update documentation,5,0,0,2,['Documentation']
85603,'result_type': is not a member of 'std::hash<T>',2,0,1,3,['Other']
85600,[ONNX] 1.13 Release,25,0,3,2,['Other']
85592,"mps-device bug (with repro!), with floating point values",10,1,5,3,['Bug']
85587,INTERNAL ASSERT FAILED with nvfuser single node mode for `std` and `var`,16,0,0,2,['Other']
85578,Allow External Scripts To Discover and Execute unittest Tests (e.g. vscode),1,0,0,0,['Other']
85575,Introduce RECORD_OUTPUTS() macro to be used with existing RECORD_FUNCTION() for the purpose of passing an operators output tensors to the profiler ,30,0,1,2,['Other']
85535,[functorch] nn.LeakyRelu with inplace=True fails with InternalAssert with `jvp`,4,1,2,5,['Critical']
85525,torch.fake_quantize_per_channel_affine : implementation and documentation mismatch ,4,1,2,1,['Documentation']
85517,"masked_fill.tensor decomposition bakes cpu scalar into traced FX graph, triggering data-dependent control flow error",6,0,4,3,['Bug']
85516,"[MPS] rearrange() returns a tensor mostly filled with NaN, until you look at it twice - regression in nightly",6,0,3,2,['Other']
85506,`import torch` fails on Python-3.11 runtime,111,0,3,3,['Other']
85504,[PrimTorch] `expected scalar type Float but found Half` error with AMP,0,0,0,0,['Other']
85503,`topk` will return incorrect value out-of-bound after jit on cuda,17,0,0,1,['Other']
85465,ModuleNotFoundError: No module named 'torch.onnx.symbolic_registry',2,1,9,3,['Bug']
85464,[onnx]Unsupported: ONNX export of convolution for kernel of unknown shape,29,1,15,3,['Other']
85452,torch._refs.permute doesn't support torch.Tensor.permute python binding on variadic arguments,6,1,3,2,['Other']
85445,ONNX tests occasionally failing with `NameError: name '_C' is not defined`,11,0,5,3,['Bug']
85440,Mac M1 runners run out of space due to /System/Library/Caches/com.apple.coresymbolicationd,11,1,8,3,['Critical']
85436,C++ Memory Management API,0,0,3,1,['Other']
85427,torchrun AttributeError caused by `file_based_local_timer` on Windows,49,0,8,5,"['Critical', 'Bug']"
85415,[ONNX] RuntimeError: Dynamic shape axis should be no more than the shape dimension for mask_dynamic_axes_1,33,0,2,3,['Bug']
85410,_LRScheduler memory leak,15,0,3,6,['Critical']
85409,Result of backward is wrong with conj_view and neg_view for Tensor.sum_to_size,15,0,3,7,['Critical']
85406,mps on apple m1 seems incorrect in matrix multiplication,4,1,16,4,['Other']
85405,DecompCrossRefMode not dispatching correctly,1,0,6,3,['Other']
85404,LibTorch's torch::cat() crashes in debug mode,5,1,6,3,"['Bug', 'Critical']"
85393,Crash in `torch.nn.ModuleList`,2,0,1,3,['Critical']
85388,[ONNX] Exporting the operator ::max_unpool2d to ONNX,33,1,5,4,['Other']
85385,[FSDP] Fix communication hook docs,72,1,1,4,['Other']
85376,"[NestedTensor] Implement the following operations: nested_tensor, as_nested_tensor",41,0,1,3,['Other']
85371,[ONNX: feature request]: support for linalg_pinv/ svd,33,0,1,2,['enhancement']
85363,[ONNX] Comprehensive and automated testing,86,1,2,4,['Other']
85362,docker pulls failing with no space left on disk,0,0,10,1,['Other']
85348,gha mac runners failing at checkout,0,0,1,1,['Other']
85341,DISABLED test_vmap_exhaustive_linalg_ldl_solve_cuda_float32 (__main__.TestVmapOperatorsOpInfoCUDA),93,0,2,2,['Other']
85340,Simultaneously using `torch.no_grad` and `autocast` causes `RuntimeError: expected scalar type Half but found Float` for some operations.,5,0,3,2,['Bug']
85334,ddp got stuck(deadlock),6,0,4,3,['Other']
85332,torch.cuda.is_available()=false,0,0,1,0,['Other']
85328,Crash in `torch.nn.utils.parametrize.ParametrizationList`,2,0,1,3,['Critical']
85327,Crash in `torch.optim.Optimizer`,2,0,1,3,['Critical']
85317,how can make gradcheck support for List[Tensor] ?,0,0,0,0,['Other']
85316,[ONNX] `f64 * LeakyReLU(f64)` mistakingly returns f32 ,6,1,2,3,['Other']
85297,"MPS backend is 5~6% slower on nightly builds — makes 78% more calls to aten::copy_, spends 72% more time there",42,1,7,4,['Other']
85295,Visualize nightly periodic tests on HUD,49,0,2,2,['Other']
85273,[ONNX] Re-export onnx name space members,0,1,1,3,['Other']
85266,Mismatch between torch.stft and torch.rfft,1,0,1,1,['Other']
85259,TestAutograd.test_thread_shutdown may fail sometimes,18,0,8,2,['Other']
85257,Limited Symmetric Rank 1 Update,0,0,0,0,['Other']
85253,[feat][torch.fx] use concrete trace to pass complex branches,62,0,3,2,['Other']
85252,[CV] Optimize the Large Kernel DepthWise convolutions (LKDWconvs) with `nn.Conv2d` to be faster than the counterpart of `megengine`,2,0,2,4,['Other']
85251,Crash with Segmentation fault in `torch.le`,0,0,2,3,"['Bug', 'Critical']"
85250,Crash with Segmentation fault in `torch.ldexp`,0,0,1,0,['Other']
85249,Crash with Segmentation fault in `torch.lcm`,0,0,1,0,['Other']
85237,Segmentation fault in `torch.futures.wait_all`,1,1,2,4,['Critical']
85226,Implement derivative for `to_sparse_csr` ,86,0,1,4,['Other']
85224,[MPS] einsum returns incorrect matmul result on first invocation on nightly builds,27,1,36,4,['Other']
85220,Macbook M1 MPS acceleration bug report,13,1,2,2,['Bug']
85218,Segmentation fault in ormqr,2,0,1,5,"['Critical', 'Bug']"
85216,Segmentation fault in _mkldnn_transpose,47,0,0,5,"['Critical', 'Bug']"
85213,Segmentation fault in embedding_bag,101,1,3,5,"['Critical', 'Bug']"
85212,Segmentation fault in choose_qparams_optimized,9,0,0,6,"['Critical', 'Bug']"
85208,Activation functions for sparse tensors.,27,0,7,3,['enhancement']
85182,Readme typos,13,0,1,2,['Other']
85169,torch.sparse.sampled_addmm does not behave the same on CPU and GPU,7,0,1,2,['Other']
85167,torch.ger crash with segmentation fault ,3,1,1,3,['Critical']
85166,torch.pow crash with segmentation fault,3,1,1,4,"['Critical', 'Bug']"
85159,Add the OpenSSF Scorecards GitHub Action,14,1,6,3,['Other']
85155,torch.nn.PixelShuffle crash with floating point exception when input has 0 size in the last three dimensions,18,0,7,6,"['Critical', 'Bug']"
85143,"failed assertion `Error: Invalid KernelDAG, equalShape for destination failed' MPS for F.pad",14,1,0,2,['Bug']
85137,Is there has some best nlp framework  process text  data  suitable  with  cpp libtorch ?,0,0,1,0,['Other']
85123,randn has undocumented pin_memory parameter,6,1,1,2,['Other']
85111,torch.nn.functional.conv1d/2d/3d crash with floating point exception,3,0,9,5,"['Critical', 'Bug']"
85109,Initial version of diagnostics infrastructure.,0,0,0,0,['Other']
85106,[MPS] division-by-zero returns 0.0 instead of Inf,28,0,3,2,['Other']
85094,The tensor constructed by torch.tensor(t) and t.clone().detach() have different behavior,1,0,1,3,['Other']
85092,DISABLED test_scatter_full_optim_state_dict_nested_use_multiple_param_groups_True_wrap_alt_False_use_diff_optim_inputs_True (__main__.TestFSDPOptimState),45,0,2,4,['Other']
85089,Investigate binary windows failures,7,1,1,3,['Critical']
85085,Investigate binary validation failure nightly linux 3.9 cuda 11.6,21,2,11,3,['Critical']
85074,A tiny typo in the README file,16,0,0,2,['Other']
85066,[Checkpoint Wrapper] ReEntrant activation checkpointing generates errant warning about no tensor gradients during validation loop,3,0,1,2,['Other']
85064,Nested matmul is broken when the nested tensors are >2D,11,0,2,2,['Other']
85059,torch.atan2 crash with segmentation fault in the nightly version,5,0,1,2,"['Bug', 'Critical']"
85057,torch.nn.functional.normalize crash with segfault,12,0,1,2,"['Bug', 'Critical']"
85053,torch.div crash with segmentation fault,5,0,1,3,"['Bug', 'Critical']"
85046,torch.bitwise_or crash with segfault,5,0,1,3,"['Bug', 'Critical']"
85035,torch.max crash with segmentation fault,13,0,1,2,"['Bug', 'Critical']"
85034,torch.floor_divide crash with segmentation fault in nightly version,13,0,1,2,"['Bug', 'Critical']"
85026,torch.lu_unpack crash with segmentation fault in the nightly version,16,0,2,3,['Critical']
85022,cannot import name 'VGG16_BN_Weights',1,0,1,0,['Other']
85021,[Missing documentation] cuSOLVER path for `linalg.lstsq` for underdetermined linear systems (on GPU),72,0,7,5,['Documentation']
85019,torch.add crash with segmentation fault in nightly version,13,0,1,2,"['Bug', 'Critical']"
85015,[ONNX] Remove spammy warnings,66,1,4,3,['Other']
85007,MacOS nightly wheel build is broken,1,1,3,5,['Critical']
85006,Python 3.11 Wheels are broken by functorch commit,8,1,4,3,['Other']
85001,Batched `torch.linalg.matrix_exp` raises `UserWarning: An output with one or more elements was resized`,0,0,2,0,['Other']
84999,Transposing a sparse CSR tensor changes the CUDA index of the tensor,5,1,2,2,['Other']
84998,torch.zeros with CSC layout throws INTERNAL ASSERT exception,1,1,2,2,['Bug']
84997,torch.zeros with a CSR layout produces tensor with invalid crow_indices,1,1,2,2,['Bug']
84995,[MPS] torch.div invoked with integral types crashes with internal assert,0,1,4,2,['Critical']
84991,What are PyTorch's plans for Onnx support in the future,40,0,2,3,['Other']
84989,"RuntimeError: ""upsample_linear1d_out_frame"" not implemented for 'BFloat16'",3,0,2,3,['Bug']
84988,Document how to use parameters in C++ modular API (was How to use torch.nn.Parameter in libtorch cpp?),1,0,5,0,['Other']
84987,error_on_missing_kernels doesn't actually do anything if autograd key is set (and symint behavior is wrong),2,0,0,4,"['Critical', 'Bug']"
84986,torch.new_zeros doc missing layout or pin_memory fields,11,0,1,2,['Other']
84979,torch.nn.functional.pad generates incomplete ONNX without explicit padding value,37,1,7,2,['Other']
84962,MPS nn.BatchNorm2d gives different result from CPU,4,1,7,2,['Other']
84954,Memory Consumption In Containers,0,0,1,0,['Other']
84933,Setup smoke tests for python 3.11 wheels,36,1,1,2,['Other']
84930,`addmm` meta kernel type definition incorrect in edge case,6,0,4,2,['Other']
84923,[FX] How to replace torch.functional with nn.module? TypeError: forward() takes 2 positional arguments but 3 were given,0,0,2,1,['Bug']
84898,DISABLED test_serialization_offset (__main__.TestOldSerialization),3,0,4,3,['Other']
84888,Speed up build of the generated VariableType,16,0,0,1,['Other']
84884,[ONNX] Add OperatorExportTypes for the usages that valid ONNX is not necessary.,38,1,6,3,['Other']
84882,Unable to install functorch,0,0,3,0,['Other']
84874,Using `expectedFailureMeta` decorator prevents tests from running,1,1,0,3,['Critical']
84873,torch.jit.freeze assumes forward method exists,16,1,1,1,['Other']
84865,torch.distributed.reduce_scatter documentation lacks op parameter description,3,0,1,4,['Documentation']
84841,M1 runner i-00893d044c5434268 run out of disk space,4,1,21,2,['Other']
84836,[ONNX] RuntimeError: torchvision.models.detection.maskrcnn_resnet50_fpn,65,0,2,3,['Bug']
84827,Different value of `ctc_loss` w/ and w/o tracing,29,0,0,3,['Other']
84807,Replace nondeterministic alert test decorator `expectedAlertNondeterministic` with simpler function,5,1,0,4,['Other']
84803,Silent data corruption when moving data between GPUs,44,0,15,4,['Other']
84783,[doc] torch.narrow support for `start` arg as Tensor is undocumented,6,0,1,2,['Other']
84764,"Setup periodic test to run in following wayExecute nightly channel tests 1 time a day after the nightly build is completed.Execute release channel test 2 times a day at morning, afternoonExecute test channel after rc has been cut",12,0,0,2,['Other']
84763,Surface results on HUD  from builder repo,10,1,1,2,['Other']
84756,segfault in pytorch while exiting python interpreter,0,0,1,0,['Other']
84748,test_quantization fails when build without FBGEMM,74,0,1,2,['Other']
84746,torch::from_blob() cause coredump,9,0,3,2,['Critical']
84745,test_model_dump fails,3,0,1,1,['Other']
84743,UNET implementation,0,0,1,2,['enhancement']
84740,make_data_loader error in libtorch on windows,10,0,3,3,['Bug']
84736,[Mac M1 MPS] Incorrect matrix multiplication results for n-by-n matrices,1,0,2,1,['Other']
84734,make_fx fails under TorchRefsMode context,0,0,8,3,['Other']
84712,Fix deprecation warning in `torch.utils.tensorboard` import,109,0,2,2,['Other']
84706,Lite interpreter fails in runtime: XNNPACK Linear not available,0,0,1,0,['Other']
84694,[ONNX] Exporting the operator quantized::conv1d_relu to ONNX opset version 13 is not supported,47,2,0,3,['Other']
84693,Issue with the `aten::_reshape_alias` op,4,0,1,0,['Other']
84690,Query for ways to select gpu to run on slurm,5,0,1,0,['Other']
84684,[torchaudio]`torchaudio.compliance.kaldi.mfcc` seems to produce strange energy values.,0,0,2,0,['Other']
84683,Request deterministic support for `scatter_add_cuda_kernel` operation,1,0,5,2,['Other']
84650,lazy backend_interface.h missing include tensor.h,0,1,4,1,['Other']
84644,`actions/download-artifact` frequently fails with EACCES error,0,1,1,3,"['Critical', 'Bug']"
84643,[ONNX] Update constants,1,0,0,3,['Other']
84623,incompatible withi torchvision,1,0,1,0,['Other']
84622,[feature request] A rank-revealing factorization of a matrix that is stable in backward.,0,0,7,2,['enhancement']
84618,[primTorch] view size is not compatible with input tensor's size and stride,2,0,4,2,['Other']
84614,torch.cuda.make_graphed_callables causes incorrect results in dropout,7,0,6,2,['Other']
84611,libtorch trunk job accidentaly fail during `Hold runner for 2 hours` step,0,0,2,2,['Other']
84591,"""error: invalid axis (0,-1) for shape of rank 1"" calling `torch.nn.functional.linear` on Mac MPS",21,1,0,2,['Bug']
84582,1x1 Convolution and Index Cropping are not swappable.,0,0,1,1,['Other']
84577,out= not correct in narrow_copy and avg_pool3d operators when out tensor is not contiguous,54,0,4,2,['Other']
84574,Sparse / dense tensors .mul operation inconsistency,1,1,5,2,['Other']
84571,dist.scatter_object_list() NCCL support,1,0,2,2,['Other']
84566,Update dist.scatter() documentation to provide clearer arg description,27,0,2,4,['Documentation']
84563,Export LayerNorm to ONNX lead to wrong output shape info.,0,0,2,3,['Other']
84562,"I use pytorch1.8.0 getting error like THPVariable_Check INTERNAL ASSRT FAILED ""/pytorch/torch/csrc/jit/passed/onnx/shape_type_inference.cpp"":657",39,0,1,3,['Bug']
84561,Unnecessary uses of `copy_to` in refs implementations,55,0,5,2,['Other']
84556,[Nested Tensor] Indexing does not work in a nestedtensor with requires_grad=True,1,1,2,3,['Other']
84553,[ONNX] Change how context is given to symbolic functions,23,1,1,3,['Other']
84540,CUDA Out of memory with more than 80% of the cards vram being free with a small allocation.,1,0,15,5,['Other']
84535,MPS: invalid padding argument of size 8,25,1,0,2,['Other']
84531,DISABLED test_load_with_different_shard_plan (__main__.TestDistributedReshardOnLoad),100,0,4,4,['Other']
84525,`torch.distributed.all_gather` on wrong type of tensor list should raise a `TypeError`,11,0,0,3,['Bug']
84522,DataParallel: some parameters are not parallelized,1,0,1,0,['Other']
84521,latest libtorch debug error 1.12.1 ,65,1,7,3,['Bug']
84516,Dropout is non deterministic on MPS,123,1,3,2,['Other']
84514,"[ONNX] when exporting a PyTorch model, creates an unnecessary variable that messes up inferencing.",19,0,4,3,['Other']
84512,Error in the docs (docstring) of torch.nn.MultiMarginLoss,4,0,0,3,['Bug']
84511,Crash in backward propagation,16,1,6,6,['Critical']
84507,Typo in torch/package/_mock.py,2,0,1,1,['Other']
84501,Custom C++ Torchscript with Composite PyTorch Functions,2,0,4,1,['Other']
84494,[make_fx] Expected behavior? Resulting FX graph not scriptable.,4,0,2,1,['Other']
84492,The distributed setting call in data loader constructor is invalid,21,0,10,2,['Other']
84488,Conv3d computes incorrect result for large input size,107,1,3,6,['Critical']
84485,OneCycleLR is incompatible with optimizer having more than 2 betas,4,0,0,3,['Other']
84471,`coalesce` is likely broken for large inputs,0,0,4,2,['Other']
84458,[Quant] Unit test 'TestQuantizedConv.test_qconv_transpose1d' fails randomly,72,0,2,1,['Other']
84570,functionalize: AttributeError: 'fn' object has no attribute '__code__'.,5,0,5,3,['Bug']
84441,DISABLED test_profiler_experimental_tree_with_stack_and_torch_dispatch (__main__.TestProfilerTree),110,0,2,3,['Other']
84440,DISABLED test_load_rowwise_to_colwise (__main__.TestDistributedReshardOnLoad),103,0,4,4,['Other']
84421,Reuse builder check_binary for all environments,35,1,0,3,['Other']
84420,DISABLED test_ddp_uneven_input_exception (__main__.TestDistBackendWithSpawn),59,0,3,3,['Other']
84417,Wrong output in constraints check for positive definite matrix,3,0,3,3,['Other']
84413,reentrant checkpoint cause cyclic reference if run_fn capture object that reference output,7,0,7,2,['Other']
84407,Speed of torch.istft in GPU settings,5,1,6,3,['Other']
84406,[ONNX] Exporting the operator zero to ONNX opset version 9-15 is not supported.,53,0,3,4,['Other']
84396,Runtime Error raised by `torch._native_multi_head_attention` working with `torch.cuda.amp.autocast`,12,1,3,4,['Bug']
84374,nn.functional.interpolate with dynamic size cannot export correctly,0,0,0,0,['Other']
84365,"RuntimeError: r INTERNAL ASSERT FAILED at ""../aten/src/ATen/core/jit_type_base.h"":545",63,3,10,5,['Bug']
84364,[MPS] Indexing into new axis of tensor causes its every element to become ±Inf,30,1,1,2,['Other']
84357,[Profiler] Optimize Scalar collection,20,1,2,2,['Other']
84356,LayerNorm does not normalize to unitary variance.,1,0,2,2,['Other']
84351,_dl.*.so is an x86_64 binary in an arm64 pytorch installation,0,1,2,4,['Critical']
84339,"ImportError: symbol not found in flat namespace, when loading custom C++ extension on MAC OSX M1",1,0,1,0,['Other']
84334,"About the results of ""torch.matmul"" on RTX 3080",0,0,7,1,['Other']
84328,nn.Linear should warn the mismatched dimension on CUDA,0,0,1,0,['Other']
84326,[MPS][Metal Driver Overhead] Fix the driver overhead bottlenecks,31,0,4,3,['Other']
84291,`any/all` reductions are synchronizing ,3,0,1,4,['Other']
84288,MPS: torch.manual_seed not working on metal (mps)  for  torch.randn,125,1,6,3,['Other']
84269,dataloader,1,0,3,0,['Other']
84268,'Tensor' object has no attribute or method 'forward',0,0,3,0,['Other']
84267,Improve speed/overhead of CUDA array interface,20,0,0,4,['Other']
84264,Support more overloads of Tensor.to in torch._refs.to,21,1,2,3,['enhancement']
84262,Simple Typos Spotted,0,0,0,0,['Other']
84244,Fused addmm path in linear causing performance regression in XLA backend,3,1,1,4,['Bug']
84229,Tensor indexing fail on MPS backend. ,33,1,3,2,['Other']
84225,Add running mean/var support to LayerNorm,1,0,1,2,['Other']
84223,[ONNX] Export with export_modules_as_functions fails for ConvXd modules,3,0,3,3,['Other']
84213,DISABLED test_comprehensive_cartesian_prod_cpu_float16 (__main__.TestDecompCPU),108,0,28,4,['Other']
84206,source and weight input channels mismatch when using Conv2D on mps,29,0,8,3,['Other']
84196,M1 runner i-00d2de3afb92ed15f fails during `Setup Miniconda step`,39,0,4,2,['Other']
84191,DISABLED test_comprehensive_column_stack_cpu_bfloat16 (__main__.TestDecompCPU),115,1,18,4,['Other']
84176,`Tensor.stride()` has wrong type hints,57,0,0,2,['Other']
84172,Insufficient CI for metal backend,35,0,3,4,['Critical']
84171,Conv2d layer produces NaNs in Pytorch 1.12.1,2,0,5,4,['Other']
84170,[ONNX] Fix type checks that are commented out,3,1,0,2,['Other']
84168," ValueError: Expected value argument (Tensor of shape ()) to be within the support (Real()) of the distribution Normal(loc: tensor([0.]), scale: tensor([1.])), but found invalid values:",2,0,1,0,['Other']
84162,torch is not compiled with CUDA support,3,0,10,4,['Other']
84161,NNAPI failed in converting a constant defined in the model,3,0,2,2,['Other']
84156,[distributed] incorrect import for is_namedtuple generates console filling warnings,0,0,0,1,['Other']
84150,DISABLED test_comprehensive_cartesian_prod_cpu_bfloat16 (__main__.TestDecompCPU),111,0,21,4,['Other']
84147,"If we block a merge due to merge rules, call out the rule that failed!",3,1,3,3,['Other']
84144,cuda softmax (and logsoftmax) are incorrect on very large tensors,2,0,1,0,['Other']
84132,[ONNX] replace AT_ASSERT with TORCH_INTERNAL_ASSERT,17,1,0,3,['Other']
84123,[ONNX] Move model and input to the same device when exporting,36,2,1,2,['Other']
84122,DISABLED test_comprehensive_column_stack_cpu_float16 (__main__.TestDecompCPU),111,0,5,4,['Other']
84118,DISABLED test_normalize_operator_exhaustive_where_cpu_float32 (__main__.TestNormalizeOperatorsCPU),0,0,2,3,['Other']
84110,YOLOv5-v6.0 Initialisation ISSUE WITH PYTHON3: ,7,0,1,0,['Other']
84109,"Request for LAPACK, XNNPPACK support for mobile pytorch model of react-native app",3,0,5,2,['enhancement']
84097,Got build error `error: ‘size_t’ does not name a type` in gcc 11,0,1,3,2,['Bug']
84095,GitHub Actions performance degraded,0,0,1,1,['Other']
84092,torch.jit.trace doesn't work with autocast on Conv node.,32,1,10,4,['Other']
84089,Mac M1 arm64 runners not available,0,1,4,1,['Other']
84082,Investigate from_padded implementations correctness,4,2,6,5,['Critical']
84069,PyTorch with cuda 11.3 does not work on cuda 11.4 as claimed,0,0,3,0,['Other']
84060,Track land validation usage,39,1,2,2,['Other']
84058,Land Validation should ignore stale commit check,64,0,0,2,['Other']
84056,Handle python exceptions correctly in DLPack Capsule Destructor,39,0,2,2,['Other']
84053,Buffers in AveragedModel are not synchronized with the source model when use_buffers=False,60,0,0,2,['Other']
84048,DISABLED test_binary_op_scalar_fastpath__foreach_div_cuda_int32 (__main__.TestForeachCUDA),111,0,4,4,['Other']
84047,DISABLED test_binary_op_scalar_fastpath__foreach_div_cuda_int8 (__main__.TestForeachCUDA),110,0,4,4,['Other']
84042,"""RuntimeError: src_total_size >= storage_byte_offset INTERNAL ASSERT FAILED"" when training using MPS on YOLOv5",36,1,2,2,['Bug']
84040,"""compute_indices_weights_linear"" not implemented for 'Half'",4,0,1,2,['Other']
84032,DISABLED test_shuffle_workers (__main__.TestDataLoader),113,0,2,4,['Other']
84030,Dropout isn't deterministic between Intel and M1 MacBooks,4,0,10,4,['Other']
84022,"M1 CI is generally flaky with SIGSEGVs, exit code 134s, and flaky tests",37,1,14,5,['Critical']
84019,DISABLED test_make_fx_exhaustive_nn_functional_ctc_loss_cpu_float32 (__main__.TestProxyTensorOpInfoCPU),120,0,4,5,['Other']
84018,Illegal Memory Access was encountered in AvgPool2d CUDA kernel,40,1,5,6,['Critical']
83995,"RuntimeError: dst.nbytes() >= (dst.storage_offset() * dst.element_size()) INTERNAL ASSERT FAILED at ""/Users/davidlaxer/pytorch/aten/src/ATen/native/mps/operations/Copy.mm"":130, please report a bug to PyTorch. ",106,1,0,2,['Bug']
83987,test,0,0,1,0,['Other']
83981,[ONNX] Clean up in-line imports in symbolic helper,38,1,6,3,['Other']
83974,"export onnx error,Warning: Constant folding in symbolic shape inference fails: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)",83,0,2,3,['Bug']
83973,Implement `torch.cuda.device_count` without poison,20,0,23,2,['Other']
83972,Calling torch.squeeze with out parameter provided throws TypeError,28,0,2,2,['Bug']
83970,Fast cuda layer norm for bf16,0,0,0,0,['Other']
83951,DISABLED test_binary_op_scalarlist_fastpath__foreach_div_cuda_int16 (__main__.TestForeachCUDA),117,0,4,4,['Other']
83943,Notify devs on the PR when there's an active sev,65,0,1,1,['Other']
83942,Make the mergebot block merges when there's an active Sev,61,1,1,1,['Other']
83936,[functorch] batch rule for cross is too permissive ,54,0,0,2,['Other']
83928,Linux CUDA workflows failing at Install NVIDIA runtime step - rerun to get back to green,0,0,6,1,['Other']
83919,[ONNX] Op discovery,26,0,0,3,['Other']
83913,RuntimeError: isDifferentiableType(variable.scalar_type()) INTERNAL ASSERT FAILED,1,0,1,2,['Bug']
83912,[BE] [c10d] [send] Improve error message on dist.send() with destination rank as itself,83,1,0,4,['Bug']
83908,wrap_torch_function segfaults if dispatcher doesn't return tuple,76,1,0,2,['Bug']
83907,[functorch] Fix cross or remove comments after bug fix,139,0,0,2,['Bug']
83905,Building PyTorch for M1: problems using CPU,0,0,3,3,['Other']
83903,-,0,0,0,0,['Other']
83887,All CXX11 libtorch builds has been broken since Aug 4th,1,0,3,6,['Critical']
83856,libtorch missing header,1,0,1,3,['Other']
83840,Interpolate(antialias=False) is 8X slower than antialias=True depending on the tensor stride,49,1,6,2,['Other']
83839,Get the conjugate result when use torch.exp to calculate a complex tensor.,1,0,5,2,['Other']
83835,Profiler trace result showed the profiler stopped recording when the training step wasn't finished.,47,0,1,1,['Other']
83832,onnx opset17 is now available?,4,0,2,3,['Other']
83831,Why torch.distributions.multivariate_normal.MultivariateNormal requires positive-definite covariance_matrix rather than positive-semidefinite,0,0,1,0,['Other']
83828,Autograd fails when clamping complex numbers,1,0,3,5,['Critical']
83820,pytorch incompatible with windows sdk >= 25131,52,1,1,3,['Other']
83801,[ONNX] RuntimeError: Unsupported prim::Constant kind: `ival`,86,0,5,4,['Bug']
83797,Parameter `idx` of  method `__getitem__` from class `ModuleList` should accept type `slice`,2,0,0,4,['Other']
83791,AttributeError: 'NoneType' object has no attribute 'python_exit_status',5,1,5,3,['Bug']
83790,Flaky CUDA 11.6 builds when compiling NCCL onerank_reduce.cu,24,1,6,2,['Other']
83776,Flaky tests may be due to limited shared memory,159,0,5,4,['Other']
83771,Timm Models Slow Operators,0,0,0,0,['Other']
83768,FakeTensor internal assert failure running `hf_BigBird` model,2,1,3,1,['Other']
83756,linalg.cross doesn't run checks on broadcasted dimensions,3,1,1,2,['Other']
83747,Consecutive BatchNorm1d is not equivalent to the last one,1,0,2,0,['Other']
83732,Bad Example in pytorch CE,0,0,2,0,['Other']
83730,function torch.linalg.solve gets a different result from 'cpu' when using the 'cuda' calculation,33,0,2,5,['Other']
83699,"ONNX with torch.jit.script function result in ""outerNode->outputs().size() == node->inputs().size()""",0,0,0,1,['Other']
83687,[ONNX] PyTorch-ONNX exporter:Dynamic output fail.,89,0,2,3,['Other']
83685,How to use accessors for fast elementwise write?,6,0,1,0,['Other']
83674,Changes to torchgen/ don't trigger tools/autograd codegen regeneration,0,1,1,2,['Other']
83661,[ONNX] Support exporting new dispatch to linalg.vector_norm and linalg.matrix_norm from torch.norm,140,1,6,3,['Other']
83660,DISABLED test_jvp_nn_functional_conv_transpose3d_cuda_float32 (__main__.TestOperatorsCUDA),116,0,2,4,['Other']
83659,DISABLED test_shuffle_batch_workers_prefetch (__main__.TestDataLoaderPersistentWorkers),126,0,2,4,['Other']
83656,Metal performance shader topk not working after torch.topk>15,0,0,1,2,['Other']
83652,No grad_fn for non-leaf saved tensor,0,0,1,0,['Other']
83647,"[ONNX] conversion of torch.Tensor.normal_  operator breaks with ''Exporting the operator 'prim::layout' to ONNX not supported""",14,1,0,3,['Other']
83617,Multi-Grad Hooks,63,0,9,4,['enhancement']
83613,`state_dict()` pre-hook,0,0,2,1,['Other']
83600,[ONNX] Optional type doesn't align in Loop,26,1,0,3,['Other']
83594,third_party/cpuinfo commit needs to be updated,2,1,1,2,['Other']
83576,[prims+nvfuser] addcdiv is failing primtorch testing with NVFuser and is currently disabled,0,3,1,3,['Other']
83574,DISABLED test_single_output (__main__.TestAOTAutograd),0,0,7,4,['Other']
83573,DISABLED test_single_output (__main__.TestAOTAutograd),0,0,4,4,['Other']
83539,"[ROCm] Bad ROCm runner(s) ""worker-rocm-amd-38""",120,2,2,3,['Other']
83538,torchdynamo is swallowing relevant exceptions even when debug/trace is enabled,108,1,1,2,['Bug']
83533,[jit] jit.trace fails on mps models,30,1,9,5,['Other']
83519,"Provide common set of smoke tests for torch cpu, torch gpu, torchvision, torchaudio",35,1,4,2,['Other']
83513,DISABLED test_binary_op_tensorlists_fastpath__foreach_div_cuda_int16 (__main__.TestForeachCUDA),121,0,4,4,['Other']
83512,DISABLED test_batch_sampler (__main__.TestDataLoader),2,0,3,6,['Other']
83511,DISABLED test_nnc_pytrees_cpu (__main__.TestPythonKeyCPU),1,0,11,5,['Other']
83506,Python custom op registration doesn't broadcast optional int arguments,11,0,0,3,['Other']
83505,isDifferentiableType(variable.scalar_type()) INTERNAL ASSERT FAILED,13,0,11,5,['Critical']
83504,quantized.linear fails with aarch64 linux packages of torch.,9,0,2,1,['Other']
83499,DISABLED test_exception_raises (__main__.SpawnTest),119,0,4,4,['Other']
83498,torch.onnx not support stft,69,0,1,3,['Other']
83491,DISABLED test_profiler_for_loop_indexing_pattern (__main__.TestExperimentalUtils),122,0,4,3,['Other']
83490,improve cuda graph to be memory efficient,28,0,7,2,['Other']
83480,DISABLED test_aot_autograd_exhaustive_atanh_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83479,DISABLED test_aot_autograd_exhaustive_mul_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83478,DISABLED test_aot_autograd_exhaustive_linalg_eigvals_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83477,DISABLED test_aot_autograd_exhaustive_hypot_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83475,DISABLED test_aot_autograd_exhaustive_ceil_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83476,DISABLED test_aot_autograd_exhaustive_pow_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83474,DISABLED test_aot_autograd_exhaustive_sigmoid_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83473,DISABLED test_aot_autograd_exhaustive___rsub___cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83472,DISABLED test_aot_autograd_exhaustive_ceil_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83471,DISABLED test_aot_autograd_exhaustive_linalg_svdvals_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83470,DISABLED test_aot_autograd_exhaustive_linalg_eigvals_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83469,DISABLED test_aot_autograd_exhaustive_linalg_eigvals_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83468,DISABLED test_aot_autograd_exhaustive_zero__cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83458,Look into how the CI passes the list of slow tests and disabled tests around using env variables,8,1,3,4,"['enhancement', 'Bug']"
83453,DISABLED test_aot_autograd_exhaustive_special_erfcx_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,2,3,['Other']
83452,DISABLED test_aot_autograd_exhaustive_square_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,2,3,['Other']
83451,DISABLED test_aot_autograd_exhaustive_nn_functional_celu_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83450,DISABLED test_aot_autograd_exhaustive_nn_functional_elu_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83449,DISABLED test_aot_autograd_exhaustive_sum_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83448,DISABLED test_aot_autograd_exhaustive_special_i0e_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,2,3,['Other']
83447,DISABLED test_aot_autograd_exhaustive_nn_functional_tanhshrink_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83446,DISABLED test_aot_autograd_exhaustive_log2_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,2,3,['Other']
83445,DISABLED test_aot_autograd_exhaustive_special_i1_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83444,DISABLED test_aot_autograd_exhaustive_special_ndtri_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83443,DISABLED test_aot_autograd_exhaustive_log_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,3,3,['Other']
83442,DISABLED test_aot_autograd_exhaustive_min_binary_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83440,There should be one source of truth for storing list of contributors,16,1,1,2,['Other']
83433,Windows CI test breakages due to env variable length limit,0,1,3,1,['Other']
83414,DISABLED test_aot_autograd_exhaustive_double_functorch_no_channels_last_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,4,['Other']
83413,DISABLED test_aot_autograd_exhaustive_asin_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,5,4,['Other']
83412,DISABLED test_aot_autograd_exhaustive_sin_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,4,4,['Other']
83411,DISABLED test_aot_autograd_exhaustive_nn_functional_hardsigmoid_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,4,4,['Other']
83410,DISABLED test_aot_autograd_exhaustive_exp_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,4,['Other']
83409,DISABLED test_aot_autograd_exhaustive_nn_functional_selu_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,2,3,['Other']
83408,DISABLED test_new_empty (__main__.TestSymbolicTracing),128,0,5,4,['Other']
83407,DISABLED test_aot_autograd_exhaustive_mH_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,4,['Other']
83406,DISABLED test_aot_autograd_exhaustive_minimum_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,4,['Other']
83405,DISABLED test_single_output_functionalize (make_functionalize_test.<locals>.FunctionalizeTest),2,0,10,3,['Other']
83403,DISABLED test_aot_autograd_exhaustive_erfc_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,4,['Other']
83404,DISABLED test_aot_autograd_exhaustive_mT_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,4,['Other']
83402,DISABLED test_aot_autograd_exhaustive_max_reduction_no_dim_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83401,DISABLED test_aot_autograd_exhaustive_linalg_inv_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,2,3,['Other']
83400,DISABLED test_aot_autograd_exhaustive_special_log_ndtr_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,2,3,['Other']
83398,DISABLED test_aot_autograd_exhaustive_nn_functional_mish_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,3,['Other']
83399,DISABLED test_aot_autograd_exhaustive_exp2_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,2,4,['Other']
83397,DISABLED test_aot_autograd_exhaustive_sinc_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,1,4,['Other']
83396,DISABLED test_aot_autograd_exhaustive_matrix_exp_cpu_float32 (__main__.TestEagerFusionOpInfoCPU),0,0,4,3,['Other']
83390,LIBTORCH: Stack smashing encountered when using malloc/ free with libtorch,0,0,1,4,['Critical']
83386,RuntimeError: derivative for aten::mps_linear_backward is not implemented,51,0,4,3,['Bug']
83384,M1 nightly install is broken,1,1,4,5,['Critical']
83382,torch.nn.functional.conv2d runs slower on float16 type than on float32 type,1,0,1,4,['Other']
83378,JIT compiling this specific function with grad-enabled tensors makes it always produce grad-enabled tensors,4,0,1,1,['Other']
83363,CODEOWNERS/merge_rules/POI and mergebot bug are inconsistent with public documentation and each other,3,1,1,2,"['Bug', 'Documentation']"
83362,Meta Impl of native_layer_norm (math_native_layer_norm) Errors Where Cuda Succeeds,3,0,1,2,['Bug']
83355,Only support when num_heads is even in transformer,26,2,7,6,['Critical']
83347,Add type hints for values generated by dataloaders,4,0,2,3,['Other']
83343,torch.nn.functional.pad throw 'Dimension out of range' on Apple Silicon M1 MPS,9,1,0,4,['Bug']
83340,Massive growth in cpu memory use when loading model from cpu to gpu,2,0,1,0,['Other']
83335,periodic linux-xenial-cuda10.2-py3-gcc7-slow-gradcheck  times out,3,0,4,6,['Critical']
83328,torch.nn.Conv2d will segfault when the type of input tensor is float16,129,1,6,6,"['Critical', 'Bug']"
83326,torch.tril lacks of checking 'out of bound' on cuda,101,0,2,3,['Bug']
83325,torch.nn.MaxPool1d dont accept 0-batch dim tensors on gpu,4,0,2,5,['Bug']
83322,"""clamp_min_cpu"" not implemented for 'Half'",0,0,2,2,['Other']
83321,"when input type of torch.nn.AvgPool3d is bfloat16, cpu's running result is inconsistent with gpu",0,0,2,0,['Other']
83318,torch.lu_solve will return tensor if input contains int type tensor,2,0,2,3,['Bug']
83314,torch.equal not give the same result on GPU vs on CPU,4,1,4,2,['Other']
83311,"when input type of torch.cholesky_inverse is complex128, cpu's running result is inconsistent with gpu",5,0,5,3,['Other']
83291,Libtorch 1.12.1 crashes on debug mode under Windows,85,1,10,3,"['Bug', 'Critical']"
83290,Pytorch based Bert NER for transfer learning/retraining,0,0,0,0,['Other']
83270,Issue with torch.utils.data.DataLoader 'shuffle=True' ,0,0,1,2,['Other']
83256,F.batch_norm uses unbiased estimator but documentation says biased estimator,1,0,1,3,['Documentation']
83255,Static initialization issue when building LibTorch (CPU) as static lib on Windows,119,1,6,3,['Other']
83251,make_fx doesn't capture symbolically boolean values returned by torch calls,1,1,2,3,['Other']
83247,DISABLED test_scalar_ins (__main__.TestTorchTidyProfiler),125,0,5,3,['Other']
83230,ONNX export is incorrect on Apple Silicon M1 MPS,12,1,22,4,['Bug']
83228,DISABLED test_profiler_experimental_tree_with_memory_and_stack (__main__.TestProfilerTree),133,0,2,3,['Other']
83227,"QAT the bias  is the int32, how to set the int8?",0,0,2,1,['Other']
83224,parameter 'padding' of torch.nn.MaxPool1d can be set to negative integral,12,0,1,2,['Other']
83211,Making quantizable LSTM scriptable,15,0,6,1,['Other']
83180,On Mac M1 MPS Conv2d produces different result than cpu when stride is different in two dimensions,6,0,0,2,['Other']
83164,parameter '_stacklevel' of torch.nn.functional.{softmax|log_softmax} can set to string,0,0,2,0,['Other']
83160,torch.nn.functional.rrelu_ allows lower bound greater than upper bound,42,0,1,4,['Other']
83156,"QAT  the weights -->  [-128, 127] but the relu -->[0, 255] , i can change relu to [-128, 127]?",1,0,1,1,['Other']
83142,Transformer encoder error when encoding long sequence (more than 1024 tokens),20,1,2,3,['Bug']
83138,"Typo in norm_first parameter description of transformer layer, respectivaly - > respectively",0,0,0,0,['Other']
83133,github actions having a variety of issues - please dont merge without proper signal,0,0,2,2,['Other']
83129,FSDP does not reshard params if _post_backward_hook did not fire,21,1,1,5,['Critical']
83120,Expose c++ Node pre-hook to python,3,1,0,3,['Other']
83117,Add option to run anomaly mode without nan checking,7,0,0,3,['Other']
83116,[FX] Cannot deepcopy Tracer objects,6,1,0,1,['Other']
83113,DISABLED test_tensor_properties (__main__.TestTorchTidyProfiler),126,1,5,3,['Other']
83110,Remove `remove_quant_dequant_pairs` and fix the tests,33,1,0,1,['Other']
83108,Remove `duplicate_dequantize_node` and `duplicate_quantize_dynamic_node` and `remove_extra_dequantize` in lowering code,16,0,1,2,['Other']
83101,Importing torchvision.models.detection.faster_rcnn when on CPU results in GIL deadlock when torch tensor from numpy.array is deallocated,56,0,10,4,['Other']
83099,Add docs tooling to validate pytorch tests were correctly built,80,1,1,2,['Other']
83096,Migrate DevX KPIs from Grafana to HUD,169,1,1,2,['Other']
83093,Remove WEIGHT_INDEX_DICT and BIAS_INDEX_DICT from fx quant codebase,19,1,0,3,['Other']
83090,Remove `_` from reference modules path,37,1,2,2,['Other']
83076,[FSDP] `summon_full_params(offload_to_cpu=True)` keeps `_full_param_padded` on GPU,37,1,2,2,['Other']
83071,torch.nn.functional.adaptive_max_pool{1|2|3}d can get negative dimension tensor,1,0,3,3,['Other']
83069,__dlpack__() should normalize strides,14,1,2,2,['Other']
83068,[FSDP] Parameter MP + root FSDP `summon_full_params()` does not force full precision after forward,37,1,2,2,['Other']
83066,`torch.Tensor.size(dim)` returns `torch.Size` when `dim` is specified,0,0,1,0,['Other']
83065,Can't pickle local object 'CDLL.__init__.<locals>._FuncPtr',6,0,1,2,['Other']
83063,torch.nn.AdaptiveMaxPool{2|3}d create tensor with negative dimension,1,0,8,3,['Other']
83062,torch.nn.AdaptiveAvgPool2d didn't return result after 2 minutes running,2,0,2,3,['Other']
83054,FSDP device_id + CPU offload crash,159,2,3,5,['Critical']
83053,FSDP namedtuple support has issues,57,0,1,6,['Critical']
83051,Op dispatch declaration bug,28,0,6,1,['Bug']
83044,Test jobs should not be named `build`,129,0,0,2,['Other']
83041,Codegen for AutogradNestedTensor,24,3,2,1,['Other']
83038,[ONNX] Produce comprehensive assertion errors for quantized outputs,85,2,1,5,['Bug']
83029,DISABLED test_binary_op_scalarlist_fastpath__foreach_add_cuda_int32 (__main__.TestForeachCUDA),134,0,4,4,['Other']
83028,DISABLED test_binary_op_scalarlist_fastpath__foreach_div_cuda_int64 (__main__.TestForeachCUDA),127,0,4,4,['Other']
83027,DISABLED test_binary_op_scalarlist_fastpath__foreach_div_cuda_bool (__main__.TestForeachCUDA),128,0,4,4,['Other']
83026,DISABLED test_binary_op_scalarlist_fastpath__foreach_add_cuda_uint8 (__main__.TestForeachCUDA),128,0,4,4,['Other']
83023,aten::inverse FuncTorchBatched has duplicate errors,1,0,2,3,['Bug']
83021,Add smoke test to the validation workflow MacOS ,49,1,0,2,['Other']
83013,Create Workflow to install binary builds using install instructions as per get started page for MacOS,49,1,0,3,['Other']
83003,Pre-install MiniConda into Windows AMI,4,1,2,3,['Other']
82998,[ONNX] Unable to cast from non-held to held instance,48,0,1,3,['Other']
82996,Design and automate generation of get_started page,147,1,0,1,['Other']
82991,"Create a workflow to validate binary presence based on the release matrix, for conda, wheels, libtorch.",91,0,1,1,['Other']
82983,"Setting torch.cfloat as default tensor type raises ""invalid type"" error",35,0,3,2,['Bug']
82980,Add smoke test to the validation workflow Windows,52,0,0,3,['Other']
82978,Create Workflow to install binary builds using install instructions as per get started page for Windows,52,0,1,3,['Other']
82977,Reuse existing Windows AMI for the validation,52,0,1,3,['Other']
82973,Add smoke test to the validation workflow Linux,52,0,0,2,['Other']
82971,Create Workflow to install binary builds using install instructions as per get started page for Linux,52,2,2,2,['Other']
82969,Create basic ubuntu images without any dependencies,2,1,2,2,['Other']
82966,MPS build raises too many warnings,2,1,7,5,['Critical']
82964,"ValueError: Sequence must have length 1, got 3.",21,0,4,2,['Bug']
82963,[FSDP] TypeError: load_state_dict() got an unexpected keyword argument 'strict',58,1,4,5,"['Critical', 'Bug']"
82961,DISABLED test_output_match_split_cpu_float32 (__main__.TestConsistencyCPU),57,1,2,4,['Other']
82956,torch.add triggers INTERNAL ASSERT FAILED,0,0,1,0,['Other']
82948,DISABLED test_no_cyclic_references (__main__.TestLRScheduler),60,0,3,6,['Other']
82945,"""RuntimeError: Cannot insert a Tensor..."" happened when exporting onnx",12,0,3,3,['Bug']
82936,RuntimeError: Expected sequence length to be larger than 0 in RNN,0,0,4,0,['Other']
82934,buck-build-and-test fails to download jdk dependency,0,0,0,3,['Critical']
82933,[bug] bug in size and map methods of torch::data::Dataset in libtorch,5,0,4,2,['Bug']
82932,"A fixed tensor is divided into two parts for two GPU while in multi-gpu env for training with device=[0, 1].",143,0,3,2,['Other']
82921,Conv1d with stride other than 1 fails on mps,11,0,3,5,['Critical']
82920,nan_to_num optional argument causes None errors in arg promotion - make nan_to_num match aten op,2,1,1,0,['Other']
82914,DISABLED test_profiler_optimizer_single_tensor_pattern (__main__.TestExperimentalUtils),135,0,4,3,['Other']
82913,PyTorch CI/binary smoke test should validate minor version compatibility feature,47,1,3,4,"['enhancement', 'Critical', 'Minor']"
82891,FSDP device_id + CPU offload can have issues,10,1,1,6,['Critical']
82890,Periodic IOS Workflows Are Timing Out/Flaky,5,1,6,2,['Other']
82889,LayerNorm+CUDA+JIT,5,1,13,2,['Other']
82888,trunk / libtorch-linux-bionic-cuda11.6-py3.7-gcc7 / build is Flaky,5,1,2,3,['Other']
82885,torch.log test with negative numbers…,0,0,3,2,['Other']
82881,No support for AVX512 in torch 1.12.0+cpu python package,10,0,4,2,['Other']
82878,torch.topk() cuda version is not working correctly,3,0,3,2,['Other']
82875,Unable to freeze tensor of type Int64/Float64 into constant layer,3,0,2,0,['Other']
82873,DISABLED test_profiler_extra_cuda_copy_pattern (__main__.TestExperimentalUtils),131,0,4,4,['Other']
82870,"[ONNX] Converted to onnx successful, but can not load",102,0,6,3,['Other']
82868,Change default `rcond` parameter in `torch.linalg.lstsq` to match `numpy.linalg.lstsq`,0,0,2,3,['Other']
82864,DISABLED test_profiler_matmul_dim_fp16_pattern (__main__.TestExperimentalUtils),132,0,4,3,['Other']
82859,ReduceLROnPlateau when using chained schedulers does not work,0,0,1,2,['Other']
82858,expanded_extent_ == nullptr || isBroadcast() INTERNAL ASSERT FAILED ,5,1,7,2,['Other']
82857,Torch.hub changes pyplot backend,0,0,4,2,['Other']
82832,Tensor subclasses should get __hash__ automatically defined,6,0,9,2,['Other']
82811,"torch export onnx graph, the scale_factor parameter of  __interpolate is converted to a constant",0,0,0,0,['Other']
82810,TestNNAPI fails when not build with QNNPACK,1,0,0,3,['Other']
82808,`torch.nn.utils.weight_norm` backward causes Segmentation Fault nondeterministically,4,0,4,5,['Critical']
82807,Lacking utils.so when building ,1,0,1,0,['Other']
82803,DISABLED test_worker_init_fn (__main__.TestDataLoader),132,0,4,5,['Other']
82798,"No module named 'torchvision.ops.nms' is still a bug in latest library after torch >=1.11, torch vision >=0.11",1,0,2,0,['Other']
82784,NVFuser produces incorrect output for broadcasted dropout,21,0,4,3,['Critical']
82783,TransformerEncoderLayer fast path errors under `torch.autocast`,35,1,2,1,['Bug']
82781,DISABLED test_profiler_extra_cuda_copy_pattern_benchmark (__main__.TestExperimentalUtils),4,2,3,1,['Other']
82763,Primtorch nan_to_num signature does not align with aten,1,0,12,1,['Other']
82738,[CI] Add CircleCI Mac jobs on pull request,63,1,2,2,['Other']
82732,Creating iterator from Dataset raises StopIteration instead of IndexError in __getitem__ method,0,0,1,2,['Bug']
82720,DISABLED test_profiler_conv2d_bias_followed_by_batchnorm2d_pattern (__main__.TestExperimentalUtils),134,0,4,4,['Other']
82719,DISABLED test_extra_fields (__main__.TestTorchTidyProfiler),133,0,4,4,['Other']
82716,torch.sparse has no attribute softmax,0,0,1,0,['Other']
82715,torch.sparse has no attribute softmax,0,0,0,0,['Other']
82708,[Quant] Tanh: QConfigMapping must specify fixed qparams observer for fixed qparams op,5,1,3,2,['Other']
82707,[Apple Silicon M1 MPS device] bad performance metrics for BERT model training,5,0,17,3,['Other']
82702,Mac: App crashes (mutex) on exiting when using MPS backend,57,1,6,4,['Critical']
82701,DISABLED test_gradgrad_nn_LazyConvTranspose3d_cuda_float64 (__main__.TestModuleCUDA),134,0,2,5,['Other']
82700,Can't run test_ops test suite,5,0,11,4,['Other']
82699,Can't reproduce 20% performance gains on resnet50 using channel last memory format,0,0,3,4,['Other']
82711,ConvTranspose1d doesn't work correctly on ARM,14,0,4,5,['Other']
82691,Pytorchbot should offer a workaround when it doesn't have access to a remote repository,90,0,2,3,['Other']
82683,`s.zero_()` on sparse csr tensor `s` fills values tensor with materialized zeros,47,2,4,2,['Other']
82671,Swap Nested Tensor buffer_ with a buffer_ of type Storage.,5,1,0,2,['Other']
82663,[MPS] `torch.expand` returns wrong results for boolean types,5,0,2,3,['Other']
82653,Unpin numpy on Windows,0,0,1,0,['Other']
82645,"[MPS] `index_select` backward error, different types are not broadcast compatible",140,1,4,2,['Bug']
82644,torch.prod : backward errors when a tensor contains zero value,48,1,1,4,"['Critical', 'Bug']"
82641,Variable's address changed when passing them through DDP model,95,1,10,5,['Critical']
82633,Need a way to reenable TorchFunction,6,0,1,2,['Other']
82588,DISABLED test_matmul_cuda_float64 (__main__.TestNestedTensorDeviceTypeCUDA),133,0,4,4,['Other']
82569,Topk: CUDA error: an illegal memory access was encountered,7,0,8,6,"['Critical', 'Bug']"
82566,MacOS MPS: src_total_size >= storage_byte_offset,44,1,2,2,['Other']
82563,ConvTranspose1D producing different results on CPU & MPS backend,17,0,3,3,['Other']
82559,Implementation of nn.Conv2d.output_size(x: torch.Tensor),1,0,5,1,['Other']
82553,"False positive AVX, AVX2 and AVX512 detection with MSVC",3,0,3,3,['Other']
82543,[MPS] Incorrect rounded results of `add` and `sub`,22,1,1,4,['Critical']
82541,[MPS] `true_divide` backward seg fault,4,0,3,3,['Critical']
82531,[MPS] `sub` backward seg fault,3,1,1,4,['Critical']
82528,"Memory leak under ""full backward hook"" with ""backward(create_graph=True)"" ",6,1,15,6,['Critical']
82524,how to build libtorch from source?,21,0,1,4,['Other']
82513,FSDP mixed precision: flag to keep gradients in reduced precision,78,0,3,3,['Other']
82502,"Remove `THPTensor` defs, override macros, and `GenerateByteType.h`",0,1,0,1,['Other']
82493,F.batch_norm produces vastly different gradient when comparing cudnn vs native implementation,1,0,4,3,['Other']
82492,Unable to run pytorch unit test because CI environment variables are not available,0,1,1,3,['Other']
82486,SparseAdam fails when a parameter has an empty sparse gradient tensor,70,1,0,4,['Critical']
82483,Conda repodata broken for osx arm64,3,1,2,4,['Critical']
82482,Saved tensor hooks checkpoint implementation cannot robustly clear storage,45,0,1,4,['Other']
82480,Support Quantized Slice / getitem operator,11,1,1,1,['Other']
82473,bug: torch.linalg.svd get wrong results,0,0,5,1,['Bug']
82463,Cannot export models to TensorRT with int8 quantization,3,0,1,2,['Other']
82462,Multi-process Pipe(),17,0,4,2,['Other']
82461,[FSDP] caffe2 error in forward method when using fsdp,68,1,9,5,"['Critical', 'Bug']"
82457,torch.cat has different CPU/CUDA behavior in PyTorch 1.12.0,17,1,4,5,['Critical']
82436,Rename `_Typed/_UntypedStorage` to `Typed/UntypedStorage` and update docs,1,1,0,2,['Documentation']
82434,aten::rrelu_with_noise function mutates noise parameter,4,0,1,0,['Other']
82431,Cumulative matrix product,3,0,3,3,['enhancement']
82428,PyTorch-1.12 can not be installed on M1 from official channel,4,1,13,6,['Critical']
82427,[MPS] `torch.full` does not work for boolean types,25,0,4,3,['Critical']
82425,PyTorch/XLA compiler upgrade to c++17 breaks upstream torch tests,21,1,13,4,['Other']
82416,Segfault in `new_empty_strided`,7,1,1,4,"['Bug', 'Critical']"
82415,"Printing out condensed list of ""unexpected successes"" when test fail",110,1,1,3,['enhancement']
82413,nullptr doesn't work with c10::intrusive_ptr,114,0,0,2,['Other']
82412,torch.load map_location cannot handle meta tensor,11,0,2,2,['Other']
82411,Dataloader fails with num_workers > 0 and tensors that require_grad,0,0,5,2,['Other']
82408,ATen/cuda/nvrtc_stub not usable from C++ extension,69,0,1,2,['Other']
82372,Remove `torch/csrc/generic`,0,1,0,1,['Other']
82370,[ONNX] Fail to export inception_v3 with torch script,27,1,2,3,['Other']
82367,target determination for functorch CI,93,1,12,2,['Other']
82364,PrimTorch out_wrapper semantics are not quite right for factory functions,1,1,1,2,['Other']
82344,Custom layer input tensor tracking support in profiler,58,0,8,2,['Other']
82343,PR #81785 causes inference start up overhead on timm models.,9,1,5,1,['Other']
82335,Mergebot should ignore skipped/cancelled workflows,0,1,2,4,['Critical']
82334,Sharing complex non-pickleable object between processes with BaseManager,1,0,2,2,['Other']
82331,Meta registration decision is not quite right,14,0,2,1,['Other']
82330,"[ONNX] When using Apex FusedLayerNorm, Transformers model has static shape (batch size).",1,1,0,3,['Other']
82327,Got import error for functorch memory_efficient_fusion,0,0,6,1,['Bug']
82320,ccache doesn't help on trivial changes to codegen,3,1,2,1,['Other']
82313,There may be problems in the documentation of batchnorm,0,0,1,3,['Documentation']
82305,[MPS] Expand does not work for torch.uint8 type,22,1,4,4,['Critical']
82304,How to use SwiftShader to test vulkan mobile models ?,1,0,1,1,['Other']
82300,DISABLED test_binary_op_tensorlists_fastpath__foreach_div_cuda_bool (__main__.TestForeachCUDA),139,0,4,4,['Other']
82299,DISABLED test_matmul_cuda_float32 (__main__.TestNestedTensorDeviceTypeCUDA),141,1,4,4,['Other']
82296,torch.mps.*Tensor datatypes,160,0,37,4,['Critical']
82286,[LTC][Codegen] Call `torch::lazy::GetCanonicalDimensionIndices` on dimension inputs,14,0,12,2,['Other']
82275,[ONNX] Cherry pick quantization for 1.12.1 release,7,0,7,3,['Other']
82266,F.avg_pool2d() crashes with Complex tensor,1,0,3,4,['Critical']
82263,A lot of documentation pages do not load 404 error,0,0,2,0,['Other']
82260,"SIGSEV, SIGBUS, SIGIOT in CI",48,0,1,2,['Other']
82245,[ONNX] Remove einsum_helper from opset12 public functions,9,0,3,5,['Other']
82235,pixel_shuffle has inconsistent aliasing between cuda and cpu,78,0,2,3,['Other']
82232,[FSDP] Unify the optimizer state_dict APIs,127,0,1,4,['enhancement']
82211,pytorch version > 1.8 init cuda env after `import torch`,0,0,3,0,['Other']
82208,[LTC][Codegen] Provide an alternative for GetIrValueForScalarFromCodegen,23,1,4,2,['Other']
82202,NotImplementedError: Could not run 'aten::aminmax.out' with arguments from the 'QuantizedCPU' backend,2,0,1,1,['Bug']
82201,[FSDP] FSDP wrapped UNet model running backward crashes,0,0,2,0,['Other']
82194,sanitize_test_filename doesn't work on Windows,0,0,1,0,['Other']
82174,"Error ""Failed to fetch https://github.com/rust-lang/crates.io-index"" on Docker rebuild",0,1,0,2,['Bug']
82168,DISABLED test_binary_op_scalarlist_fastpath__foreach_add_cuda_float16 (__main__.TestForeachCUDA),146,0,4,4,['Other']
82160,Pytorch-elastic doesn't generate run_id for jobs when --rdzv_id is not specified,10,0,4,2,['Other']
82150,Select coo tensor with zero NNZ does not preserve dtype (for integer types?),1,1,7,4,['Other']
82092,Add pivoted QR from MAGMA (PR wanted?),0,0,1,0,['Other']
82079,[FSDP] FSDP wrapped UNet model running forward crashes,1,1,3,1,['Critical']
82074,View metadata doesn't propagate when TorchDispatchMode is active,0,0,1,1,['Other']
82071,`torch.nn.functional.gumbel_softmax` returns different results on cpu and on cuda with the same input,9,0,3,5,['Critical']
82060,Wrong output of single-channel channels_last convolution with channels_first input,4,0,4,7,['Critical']
82059,frombuffer() returns oversized tensors when multiprocessing,23,0,1,2,['Other']
82055,Errors in https://github.com/pytorch/pytorch/wiki/torch_quantization_design_proposal,0,0,1,0,['Other']
82050,Need synchronize when change stream,95,0,0,2,['Other']
82044,Record fake tensor on FX IR while we're tracing make_fx,65,0,2,3,['Other']
82034,NotImplementedError: The operator 'aten::index.Tensor_out' is not current implemented for the MPS device.,30,0,4,2,['Bug']
82031,[ONNX] RReLU converted to onnx is not determenistic,13,1,8,5,['Other']
82023,DISABLED test_named_params_with_sharded_tensor (__main__.TestShardedOptimizer),145,0,4,2,['Other']
82018,"Pytorch followups issue ""`ci: sev`""",1,0,0,0,['Other']
82017,Debugger for PyTorch,1,0,0,0,['Other']
82016,DISABLED test_compilation_for_dynamic_shape (__main__.TestCompileCache),0,0,1,1,['Other']
82014,DISABLED test_extremal_numerics_binary_cross_entropy_cpu (__main__.TestOperatorsCPU),0,0,1,1,['Other']
82001,Issue with FSDP memory reduction scaling up GPUs,55,3,1,2,['Other']
81968,Debugger for PyTorch,0,0,1,0,['Other']
81950,Complex Valued Loss Function: CrossEntropyLoss(),0,0,8,4,['enhancement']
81940,a CUDNN issue for conv2d compilation leading to performance degradation,136,0,9,2,['Other']
81939,[ONNX] Handle half_to_float in aten::_log_softmax in ONNX exporter,3,0,1,3,['Other']
81934,Reduce the boilerplate in SymInt.h,12,0,0,1,['Other']
81926,A bug of torch.arange for long sequence with fp16 data type,0,0,3,0,['Other']
81920,DISABLED test_tags__refs_constant_pad_nd_cpu_float32 (__main__.TestTagsCPU),144,0,2,2,['Other']
81913,Hardlink to macos version of Python on https://pytorch.org/get-started/locally/,0,0,2,0,['Other']
81908,"`torch.backends.cudnn.flags(enable=True, benchmark=True)` ctx manager does not work after `torch.backends.disable_global_flags()` is executed",0,0,1,3,['Other']
81902,[FX] `concrete_args` unpacking erroneously carries over type annotations,0,0,0,1,['Other']
81900,403 while installing via pip,0,0,6,2,['Other']
81891,DISABLED test_seqential_batch_workers (__main__.TestDataLoader),146,0,4,4,['Other']
81871,[ONNX] `Unfold` operator unsupported when exporting to ONNX,95,0,5,3,['Other']
81869,"[ONNX] When converting a Pytorch model (which contains a constant) to onnx, constants are converted with double type",4,0,2,3,['Other']
81829,Trigger pagers after nightly builds fail two nights in a row,11,0,2,2,['Other']
81825,https://conda.anaconda.org/pytorch/win-64/torchaudio-0.12.0-py39_cu116.tar.bz2 returns 403,0,0,1,0,['Other']
81823,unable to install from conda on lts ubuntu server ,0,0,1,0,['Other']
81822,DISABLED test_forward_ad_nn_functional_conv_transpose3d_cuda_float32 (__main__.TestCompositeComplianceCUDA),144,1,7,5,['Critical']
81811,Dr. CI message up top feels ignorable,100,1,3,3,['enhancement']
81810,Improved sorting of the CI workflows in a PR,100,1,2,2,['Other']
81807,Actionlint has false positives,5,1,1,2,['Other']
81799,Pytorch fails to install on Windows with HTTP 403 errors,0,0,1,0,['Other']
81798,403 when trying to get multiple pytorch components,0,0,4,0,['Other']
81774,`test_get_torch_func_signature_exhaustive` fails for all ops that take TensorOptions,17,1,2,1,['Other']
81769,Documentation on c10d is expected,15,0,5,2,['Documentation']
81760,pytorch conda repo broke today,0,0,17,3,['Critical']
81758,PyTorch 1.12 already initializes CUDA with `import torch`,0,0,2,3,['Critical']
81710,Provide an additional constructor for `torch::lazy::Shape` to accept dynamic bits,2,1,1,2,['Other']
81704,"init_process_group connects but hangs (Kubeflow pytorch training operator, gloo backend)",0,0,1,0,['Other']
81700,AttributeError: 'Adam' object has no attribute '_warned_capturable_if_run_uncaptured' - when resumed training with state loaded from disk,0,0,4,2,['Bug']
81694,nn.Conv1d result is affected by batch,0,0,2,3,['Other']
81693,Shape inference of custom_domain::custom_op is missing despite setting type and shape via `setType()`,123,1,6,3,['Other']
81690,Conjugate resetting after loading a model,113,1,10,5,['Critical']
81686,Typo in quantization documentation,1,0,1,1,['Documentation']
81685,DISABLED test_serialization_map_location (__main__.TestOldSerialization),149,0,4,4,['Other']
81665,Runtime error using nearest neighbour upsampling on tensor with channels-last memory layout,104,0,6,5,"['Critical', 'Bug']"
81659,nn.Linear on CUDA accepts incorrect input shape,1,0,2,2,['Other']
81645,code example of TORCH.USE_DETERMINISTIC_ALGORITHMS documentation is outdated,7,1,1,4,['Documentation']
81634,Simple LSTM ~260x slower on AMD CPU vs Intel CPU,4,0,3,4,['Other']
81633,Reconsider allowing negative learning rates in torch.optim.SGD (and others),32,0,9,3,['enhancement']
81627,Modifying the source code,0,0,4,0,['Other']
81626,DISABLED test_profiler (test_jit.TestJit),192,0,4,3,['Other']
81618,Functionalization failed when using tensor constructor and out variants.,1,1,0,0,['Other']
81613,ios-12-5-1-x86-64 / Run Simulator tests does not run tests against commit in question,8,1,4,4,"['Question', 'Critical']"
81610,M1 MPS memory leak.,8,2,1,2,['Other']
81607,"Debugging fake tensor mode + proxy tensor mode is a pain, print doesn't work",36,1,1,2,['Bug']
81597,WeakTensorMap as part of stdlib,165,0,13,2,['Other']
81584,binary_cross_entropy crashes when data on mps,3,0,4,1,['Critical']
81567,"Macbook M1 GPU support ""mps"" results in wrong (random) conversion when casting a tensor to LongTensor type.",4,1,1,3,['Bug']
81566,[ONNX] Improve quantization error message,68,1,0,3,['Bug']
81557,Bugs about permute function using MPS,25,1,5,3,['Bug']
81551,The operator adaptive_avg_pool2d is not supported when torch is converted to onnx. Is there a fix in that version?,123,0,2,3,['Other']
81549,torch.cuda.is_available() return False（Try multiple versions）,7,0,4,2,['Other']
81542,A100 -->CUDA initialization: Unexpected error from cudaGetDeviceCount(),0,0,1,0,['Other']
81511,ImportError: TensorBoard logging requires TensorBoard version 1.15 or above,0,0,1,0,['Other']
81468,Failed to build from source - Failed at FbgemmBfloat16ConvertAvx512.cc.o,0,0,1,0,['Other']
81467,[CheckpointWrapper] Rename `apply_activation_checkpointing_wrapper()`?,78,2,1,3,['Other']
81457,test_functionalization.py flaky under torchdynamo,19,1,0,3,['Other']
81423,[LTC] Missing header `ltc_ops.h`,0,0,1,0,['Other']
81415,`CHECK_*` macro signatures break downstream pytorch/xla build,12,0,10,2,['Other']
81409,Segmentation fault is raised when torch._C._nn.adaptive_avg_pool2d is called with some parameters,91,0,2,3,['Critical']
81406,Docs: docstring gives wrong default arge for mode on FileOpenerIterDataPipe,2,0,0,2,['Other']
81395,How to Do Semi-Asynchronous or Asynchronous Training with Pytorch,0,0,1,0,['Other']
81393,Recent PR added -Werror=non-virtual-dtor make build failed,0,0,2,2,['Bug']
81389,DISABLED test_terminate_exit (__main__.ForkTest),154,0,4,4,['Other']
81387,"Unhandled FakeTensor Device Propagation for aten.index_put_.default, found two different devices cuda:0, cpu     ",6,1,2,2,['Other']
81384,Inconsistent results between CPU and MPS on MLP.,0,0,2,0,['Other']
81370,Incorrect type replacement in torch.linspace docs,7,0,0,2,['Other']
81365,Segfault when functionalization tensor wrapping subclass is an output saved for backward,5,1,1,4,"['Critical', 'Bug']"
81350,Trunk + Binary build workflows don't get cancelled when a new commit is pushed,8,0,2,2,['Other']
81336,[ONNX] PR #80074 is skipping a ONNX test,65,1,0,3,['Other']
81329,Use yaml.safe_load to replace yaml.load in the code for security.,9,0,9,2,['Other']
81315,C++ Documentation Missing!,16,0,1,4,['Documentation']
81313,distributed training hanging,5,0,3,1,['Other']
81306,Version 10 training model inference error in version 12,103,0,7,2,['Bug']
81296,Gradient hook is called twice for shared parameter with activation checkpointing,0,0,12,3,['Other']
81294,Circular import error in torchgen.api.types,1,0,3,2,['Bug']
81280,DISABLED test_success_non_blocking (__main__.ForkTest),154,0,5,4,['Other']
81254,Typo in event_shape of TransformedDistribution?,127,0,3,2,['Other']
81234,Guard against reused generators passed to test instantiation decorators,10,0,6,2,['Other']
81223,"Inconsistent in ""EXTENDING PYTORCH"" and ""save_for_backward""",10,1,2,4,['Other']
81222,DISABLED test_mixed_wrappers_valid (__main__.TestFunctionalization),22,0,3,5,['Other']
81221,DISABLED test_simple (__main__.TestFunctionalization),22,0,4,4,['Other']
81220,DISABLED test_everything (__main__.TestFunctionalization),22,0,3,5,['Other']
81218,DISABLED test_reapply_views_simple (__main__.TestFunctionalization),22,0,3,5,['Other']
81219,DISABLED test_multiple_levels_of_wrapping (__main__.TestFunctionalization),17,1,4,5,['Other']
81217,DISABLED test_multi_out (__main__.TestFunctionalization),22,0,3,5,['Other']
81216,DISABLED test_cat (__main__.TestFunctionalization),22,0,3,5,['Other']
81215,DISABLED test_tensor_list_composite (__main__.TestFunctionalization),22,0,3,5,['Other']
81214,DISABLED test_split (__main__.TestFunctionalization),22,0,3,5,['Other']
81212,DISABLED test_simple_out (__main__.TestFunctionalization),22,0,6,4,['Other']
81211,DISABLED test_diagonal (__main__.TestFunctionalization),22,0,3,5,['Other']
81210,DISABLED test_as_strided (__main__.TestFunctionalization),22,0,3,5,['Other']
81209,DISABLED test_resize_smaller (__main__.TestFunctionalization),22,0,3,5,['Other']
81208,DISABLED test_mutable_op_not_inplace_or_other (__main__.TestFunctionalization),22,0,3,5,['Other']
81207,DISABLED test_optional_tensor_list (__main__.TestFunctionalization),22,0,3,5,['Other']
81206,DISABLED test_copy_ (__main__.TestFunctionalization),22,0,3,5,['Other']
81205,DISABLED test_fill_ (__main__.TestFunctionalization),22,0,3,5,['Other']
81204,DISABLED test_inplace_on_non_view (__main__.TestFunctionalization),22,0,3,5,['Other']
81203,DISABLED test_view_inplace (__main__.TestFunctionalization),22,0,3,5,['Other']
81201,DISABLED test_resize_larger_valid (__main__.TestFunctionalization),22,0,3,5,['Other']
81202,DISABLED test_only_one_view (__main__.TestFunctionalization),22,0,3,5,['Other']
81200,DISABLED test_scalars (__main__.TestFunctionalization),22,0,3,5,['Other']
81198,Android build causes compile error with `#include <torch/torch.h>` from v1.12.0 because PadNd.h is not found,91,0,13,4,"['Critical', 'Bug']"
81197,"RuntimeError: values[i]->type()->isSubtypeOf(value_type) INTERNAL ASSERT FAILED at ""/pytorch/torch/csrc/jit/ir/ir.cpp"":1650, please report a bug to PyTorch.",0,0,2,1,['Bug']
81194,Please validate PyTorch converter with ORT 1.12 release candidate.,1,0,2,3,['Other']
81187,The following operation failed in the TorchScript interpreter: torch.masked_fill,12,0,1,1,['Other']
81184,[MPS] Gardening spelling,36,0,2,3,['Minor']
81181,LICENSE file in the wheel package references files that are not included in the wheel,8,0,5,1,['Other']
81180,MPS: Placeholder tensor is empty!,52,1,1,2,['Other']
81178,Building with QNNPACK and FBGEMM disabled misses `packed_params.h` in `qlinear_serialize.cpp`,4,1,2,2,['Other']
81176,RuntimeError: CUDA error: no kernel image is available for execution on the device,2,0,2,0,['Other']
81161,Numpy API: concatenate(),67,0,4,4,['enhancement']
81152,land validation merged PR even though some trunk jobs failed,5,1,1,2,['Other']
81148,Concurrency limits for `ciflow/` triggered jobs are set incorrectly,0,0,4,1,['Other']
81138,hardshrink NaN behavior different in vectorized vs non-vectorized implementation,3,1,1,2,['Other']
81132,Transforms rotate doesn't work on 5D tensor,0,0,2,0,['Other']
81129,Transformer and CPU path with `src_mask` raises error with torch 1.12,7,1,6,4,"['Critical', 'Bug']"
81121,ONNX tests fail after torchvision update,100,2,4,3,['Other']
81118,TorchVision patch for PyTorch 1.12.1 minor release,19,0,1,1,['Minor']
81117,TorchText patch for PyTorch 1.12.1 minor release,19,0,1,2,['Minor']
81111,convolution forward over reverse internal asserts in specific case,2,1,6,4,['Critical']
81106,torchvision.transforms.functional.rgb_to_grayscale() + torch.nn.Conv2d() don`t work on 1080 GPU,5,0,5,3,['Other']
81099,Unable to get operator's information from traced graph node,0,0,0,0,['Other']
81096,[ONNX ] export | tensors spread across devices cuda and cpu,5,0,2,3,['Other']
81090,LayerNorm got wrong answer,2,0,5,2,['Other']
81082,DISABLED test_segfault (__main__.TestDataLoaderPersistentWorkers),160,0,3,4,['Bug']
81077,NaNs in torch.nn.MultiheadAttention output with certain params,67,1,6,2,['Other']
81068,FakeTensor doesn't normalize cuda and cuda:0,14,1,1,2,['Other']
81067,Add a check that tutorials are executing on build ,75,1,1,3,['Other']
81063,JIT Module serialization loses shape information,35,0,1,1,['Other']
81054, y.get_desc().is_nhwc() INTERNAL ASSERT FAILED,122,1,11,4,['Other']
81051,MPS runtime error when indexing from list / tensor,46,0,8,2,['Bug']
81050,[FSDP] Rename `transformer_auto_wrap_policy()`,134,0,2,2,['Other']
81039,CUDA-GCC version mapping for CUDA 11.4 ,29,1,3,4,['Other']
81037,Error Validating Libtorch Pod,26,1,2,2,['Bug']
81034,DISABLED test_partial_workers (__main__.TestDataLoader),161,0,4,4,['Other']
81027,Constraint check failed on parameter probs but not find any invalid values,2,1,5,2,['Other']
81026,torch.utils.bottleneck spams output and crashes,0,0,3,0,['Other']
81018,[primtorch] `torch.masked_fill` ref does not match eager's device promotion semantics.,28,0,3,3,['Other']
81016,pytorchbot revert report an error when reverts succeeds,0,0,1,3,['Bug']
80989,torch.onnx.export prim::Constant type and ONNX Expand input shape constraint not satisfied.,1,0,6,3,['Other']
80983,Copy does not work on empty subclassed tensors,4,1,0,2,['Other']
80979,TensorList Python Binding Encountering C++ TypeError,1,1,3,2,['Bug']
80953,ExpandedWeights fail on Conv3D,13,0,2,2,['Other']
80952,ExpandedWeights fails on LayerNorm if input doesn't require grad,13,0,2,2,['Other']
80949,ddp fails on NCCL,0,0,2,0,['Other']
80948,Weird warning using matrix exp for complex tensors,6,1,8,3,['Critical']
80947,[ONNX] Lossing Dropout layer when export pytorch model to onnx ,0,0,1,0,['Other']
80945,Why `sigmoid_()` do not take effect when applied to a indexed tensor? ,0,0,3,1,['Other']
80934,DISABLED test_comprehensive_linalg_pinv_singular_cuda_complex128 (__main__.TestDecompCUDA),172,0,2,5,['Other']
80933,DISABLED test_reload_jit_extension (__main__.TestCppExtensionJIT),162,0,4,3,['Other']
80931,python setup.py develop error,0,0,1,0,['Other']
80928,forward-over-reverse gives wrong gradgrad for `abs`,1,1,2,2,['Other']
80926,forward-over-reverse gives wrong gradgrad for `Softsign`,1,1,2,3,['Bug']
80924,gradcheck fails for `sgn` in forward-mode,3,0,2,2,['Other']
80923,[mergebot] merge -l double-comments,8,0,2,4,['enhancement']
80911,TorchScript interpreter codegen Failed,5,0,3,2,['Other']
80898,MPS cherry picks for 1.12.1,19,0,4,2,['Other']
80876,"[1.12] os.environ[""CUDA_VISIBLE_DEVICES""] has no effect",0,1,10,4,['Critical']
80872,[FSDP] `clip_grad_norm()` fails in `test_fsdp_core.py`,161,1,2,4,['Other']
80865,Custom TorchScript op causes duplicated TORCH_LIBRARY block,1,0,2,2,['Other']
80858,[composite compliance] torch.clone: not composite compliant for non-contiguous input with requires grad,2,0,3,2,['Other']
80856,Wrong conv2d output after using F.pad + mps,7,0,4,3,['Critical']
80853,"When I tried to use 'torch.nn.MaxUnpool3d', the following error occurred",141,1,4,3,['Bug']
80850,Mps Torch Stack Return Value,10,1,3,3,['Critical']
80848,[ROCm] rocblas.h file not found,20,0,1,2,['Other']
80846,Code not showing in Profiler tutorials,0,0,1,2,['Bug']
80845,Assertion error - _dl_shared_seed_recv_cnt - pt 1.12 - multi node,3,0,10,3,['Bug']
80844,MPS device neural net in validation gives the same results after n-th batch element,34,1,4,2,['Other']
80839,Reverse mode gives wrong gradient for `init.constant_`,3,0,1,4,['Other']
80838,BF16 didn't get speed up on A100,0,0,0,0,['Other']
80837,"Got ""RuntimeError: y.get_desc().is_nhwc() INTERNAL ASSERT FAILED""  while applying conv2d over a transposed tensor",106,1,2,2,['Bug']
80834,[ONNX] Missing support opset 17 operators,73,0,7,5,['Other']
80831,Pytorch 1.12.0 AttributeError: 'Adam' object has no attribute '_warned_capturable_if_run_uncaptured',1,0,5,4,"['Critical', 'Bug']"
80809,"assert not step_t.is_cuda, ""If capturable=False, state_steps should not be CUDA tensors.",0,0,13,0,['Other']
80802,Segmentation fault (core dumped),2,0,5,4,['Critical']
80800,MPS RuntimeError: view size is not compatible with input tensor's size and stride,88,1,8,2,['Bug']
80798,pytorchbot merge does not report an error when the merge workflow times out,128,1,4,3,['Bug']
80795,torch.arctan2() returns wrong value,8,0,6,5,['Critical']
80794,CTCloss suddenly appears nan,16,0,1,2,['Other']
80786,`torch.nn.functional.interpolate` parameter size for `scale_factor`,2,0,0,4,['Other']
80784,Operation 'abs_out_mps()' does not support input type 'int64' in MPS backend.,6,0,8,2,['Other']
80783,torch.onnx.export() error on ELU,0,0,1,0,['Other']
80779,Affine Grid,2,0,5,5,['Other']
80778,Running pytorch on Node js server is undiscribed.,1,0,1,0,['Other']
80772,c10d connectivity issues with Torchx,16,0,9,2,['Other']
80770,`xlogy` returns wrong gradient when `input` is 0,48,0,22,4,['Other']
80769,DISABLED test_worker_seed (__main__.TestDataLoader),166,0,4,4,['Other']
80766,Convolution overrideable missed transposed parameter,3,0,3,7,['Critical']
80764,Multiarch docker image,46,1,9,4,['enhancement']
80763,`acosh` has an incorrect complex derivative,3,0,4,3,['Other']
80757,DISABLED test_chain_iterable_style_dataset (__main__.TestDataLoaderPersistentWorkers),166,0,4,4,['Other']
80754,Fused graph module produced by CapabilityBasedPartitioner don't print their inner fusion groups,19,0,4,3,['Other']
80745,vision hash update failing,13,1,3,3,['Other']
80735,Commit 32fbeb1 introduced 7-10x slowdown for th.inverse on large batch matrices.,18,0,7,5,['Critical']
80733,share_memory() on CUDA tensors no longer no-ops and instead crashes in version 1.12.0,4,1,1,3,['Critical']
80732,[MPS] AdaptiveAvgPool2D doesn't accept input spatial size smaller than output shape,74,1,2,3,['Other']
80638,multiprocessing init_process_group based on gloo fails on Windows,48,0,3,3,['Other']
80635,MergeBot does not preserve authorship,0,1,4,4,"['Critical', 'enhancement']"
80637,PyTorch 1.12 cu113 wheels cudnn discoverability issue,11,1,8,2,['Other']
80599,PyTorch 1.12.0 weight_norm is not working with float16,0,0,3,8,['Critical']
80598,NotImplementedError: The operator 'aten::l1_loss_backward.grad_input' is not current implemented for the MPS device. ,4,0,2,2,['Bug']
80592,Illustration of LeakyReLU is wrong,7,0,3,2,['Other']
80589,`arange` returns incorrect results for certain values,6,1,2,3,['Other']
80576,Nvidia Jetson Xavier - fails to load image Python extension and Couldn't load custom C++ ops when drawing bounding boxes,3,0,5,2,['Other']
80569,[PyTorch 1.12] New release breaks `torch.nn.weight_norm` backwards pass and breaks all Wav2Vec2 implementations,7,1,44,5,['Critical']
80568,"Missed ""break"" statements in IListRef.h (line 385, 387, 399, 401) in IListRefIterator constructor and destructor",0,0,4,2,['Other']
80542,Support layout conversions via `Tensor.to(...)`,193,1,14,4,['enhancement']
80529,ROCm periodic jobs are timing out,29,0,4,2,['Other']
80527,[LTC] Add `Use` struct to track `Node` usage,0,0,2,0,['Other']
80524,Testing is slow due to GitHub outage,0,0,0,1,['Other']
80517,inference using wav2letter AM,0,0,1,0,['Other']
80508,`torch.ops.aten.where` failed to run with scalar inputs,1,1,2,4,['Critical']
80507,Forward AD mismatched stride when size = 0 becomes mismatched storage offset after slice,12,0,7,2,['Other']
80506,conflicts when installing pytorch on miniconda arm,0,0,2,0,['Other']
80505,C++ documentation: link to full API docs disappeared,21,0,6,4,"['Documentation', 'Critical']"
80500,[ONNX] Exported model errors when executed with onnxruntime,139,0,3,3,['Bug']
80499,"std() is incorrect on ""mps"" backend",1,0,1,3,['Other']
80493,DataLoader runs out of memory when `batch_size` >> `len(dataset)`  ,1,0,4,2,['Other']
80490,id() of buffer changes after model.to(),0,0,2,2,['Other']
80489,"CPU-only c++ extension libraries (functorch, torchtext) built against PyTorch wheels are not fully compatible with PyTorch wheels",13,0,15,5,['Critical']
80483,torch.arange for torch.float16,1,0,7,3,['Other']
80454,Functional version of torch.nn.LSTM -> torch.nn.functional.LSTM,29,0,11,3,['enhancement']
80441,torch.linalg.lstsq has confusing syntax highlighting in example,139,0,4,5,['Other']
80437,[RFC] Adding custom Metal kernel for mps ops requiring high performance,55,0,2,4,['enhancement']
80433,Fix the import of `Parameter` in `torch.nn.__init__.py`,8,0,1,3,['Other']
80430,**torch.load() requires model module in the same folder**  pytorch/pytorch#3678,0,0,0,0,['Other']
80426,Error while exporting traced torchscript model to tensorRT using torch_tensorrt,6,0,5,1,['Bug']
80413,DISABLED test_backward_T_cuda_float32 (__main__.TestCompositeComplianceCUDA),167,0,2,5,['Other']
80412,Cannot initialise torch.optim modules in torchscript,0,0,2,1,['Other']
80409,DISABLED test_fq_module_per_tensor (quantization.core.test_workflow_ops.TestFakeQuantizeOps),171,0,4,3,['Other']
80379,"[ONNX] ""Mostly allclose"" decorator for flaky test cases",83,1,2,3,['Other']
80373,test_shape_ops failed due to OOM on system with SRAM <=64G,2,0,2,3,['Other']
80361,Backwards compatibility job is frequently broken on unrelated PRs,15,1,0,2,['Other']
80343,Logging tensor may not log some kwargs as well as it should,0,0,2,0,['Other']
80317,DISABLED test_gradcheck_forward_ad_respects_requires_grad (__main__.TestAutograd),1,0,3,2,['Other']
80314,gradcheck jobs have multiple issues,38,0,18,7,['Critical']
80312,Linux docs are ooming intermittently,0,0,3,4,['Critical']
80310,Slow training of Efficientnet when updated to pytorch 1.10 from 1.8,1,0,3,5,['Bug']
80307,unable to save the model in TorchScript format?,25,0,1,1,['Other']
80306,LSTM Output Transposed w/MPS on 1.13 nightly build,10,1,7,2,['Other']
80304,Brevitas Trained Model Does Not Get Exported To ONNX,142,0,3,3,['Other']
80300,[ONNX] Only prim ops are allowed to not have a registered operator but aten::mul doesn't have one either,142,0,3,3,['Other']
80298,"If use Pandas and utils weight_norm, restarted Jupyter on Apple Silicon preview PyTorch",4,1,3,2,['Other']
80291,SequentialLR can raise bug when using pytorch_lightning,1,0,2,2,['Bug']
80290,Support LBFGS closures in torchscript,2,0,1,1,['Other']
80288,Bug with MPS at::native::prepare_matrices_for_broadcasting c10::Error: tensors must be 2-D,19,1,0,2,['Bug']
80287,Remove @infernece_mode from nested tensor tests,79,0,1,2,['Other']
80285,Bug in MPS permute for uint8,58,0,6,3,['Bug']
80281,Pytorch modeling with javascript,1,0,3,1,['Other']
80278,MPS strange warning,5,0,5,2,['Other']
80275,Inconsistent behavior and false warning for complex dtype `backward`,4,1,7,4,['Critical']
80249,DISABLED test_worker_seed_reproducibility (__main__.TestDataLoader),173,0,4,4,['Other']
80247,`ModuleInfo` skip logic is incorrect,13,0,0,3,['Other']
80246,Change the naming of pg/process_group to self,12,1,0,1,['Other']
80243,Change AllReduceCommHook to accept an instrusive_ptr,12,1,0,1,['Other']
80225,Hj,0,0,1,0,['Other']
80212,"Docker build fails with `no cmake or cmake3 with version >= 3.13.0 found""`",0,0,2,3,['Other']
80205,`rrelu` gives wrong gradient on cuda for particular inputs,11,0,0,5,['Critical']
80202,Sequential equivalence for RNG,11,0,3,3,['enhancement']
80201,trymerge workflow should do a better job showing progress,126,1,2,3,['Other']
80192,MPS incorrect behavior of torch.nn.functional.pad,18,0,3,5,['Other']
80165,[MPS] segmentation fault when multiplying two scalar tensors,5,0,7,3,['Other']
80158,Backpropagation not working on KL divergence loss function due to data type mismatch,11,1,2,4,['Other']
80155,Mask+Index Assignment Broken,2,0,3,2,['Other']
80153,Change `@pytorchbot merge` merged failed to Matched rule superuser to include all users,216,1,3,3,['Other']
80150,jit does not correctly script python enumerate ,6,0,1,1,['Other']
80141,rpc_init always enables CUDA if it's available,14,1,5,3,['Other']
80137,[torch::deploy] Cache line optimization in LoaderBalancer has negative effect to performance,21,0,7,3,['Other']
80133,Conversion of finetuned resnet50 (pytorch) to onnx (not the same results),144,1,9,3,['Other']
80130,ArrayRef length issue when export wav2vec model to onnx,1,0,1,1,['Other']
80129,create input tensor on GPU device takes extremely long time when inferencing with transformer models,4,0,2,2,['Other']
80127, an error happened in prediction on Android phone with torch mobile,0,0,2,0,['Other']
80125,DISABLED test_utils_compute_queue_depth (__main__.TestProfiler),1,1,2,3,['Other']
80119,The use of validation dataloader changes the train dataloader ,0,0,6,2,['Other']
80096,mergebot should notify of failure as soon as any required status fails,4,1,1,3,['Critical']
80079,Interpretation of torch.* functions to use primTorch refs in torch._refs fails for composition of nn.functional calls,2,0,0,2,['Other']
80062,Extra pings from mergebot when PR is closed are annoyng,0,0,0,0,['Other']
80047,Inference result is different between Pytorch and ONNX model when using an efficientnet architecture,146,0,2,3,['Other']
80041,nn.init will give different result if a tensor is contiguous,0,0,2,0,['Other']
80040,DataLoader traverse function doesn't work with `DataPipe` that is unhashable,25,0,2,2,['Other']
80039,[ONNX] Increase coverage of quantization operators,121,2,2,3,['Other']
80038,[ONNX] Remove spammy warnings,84,0,1,3,['Other']
80037,[ONNX] Fix test_pytorch_onnx_onnxruntime_cuda.py,69,1,0,3,['Other']
80034,XLA builds frequently fail during `download_and_install` step,47,1,17,4,['Other']
80029,PyTorch model converted to ONNX generates scatterNDupdate layers,146,0,5,4,['Other']
80027,`torch.matmul` does not work properly with tensor indexing,0,0,2,0,['Other']
80020,canUse32BitIndexMath not working properly in Conv2D layer,0,0,1,0,['Other']
80018,`USE_PRECOMPILED_HEADERS` is not supported on Apple M1,6,0,6,2,['Other']
80009,bug in mps tensor type conversion (uint8 -> float32),1,1,4,2,['Bug']
80006,mps bug in Sclising,14,0,5,2,['Bug']
80004,torch.ops.aten.stride doesn't have a default overload,145,0,5,2,['Other']
79992,[ci] Linux Docs is Running out of Memory (exit code 137),6,1,6,4,['Critical']
79963,Linkage of `void Lint(const AliasDb* db)` is internal,29,0,3,1,['Other']
79953,torch.argmin and torch.argmax behavior is not aligned with its documentation,0,0,1,0,['Other']
79951,Export to ONNX failure with mismatched devices,121,0,11,3,['Other']
79938,Implement ReLU for meta Tensor,4,0,6,4,['Other']
79934,Problems with inconsistencies in assignment operations,0,0,1,4,['Other']
79933,[Bug] D2H copy with a different dtype is pageable even with non_blocking=True,22,0,8,3,['Bug']
79914,mul_out_sparse_cuda creates invalid CUDA configuration arguments,7,1,1,2,['Other']
79907,"PR can not be merged/reverted, CircleCI jobs are not schedueld",0,0,2,2,['Other']
79892,Delete internal php code for viable/strict promotion,31,0,3,3,['Other']
79887,[FSDP] activation checkpointing errs out on T5 HF model,18,2,3,3,['Other']
79876,Change documentation to reflect CUDA 11.6 wheels inclusion ,7,0,2,4,"['Documentation', 'Critical']"
79871,"[bazel] cpp fronted `nn.linear->to(int)` throws exception, but Cmake tests pass",1,0,2,3,['Other']
79870,Error using JIT with internal pytorch function dataloader.py,1,0,1,2,['Bug']
79862,[QAT][quant] QAT training can't converge,105,1,6,2,['Other']
79859,Exporting the operator '::argsort' to ONNX opset version 16 is not supported,17,1,1,2,['Other']
79856,torch-1.13.0a0+git802efc9 Build failed from source,0,0,1,0,['Other']
79849,Bug while summing Boolean tensors on MPS device,0,0,2,0,['Other']
79841,Distributed Data Parallel +cuda.amp shows incorrect unused parameters for lstm with state burn-in,4,0,3,5,['Other']
79840,"Memory usage and iteration time increases indefinitely on Intel iMac 27"" with MPS",19,1,10,2,['Other']
79839,[ONNX] Internal assertion failure when export gpt2 model with `export_modules_as_functions=True`,93,1,8,4,['Other']
79835,Scalar add returns incorrect results for `int32` MPS array,6,1,7,6,['Critical']
79828,Distributed shared seed in DataLoader should be moved to cuda with NCCL Process Group,2,0,0,2,['Other']
79818,[primTorch] `test_python_ref_executor` often fails due to concrete arg mismatch,7,0,2,3,['Critical']
79813,torch.Tensor.to(memory_format=torch.contiguous_format) does not work properly.,125,0,5,3,['Other']
79812,Could not run aten::empty_strided with arguments from the 'PrivateUse1' backend,0,0,1,0,['Other']
79791,lite interpreted model performs differently in Python and Android,88,0,7,1,['Other']
79784,.backward() on MSELoss fails with IndexError: Dimension out of range on MPS,19,0,2,3,['Bug']
79781,onnx export with dict parameter problems,151,0,1,3,['Other']
79780,DISABLED test_binary_op_tensorlists_fastpath__foreach_add_cuda_bool (__main__.TestForeachCUDA),179,0,4,4,['Other']
79778,iSTFT length mismatch when center=False,21,1,1,2,['Other']
79776,DISABLED test_inherit_tensor (__main__.TestMultiprocessing),182,0,4,4,['Other']
79771,Linear not check shape,2,0,1,2,['Bug']
79748,"[forward ad] squeeze_, unsqueeze_ : the shape of the tensor was modified directly without going through the PyTorch dispatcher",5,0,2,2,['Other']
79738,Cuda 11.3 Pull and Periodic Jobs are Failing,0,0,0,1,['Other']
79735,Typo in nn.utils.parametrizations.orthogonal,3,0,1,3,['Bug']
79720,ChainedScheduler documentation typoo,0,0,1,0,['Other']
79716,DISABLED test_dispatch_meta__masked_amin_cuda_uint8 (__main__.TestMetaCUDA),5,0,3,1,['Other']
79714,DISABLED test_comprehensive__masked_amin_cuda_uint8 (__main__.TestDecompCUDA),0,0,1,1,['Other']
79712,DISABLED test_comprehensive__masked_amin_cuda_uint8 (__main__.TestDecompCUDA),5,0,2,1,['Other']
79711,test_dtypes__masked_amin_cuda is breaking with memory access issues,0,0,0,0,['Other']
79708,`backward(inputs=)` is not working as expected when inplace are involved (and grad() does work fine),48,1,5,5,['Critical']
79693,Does torch.utils.checkpoint support custom cuda operators,3,0,1,0,['Other']
79672,Tensor plus add result seems wrong [with Mac mps],20,1,2,2,['Other']
79670,FakeTensor doesn't work with `logical_not_()`,6,1,2,1,['Other']
79646,test_neg_conj_view_istft_cpu_complex128 fails on DEBUG=1,20,0,3,3,['Bug']
79630,Eradicate TestCase.setUp() calls in the code for super().setUp(),135,0,0,2,['Other']
79609,binary_cross_entropy_with_logits forward-over-reverse rule is silently incorrect,11,0,14,4,['Critical']
79605,"[FSDP] RuntimeError when using FSDP with auto wrap for sequence-to-sequence language models such as T5, Pegasus",40,0,13,2,['Bug']
79603,RuntimeError: CUDA error: an illegal memory access was encountered on RTX 3080 with enough memory,1,0,10,2,['Bug']
79601,Exporting the operator mode to ONNX opset version 12 is not supported,2,0,2,1,['Other']
79599,pytorch result not same as torchscript traced mod,0,0,0,1,['Other']
79594,Apply for Training Pytorch YOLOv5 by Apple M1 GPU,0,0,0,0,['Other']
79586,[LTC] `torch::lazy::Computation` to include a device,6,0,4,2,['Other']
79583,Torchscript Serialisation is broken for numbers over 1000 if global locale is set,6,1,31,3,['Other']
79540,TestModels_new_jit_API.test_inception is flaky,96,1,1,5,['Critical']
79531,torch.nn.CrossEntropyLoss output shape specification does not match behaviour,0,0,1,4,['Other']
79527,"torch.nn.BCELoss throws 'invalid axes' error when using ""mean"" or ""sum"" reduction on torch.device(""mps"")",2,1,1,3,['Bug']
79525,Enable `dim=None` for all reduction functions,45,1,3,2,['Other']
79519,Fix warning: cast from type ‘const char*’ to type ‘char*’ casts away qualifiers,0,0,1,0,['Other']
79513,"Torch FX return error ""`__cuda_array_interface__` must be a dict""",163,0,4,2,['Bug']
79512,Function to automatically calculate Conv shape,38,0,13,5,['enhancement']
79511,Suggest for a polynominal lr_scheduler,57,0,2,4,['enhancement']
79510,DISABLED test_checkpoint_wrapper_parity (__main__.CheckpointWrapperTest),188,1,5,4,['Other']
79509,DISABLED test_noncontiguous_samples_nn_functional_conv_transpose3d_cuda_float32 (__main__.TestCommonCUDA),15,1,3,5,['Critical']
79501,Different results between batched and one by one inference of nn.GRU,0,0,1,3,['Other']
79496,"Random number generation yields different values on different devices, despite the same manual seed.",0,0,1,4,['Other']
79495,How to stacked RGB images,0,0,2,0,['Other']
79485,Move OptionalHasElement/If tests from no_runtime to runtime,0,0,0,0,['Other']
79483,Can not export pytorch model to onnx.,154,0,1,3,['Other']
79461,Validate ONNX 1.12.0 release candidate,2,1,3,3,['Other']
79460,Adding python bindings for `SymInt`,50,1,0,2,['Other']
79449,UnboundLocalError: local variable 'ws' referenced before assignment,0,0,3,2,['Bug']
79447,Update autograd engine to support nested tensors,3,0,1,3,['Other']
79419,Pytorch for PPC64LE,1,0,2,0,['Other']
79415,torch.nn.modules.pooling return_indices and ceil_mode reversed,0,0,1,2,['Other']
79410,BUG: Segmentation fault when calling pytorch function after np.exp (numpy 1.21.2),198,0,3,2,['Bug']
79405,nesterov in SGD,0,0,2,1,['Other']
79402,Performance drops after running tensor multiplication for 15 seconds on M1 MAX (Pytorch MPS).,2,2,5,3,['Other']
79394,Einsum producing inconsistent results to sum(),0,0,1,1,['Other']
79384,"torch.load() fails on MPS backend (""don't know how to restore data location"")",1,1,4,3,['Other']
79361,[ONNX Export] Interpolation likely should be exported with `half_pixel` instead of `pytorch_half_pixel`,12,0,2,4,['Other']
79358,MSVC: vec_base size template fails with divide by sizeof(scalar_t),113,0,2,2,['Other']
79347,Cannot install Torch,3,0,3,0,['Other']
79346,`torch.gradient` need to check only dims specified by user and not all input tensor's dims,4,0,6,1,['Other']
79338,Adamw cannot set different lrs to different parameters,0,0,0,0,['Other']
79332,How to reimplement same behavior in AdaptiveAvgPooling2D,3,0,2,0,['Other']
79323,[build] push containers used for PyTorch build in CI to GitHub container registry,26,0,2,2,['Other']
79321,Using a Subclassed Tensor Results in Significant Decrease in Training GPU Throughput,218,0,9,3,['Other']
79304,[bazel] basic cuda tensor creation is getting program stuck,7,0,2,2,['Other']
79293,Make MPS test workflow correctly report test stats,158,1,6,3,['Other']
79286,MPS device: Invalid type casting,4,0,3,2,['Other']
79283,OOM Issues despite plenty of resources on M1 Mac,115,2,5,4,['Other']
79279,Support float tensors as float inputs,133,1,13,4,['Other']
79274,pip install failure,1,0,7,3,['Critical']
79270,float32 matrix dot product has different precision in CPU/GPU,1,0,3,2,['Other']
79268,type convert error,0,0,1,0,['Other']
79266,[Docs] The source links in `torch.testing` docs broken,31,0,0,2,['Other']
79262,[Bug Report]Unexpected result torch.abs(x - y) >= 0 while x == y,0,0,1,2,['Bug']
79260,cpu-libtorch1.11 can not load  gpu-libtorch pt-model ,0,0,1,0,['Other']
79259,[ZeRO] `test_zero_model_parallel()` failing silently since not run in CI,3,1,2,2,['Other']
79241,Remove the construction of unused tensors,3,0,0,2,['Other']
79218,"[bug] `TensorIterator` segfaults when inputs broadcast over output, and output is at least 2 dims larger than inputs.",102,0,11,4,"['Bug', 'Critical']"
79204,Support generating noncontiguous CUDA tensors using make_tensor for chalf,0,1,0,4,['Critical']
79200,MPS backend support issue for int64,5,0,1,2,['Other']
79190,Compilation failure seen on 1.12 rc2 when trying to use pretty_print_onnx function,12,0,2,1,['Other']
79182,Integrate run_android_tests.yml into trunk workflow,29,1,7,2,['Other']
79181,MPSNDArray Error: buffer is not large enough,5,0,3,3,"['Critical', 'Bug']"
79179,ONNX tests intermittently ooming on master,9,1,1,4,['Other']
79161,Support more granular test decoration,209,0,4,2,['Other']
79153,update xla hash is flaky,0,1,0,1,['Other']
79146,Pin PyTorch nightly used for comparison in BC test,6,1,5,3,['Other']
79142,DISABLED test_dcgan_models (jit.test_models.TestModels),190,0,4,3,['Other']
79135,Quantization Aware Training API Example Not Up to Date,22,1,1,1,['Other']
79134,Figure out our memory management story for SymInts,55,0,1,2,['Other']
79116,  libtorch are incompatible with gperf,19,0,1,2,['Other']
79114,[RFC] FSDP communication hook,20,2,1,2,['Other']
79112,`cumsum` op: pytorch failed to run GPT-2 model in M1's MPS device,118,1,2,2,['Other']
79106,How to find the code in '...'?,5,0,1,2,['Other']
79085,Type mismatch errors in an autocast-enabled region,0,0,1,0,['Other']
79081,[AUTOGRAD] Switch InputMetadata to using `SymInt`s,56,1,0,2,['Other']
79079,isTensorSubclassLike is returning `true` when it isn't supposed to,1,0,6,4,['Critical']
79055,[CI] Flaky initialization of OMP,145,1,1,2,['Other']
79048,Explore add NestedTensors to CompositeImplicitAutograd / CompositeExplicitAutograd dispatches,78,0,3,2,['Other']
79046,Codgen multiple derivatives from derivatives.yaml,68,1,1,3,['Other']
79044,Add operator and derivative coverage for nestedtensors,48,0,1,3,['Other']
79043,[DDP] #77809 breaks broadcasts for channels_last tensors,1,0,1,2,['Other']
79040,Update Autograd to be more shape agnostic,6,0,0,3,['Other']
79035,[ONNX] CI does not catch an error in `to_device`,139,1,5,4,['Bug']
79023,Fix overload resolution for SymInt[] and int[] in python_arg_parser.cpp,56,0,2,2,['Other']
79022,python test/run_test.py,130,1,4,3,['Other']
79019,Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead,1,0,1,2,['Other']
79009,Vectorized fmod on CPU computes wrong result,6,0,2,2,['Other']
79005,[ONNX] scatter_add result is wrong in ONNX model,0,0,3,4,['Other']
78982,DISABLED test_exception_single (__main__.SpawnTest),191,0,4,4,['Other']
78975,test_fsdp_pure_fp16 test breaks when using more than 5 GPUs (1.11 and 1.12),115,1,3,2,['Other']
78951,Fully decommission grafana (metrics.pytorch.org) for hud.pytorch.org/metrics,226,2,5,2,['Other']
78940,[bot] Improve mergebot logging,148,0,1,3,['Other']
78925,[Python 3/Pytorch] Error on Fine-tuning BERT for question answering -> RuntimeError: Overflow when unpacking long,0,0,2,0,['Other']
78923,Need to support kwargs in nvfuser python API integration,15,0,1,4,['Other']
78916,[Device MPS] Error: buffer is not large enough. Must be 19200 bytes,119,2,9,3,"['Bug', 'Critical']"
78903,Backward for Root of Complex Zero Failed with NaN,1,0,4,5,['Other']
78893,NVIDIA GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation. The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.,0,0,10,0,['Other']
78889,Possible support of mean operation on bool Tensor,1,0,2,0,['Other']
78886,Slicing with step does not work correctly with MPS backend,31,1,3,4,['Critical']
78879,Elementwise multiplication between MPS float32 and int Tensors result in LLVM error,11,1,2,4,"['Critical', 'Bug']"
78874,Swapping strided data between channels produces wrong result,2,0,1,1,['Other']
78872,Functionality that utilizes all GPU devices on a local PC,2,0,1,0,['Other']
78869,`mean` will trigger INTERNAL ASSERT with input requiring grad on cuda,1,0,1,0,['Other']
78868,"`adapative_{avg, max}_pool` will crash in the backward pass on cuda on empty output size",192,0,2,9,['Critical']
78867,`kl_div` will crash in the backward pass on cuda,30,1,7,6,['Critical']
78855,Inconsistent behavior of fmod,0,0,1,0,['Other']
78852,[ONNX] Some functions do not preserve shape for scalars,81,0,2,3,['Other']
78844,ONNX test flake on master,3,0,3,3,['Other']
78840,[collect_env] collect_env python < 3.6 incompatibility ,4,1,5,3,['Other']
78830,rebase bot suggested command is incorrect for ghstack,0,1,0,0,['Other']
78807,functionality mis-match for _multi_tensor_adam and _single_tensor_adam,67,1,12,4,['Critical']
78798,"When Shuffle is True, Get Data from the Workers of DataLoader's Iterator Randomly Rather Than One by One",6,0,6,2,['Other']
78791,`keepdim` not ignored in torch.argmin when `dim=None`,3,0,2,3,['Other']
78787,torch.jit.script matches wrong version of repeat_interleave,6,0,0,2,['Other']
78768,DISABLED test_output_unused_in_loss_tuple_module (__main__.TestDistBackendWithSpawn),0,1,1,3,['Other']
78745,Wrong import in datasets documentation,1,0,1,0,['Other']
78732,[CI] Do parallelnative builds need gcc5.4?,0,1,0,2,['Other']
78731,torch.utils.checkpoint (reentrant-based) does not appear to reduce peak memory?,0,0,2,3,['Other']
78728,Make `torch.Library` (Python Registration) work with torchdeploy,179,0,11,4,['Critical']
78711,GRU output dim issue,11,0,2,4,['Other']
78705,fx proxy retracing example is incorrect,48,0,1,2,['Other']
78694,[ONNX] Refactor the patching process to make it more transparent to users,166,0,2,3,['Other']
78687,nightly docs build failing with katex not found,0,1,3,2,['Other']
78675,Structured kernel input error checking ,2,0,1,2,['Bug']
78659,Nightly pytorch linux builds no longer contain git_version,0,0,2,4,['Critical']
78642,Expanded view does not correctly transfer to MPS device,1,0,2,2,['Other']
78622,backward(create_graph=True) causes a warning for potential memory leak,2,0,3,2,['Other']
78620,[CI] slow gradcheck CI test has been timing out since 5/31,64,2,9,5,['Critical']
78613,[primTorch] prims.cat does not error for different dimensional tensors with TensorMeta,90,2,1,2,['Bug']
78608,Add forward prefetching option in FSDP API,14,1,0,2,['Other']
78607,Return original module when fsdp wrapped model call .module,1,1,0,2,['Other']
78580,Reland use of weakref for nn.Module hooks,27,0,0,4,['Critical']
78565,Make Constructors Automatically Apply no_dispatch,34,0,1,2,['Other']
78551,Error while loading model weights to mps device,16,0,6,2,['Bug']
78549,https://github.com/pytorch/pytorch/pull/74944 breaks CUDA graph capture,2,1,2,5,['Critical']
78540,linux-focal-py3.7-gcc7-mobile-lightweight-dispatch-build frequently ooms,45,1,18,2,['Other']
78539,Rebasing with bot doesn't work with ghstack,0,1,0,2,['Other']
78534,Adding support for unsqueeze to fake tensors,0,1,6,3,['enhancement']
78531,Connection closed by peer when using `distributed` on different machine,1,0,4,1,['Other']
78514,`dist.isend` cause connection closed in `gloo`  backend,0,0,3,1,['Other']
78512,torch.nn.Sequential can use `+` (add operator) to concatenate,41,0,14,4,['enhancement']
78511,MPS matrix multiplication fails on a permuted tensor without `contiguous`,3,0,2,2,['Other']
78510,[TorchData] Allow random_split to use percentages when applied to map-style datasets,15,0,4,2,['Other']
78506,[TorchData] Add missing `raise` keyword,3,1,2,2,['Other']
78505,ONNX operator parameters being set as input nodes,31,1,5,3,['Other']
78499,Latest nightly can not be imported using Python-3.7.0,6,0,3,2,['Critical']
78497,"torch.embedding raise ""CUDA error: invalid device function"" when running scripted ",0,0,2,0,['Other']
78492,"MPSNDArray.mm:782: failed assertion `[MPSNDArray, initWithBuffer:descriptor:] Error: buffer is not large enough. Must be 20480 bytes '",1,0,4,2,['Bug']
78474,Exception when loading images to 'mps' devices,46,0,3,2,['Other']
78472,13% performance regression in MPS since d63db5234,2,0,4,2,['Other']
78470,"lt is likely that your environment is messed up. As you can see from the traceback, there are two python environments involved here:",164,0,2,2,['Other']
78453,"[bazel] ""Deleting stale sandbox base"" on any code modification",3,0,3,2,['Other']
78445,permute returning unexpected results on MPS devices,33,1,3,2,['Other']
78431,[typing] distributions.kl_divergence return type is Tensor but not annotated ,13,0,0,2,['Other']
78429,torch.nn.LayerNorm() does not work in nightly build of Accelerated PyTorch Training on Mac,10,0,4,3,['Other']
78425,[CI] Enable LGTM's pull request bot,88,0,5,2,['Other']
78420,Pip install failure (THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE.) Hashes different on each install,2,0,2,0,['Other']
78415,New ONNX Optional support doesn't work in some use cases,150,0,2,3,['Other']
78412,OOM error when converting tensor to numpy array Pytorch,4,0,5,3,['Bug']
78399,Improve auto_wrap_policy documentation,4,1,0,3,['Documentation']
78398,Should we test Gloo with TLS in CI?,61,0,2,2,['Other']
78391,[ONNX] way to write an opset_version-dependent symbolic function for autograd.Function,147,0,7,3,['Other']
78389,[primTorch] fmod tests fail on CPU with bfloat16,115,0,0,2,['Other']
78375,macos build time increased significantly after runner update to macos-12,18,2,10,3,['Other']
78365,How to calculate the gradient of the previous layer when the gradient of the latter layer is given?,4,0,2,0,['Other']
78363,torch.linalg.inv gives incorrect results for any index besides zero on M1/mps GPU device,36,1,3,3,['Critical']
78362,Numerous builds/tests are broken by protobuf update,0,0,4,3,['Critical']
78355,`gradgradcheck` misses shape mismatch in OpInfo tests for some loss functions with custom double backward implementation.,5,0,3,4,['Critical']
78348,RuntimeError: input_shape_value == reshape_value || input_shape_value == 1 || reshape_value == 1INTERNAL ASSERT FAILED,6,1,8,3,['Bug']
78347,Torchscript executing static graph with different shaped tensors inputs does not trigger recompilation (retracing),1,0,0,1,['Other']
78343,"MPS backend built, but not available",0,0,3,0,['Other']
78342,`_get_analytical_jacobian_forward_ad` cannot compute gradient for `nn.MaxPool`,0,0,1,0,['Other']
78341,RuntimeError: Numpy is not available,0,0,3,0,['Other']
78336,[ONNX] Add `__all__` to `torch.onnx`,21,1,0,3,['Other']
78331,`torch.load` does not propagate `map_location` arg to `torch.jit.load`,19,0,1,1,['Other']
78328,Code coverage?,5,0,3,0,['Other']
78311,Show parameter types in function signatures,5,0,2,3,['Other']
78308,Move test/onnx/test_onnx_export.py into test_pytorch_onnx_no_runtime.py,19,1,0,3,['Other']
78301,The example for Torch.log is not very useful (all nan),71,0,2,2,['Other']
78295,Why does the cpp docs build take so long?,156,1,5,3,['Other']
78290,[doc] asarray is uglily formatted,5,1,2,3,['Other']
78289,DISABLED test_backward_per_channel (quantization.core.test_workflow_ops.TestFakeQuantizeOps),0,0,3,1,['Other']
78288,DISABLED test_qconv_transpose2d (quantization.core.test_quantized_op.TestQuantizedConv),0,0,2,2,['Other']
78283,MobileProfiler.Backend test is flaky,7,1,6,2,['Other']
78277,[FSDP][BE] Refactor unit tests to use a few canonical models,128,1,1,3,['Other']
78275,Large numerical errors in torch.einsum and torch.matmul on A40 GPU,0,0,3,1,['Bug']
78264,torch._validate_sparse_bsr_tensor_args fails on non-trivial block size cases,5,1,1,2,['Bug']
78263,Functional API for FileLister,12,0,0,2,['Other']
78256,"Forward over reverse does not work for sub for inputs (compex, float)",57,0,2,3,['Other']
78490,"Initializing libiomp5.dylib, but found libomp.dylib already initialized.",43,1,18,5,['Other']
78252,Discrepancy in the dimension wrapping error message and type,7,1,1,2,['Bug']
78251,Python warnings printed repeatedly from JIT in libtorch,8,0,1,1,['Other']
78250,Crash with ParameterList and device='meta',6,1,2,4,['Critical']
78247,MPS convolution crashing on .expand kernel (non-contiguous),5,0,2,2,['Critical']
78243,I find that the picture has some errors?,13,0,2,2,['Bug']
78242,pytorchbot revert reason validation is confusing,7,1,8,2,['Other']
78240,`xlogy` fails to backward,0,0,2,3,['Other']
78236,WeightedRandomSampler does no shape checking,8,0,1,2,['Other']
78233,some error with pth export onnx,149,1,10,4,['Bug']
78229,DISABLED test_ddp_shared_grad_acc_unused_params (__main__.TestDistBackendWithSpawn),9,1,2,3,['Other']
78207,Problem running TorchScript models with batch normalization from old versions,141,0,6,1,['Other']
78206,Deprecate `TSNodeLoweringInterface`,6,0,3,2,['Other']
78188,torch.jit.script gives a RuntimeError for a custom MaskRCNN model,0,0,3,1,['Bug']
78182,XLA tests have high time-to-signal,65,1,19,3,['Other']
78178,torchgen is in a half complete state in PT 1.12,16,1,6,2,['Critical']
78176,[GH1] trymerge should not cancel without warning developers,2,0,0,2,['Other']
78175,[GHA] [CI] Strengthening Rockset Test Reporting Dependencies,15,0,1,2,['Other']
78168,MPS 16Bit Not Working correctly,133,1,16,2,['Other']
78152,`gelu` will backward crash,112,1,7,8,['Critical']
78149,`gather` backwards crash,11,1,1,3,['Critical']
78140,backward error for sum of vector norm,2,0,2,3,['Bug']
78138,Upload Test Stats fails when parsing test reports,16,0,1,2,['Other']
78123,Segfault in choose_qparams_optimized,184,0,0,2,['Bug']
78119,Move Optional tests from test_pytorch_onnx_no_runtime.py to test_pytorch_onnxruntime.py ,98,1,2,3,['Other']
78117,FX graph mode quantization generic support for kwargs,47,1,1,2,['Other']
78110,[mps] randn is a lie,0,0,1,0,['Other']
78107,[MPS] The value comparison result of tensor on mps device is incorrect ,4,0,1,2,['Other']
78100,Bazel build is very flaky,56,2,11,2,['Other']
78099,Torch SVD computation on mps has a large error compared to cpu,92,0,3,3,['Bug']
78095,pytorchbot rebase doesn't work for forked PRs,0,1,2,2,['Other']
78091,MPS: No conversion of Tensor datatype possible,1,0,0,4,['Critical']
78089,[ONNX] Run vision's test_onnx.py in the PyTorch CI,28,0,2,5,['Other']
78087,`bilinear` triggers INTERNAL ASSERT FAILED when input requires grad,8,0,3,2,['Other']
78077,test_expanded_weight_per_sample_grad does not work with unbatched sample,45,1,0,3,['Other']
78074,Slice operator on tensor generates wrong results on 'mps' device,44,0,3,2,['Other']
78060,"Can't convert nn.multiheadAttetion(q,k,v)  to Onnx when key isn't equal to value",18,0,7,4,['Other']
78058,[primTorch] prims are being checked as part of the BC check,4,0,1,3,['Critical']
78054,[primTorch] many primTorch test xfails are due to chalf,1,0,2,4,['Other']
78048,Segmentation fault after permute on MPS,9,0,1,3,['Critical']
78043,Non-contiguous tensor fails on MPS backend for `.cat` and `.stack` ,10,0,3,2,['Other']
78042,Device MPS: -> RuntimeError Placeholder buffer size is not large enough to contain the Tensor storage of size,1,0,7,2,['Bug']
78022,TORCH_DISTRIBUTED_DEBUG should print the expected CollectiveFingerPrint,38,1,4,4,['Bug']
78020,MPS: crashes and strange behavior with `bool` Tensors,40,1,2,2,['Critical']
78019,MPS: `log` and `exp` not working for integer Tensors,19,0,1,2,['Other']
78017,DISABLED test_error_workers (__main__.TestDataLoaderPersistentWorkers),207,0,6,4,['Bug']
78009,`torch.normal` on MPS backend creates the same output Tensor every time for identical shape,4,0,1,2,['Other']
78005,[v.1.12.0] Release Tracker,40,0,58,2,['Other']
78003,CosineAnnealingLR: LR stuck at 0 after re-initializing scheduler,4,0,5,4,['Critical']
78001,MPS backend has problems with printing non-contiguous tensors,20,0,15,2,['Other']
77992,DISABLED test_ddp_control_flow_different_across_ranks (__main__.TestDistBackendWithSpawn),14,1,3,4,['Other']
77988,MPS add incorrectly,0,0,1,0,['Other']
77980,Implement an E2E prototype to integrate with PytorchAOTAutograd,74,1,1,2,['Other']
77979,ONNX export with InstanceNormalization module fails on ONNX DML runtime if use_input_stats is not false,6,0,1,3,['Other']
77977,CPU fallback for `aten::index.Tensor` on MPS crashes or gives wrong result,94,0,3,2,['Critical']
77976,DISABLED test_Conv2d_groups_nobias (__main__.TestNN),5,0,3,1,['Other']
77974,Invalid shape from `at::native::math_native_layer_norm`,0,0,1,0,['Other']
77960,"expected key in DispatchKeySet(CPU, CUDA, ....) but got: MPS",0,0,1,0,['Other']
77959,MPS not implemented for aten::index.Tensor,94,0,2,2,['Other']
77958,`transpose` crashes on mps device,4,0,2,2,['Critical']
77957,`assert_close` crashes when comparing to inf or nan on mps device,3,1,3,2,['Critical']
77956,NotImplementedError: Could not run 'aten::_slow_conv2d_forward' with arguments from the 'MPS' backend,0,0,2,0,['Other']
77954,Doc bug about torch.linalg.inv,31,0,10,3,['Bug']
77952,`multilabel_margin_loss` returns different results with the same input twice in cuda,12,0,1,3,['Other']
77944,DISABLED test_mm_cuda_float64 (__main__.TestSparseCSRCUDA),0,0,1,5,['Critical']
77942,Bug: CUDA softplus doesn't use opmath,1,0,0,3,['Bug']
77938,"1.12 on M1 Pro Chip not using all the CPU cores. (device=""cpu"")",0,0,3,0,['Other']
77932,[primTorch] Feature Request: out-of-place fill,230,0,5,3,['enhancement']
77931,convolution operator not implemented for mps device,139,1,13,3,['Other']
77920,TensorList out= ops alias annotations aren't plumbed properly into `torch.ops.aten,96,0,1,2,['Other']
77909,Supper `DimensionNode::isDynamic()` API via `lazy::Shape::is_symbolic()`,53,1,3,2,['Other']
77908,Move C++/Python Storage bindings out of `torch/csrc/generic`,4,1,0,2,['Other']
77898,Segmentation fault in lu_unpack,133,0,8,4,['Critical']
77897,Floating point exception in group_norm,2,0,6,0,['Other']
77896,Segmentation fault in fused_moving_avg_obs_fake_quant,5,0,1,2,['Other']
77895,Floating point exception in cross_entropy_loss,14,0,3,4,['Other']
77892,Segmentation fault in _fused_moving_avg_obs_fq_helper,6,0,2,3,['Other']
77891,Segmentation fault in _fft_r2c,19,0,1,5,['Critical']
77890,Segmentation fault in _fft_c2r,19,0,2,3,['Other']
77889,Segmentation fault in _compute_linear_combination,3,0,5,2,['Other']
77886,buffer is not large enough when running pytorch on Mac M1 mps,66,0,33,3,['Other']
77885,Add meta device support for Storages,8,1,0,3,['Other']
77882,`SymInt` to support `-1` as a concrete `int`,0,1,2,1,['Other']
77874,RuntimeError while loading model with MPS device,138,1,13,2,['Bug']
77871,`linux-bionic-cuda10.2-...` builds are broken,0,0,2,1,['Other']
77867,Issue on OS X Monterey Building PyTorch with Support for Apple Metal,12,0,26,5,['Other']
77851,`MPSNDArray` or `MPSGraphTensorData` allocated with wrong size,12,0,11,2,['Other']
77849,Conversion from int to float dtype is not working on MPS device,4,0,3,3,['Critical']
77845,ONNX export of torch.rand produces different data type,25,0,0,3,['Other']
77843,Running MPS model crash '_mtlIOGPUCommandBufferStorageRebaseShmemHeader',95,1,5,3,['Critical']
77835,"tensor([bool], device='mps:0').type(torch.float) returns different values when using 'mps' device and 'cpu' device",0,0,1,0,['Other']
77833,When will the amd gpu version for mac be released？,6,0,4,4,['Other']
77831,Add support for `expand` in LazyTensor shape inference,40,1,0,2,['Other']
77829,Tensor will become all zero on MPS after switching to other softwares,6,0,6,3,['Critical']
77827,[FSDP] Pre-Branch Cut Docs Fixes,0,1,0,2,['Other']
77819,torch.baddbmm fails on Apple M1,1,0,3,2,['Other']
77817,Could not run 'aten::amax.out' with arguments from the 'MPS' backend.,13,0,2,2,['Other']
77811,qnnpack cannot be built on Apple M1 and is disabled,13,0,10,4,['Other']
77797,NotImplementedError: Could not run 'aten::eye.m_out' on MPS,12,0,5,2,['Bug']
77794,NotImplementedError: Could not run 'aten::index.Tensor' on MPS,95,0,15,3,"['enhancement', 'Bug']"
77781,TypeError: Trying to convert Double to the MPS backend but there is no mapping for it.,4,0,6,3,['Bug']
77776,NotImplementedError: Could not run 'aten::amax.out' with arguments from the 'MPS' backend.,13,0,2,2,['Bug']
77769,DISABLED test_bulk_loading_nobatch (__main__.TestDataLoaderPersistentWorkers),211,0,4,4,['Other']
77766,Error when building with USE_DISTRIBUTED=0,0,1,3,4,"['Critical', 'Bug']"
77754,Some operation are not implemented when using mps backend,14,0,11,3,['enhancement']
77753,Memory usage and epoch iteration time increases indefinitely on M1 pro MPS,2,0,21,2,['Other']
77750,Error when comparing MPS tensors,10,0,4,3,"['Critical', 'Bug']"
77748,YOLOv5: MPS on Macbook Air M1 NotImplementedError: Could not run 'aten::empty.memory_format' with arguments...,5,0,13,2,['Bug']
77732,multiprocessing: how to put a model which copied from main thread in the shared_queue,35,1,9,2,['Other']
77730,Documentation bug for torch.as_strided,13,0,0,3,"['Bug', 'Documentation']"
77723,DISABLED testAddSubFallback (__main__.TestLazyReuseIr),208,0,3,3,['Other']
77722,DISABLED testAdd (__main__.TestLazyReuseIr),208,0,2,3,['Other']
77721,DISABLED testAddSub (__main__.TestLazyReuseIr),208,0,3,3,['Other']
77718,DISABLED test_dispatch_meta_angle_cuda_complex32 (__main__.TestMetaCUDA),0,0,1,1,['Other']
77717,DISABLED test_meta_angle_cuda_complex32 (__main__.TestMetaCUDA),0,0,1,1,['Other']
77711,"Single Line Fix needed in old pull request, I'm not a contributor",1,1,2,0,['Other']
77709,[NVFuser] Testing for on-by-default,85,0,1,2,['Other']
77704,AttributeError during import after building with `USE_DISTRIBUTED=0`,0,0,3,4,"['Critical', 'Bug']"
77688,CI should check that all operators in torch._refs have ReferenceOpInfo,8,0,0,3,['Other']
77687,PrimTorch's test_ops.py reference_consistency testing is worse than test_decomps.py testing,5,0,6,3,['Other']
77679,[ONNX] Separate tests for mutating model/argument,156,0,1,3,['Other']
77678,[ONNX] Run pytest parallelly in CI,15,1,1,2,['Other']
77671,[ONNX] Exporting the operator prim::type to ONNX opset version 16 is not supported.,152,1,1,2,['Other']
77641,[quant] [fuse_modules] fuse_custom_config_dict is hard coded to None,6,0,1,2,['Other']
77629,`torch.cross` fails to backward unexpectedly,98,0,1,2,['Other']
77619,DISABLED test_conv_bn_folding_autocast_scenario_cuda (jit.test_freezing.TestFrozenOptimizations),0,0,2,3,['Other']
77618,DISABLED test_conv_bn_folding_autocast_scenario_cuda (jit.test_freezing.TestFrozenOptimizations),16,1,3,3,['Other']
77603,Probable typo in torch.package code and docs,0,0,0,2,['Other']
77600,torch.to() does not preserve stride permutation,1,0,0,3,['Other']
77599,DISABLED test_multiprocessing_contexts (__main__.TestDataLoaderPersistentWorkers),213,0,4,4,['Other']
77594,Can't make the C++ implementation of pytorch ,6,0,3,1,['Other']
77575,Segmentation fault during torch::jit::load,17,0,1,1,['Other']
77573,Segmentation fault in torch::jit::Unpickler::readInstruction(),17,0,1,1,['Other']
77565,Assigning parameter to tensor doesn't pass gradient info,15,1,4,2,['Other']
77563,Exception out_of_range uncaught during torch::jit::load(),17,0,1,1,['Other']
77562,"[FSDP] - collective operation timeout (AllGather,Reduce) results in 5/5 training runs crashing at end of training loop (epoch 6+)",7,2,9,3,['Critical']
77561,Unhandled std::out_of_range exception in torch::jit::load(),17,0,1,1,['Other']
77554,`dist.recv` got wrong elements when sending linalg results,3,0,3,4,['Critical']
77553,[primTorch] elementwise CPU strides are incorrect,255,0,1,4,['Other']
77545,assert_equal in torch/testing/_comparison.py doesn't give helpful error messages,0,0,2,0,['Other']
77533,Support serialization of BFloat16 tensors for HPU,16,0,0,2,['Other']
77532,"`out = gather(x @ x, sparse_grad=True); out.sum().backward()` fails as `matmul` does not work with sparse gradients for dense inputs.",36,0,7,4,['Other']
77528,Preinstalled torch binary does not match NVIDIA driver in Google Colab,0,0,2,0,['Other']
77526,[primTorch] Strides for complex abs are incorrect,1,0,2,4,['Other']
77522,Multi-process data loading with iterable dataset,0,0,3,0,['Other']
77511,SegFault after average pooling quantization,25,0,6,1,['Bug']
77509,`bazel query //...` errors out,22,0,0,2,['Bug']
77507,bfloat16 group_norm on CPU does moments calculation in bfloat16,87,2,6,2,['Other']
77501,Use type hints (PEP 484) in generated documentation,23,0,2,2,['Documentation']
77498,inverse strides are not consistent with transposition when zero-sized,101,0,2,3,['Other']
77497,`_get_analytical_jacobian_forward_ad` skip check of NotImplementedError,3,0,6,4,['Bug']
77494,Option to Supress ONNX warnnings,22,1,1,3,['Other']
77487,Cannot import 'torch' due to Circular import,38,0,2,2,['Other']
77482,TorchScript doesn't support tuple including None type as function return variable,19,0,1,1,['Other']
77481,switch-break problem in 'aten/src/ATen/core/IListRef.h' of debug version libtorch.,55,0,2,2,['Bug']
77472,logsumexp out variant raises RuntimeError: value cannot be converted to type int64_t without overflow,0,1,1,1,['Bug']
77461,[FSDP] Optimize sharded_state_dict saving and loading performance,159,0,1,1,['Other']
77455,RuntimeError on ONNX export of `fake_quantize_per_tensor_affine`,136,1,8,4,['Bug']
77447,Forward AD for rrelu_,68,0,4,3,['Other']
77445,`torchgen` relies on non-packaged `native_functions.yaml`,37,1,14,2,['Other']
77441,"Circular import issue with torch, torchvision, and onnx",0,0,6,0,['Other']
77432,PyTorch master OSS build not working on Mac OS,20,0,1,2,['Other']
77420,"Different behaviors when using torch.jit.trace, torch.jit.script, @torch.jit.script, and ONNX ",185,0,5,3,['Other']
77417,[question]Use libtorch 1.10.2+cu102 vs libtorch 1.9.0+cu102,0,0,1,0,['Other']
77412,Typo in torchgen/model.py,5,0,0,3,['Bug']
77406,Differing behavior between CUDA and CPU for index_put,0,0,1,3,['Other']
77399,[GHA] `sudo apt-get -y install doxygen` sometimes fails in docs builds,11,1,0,3,['Other']
77394,"MPS backend: native_functions cleanup for functions mps_linear, mps_max_pool, mps_lstm and mps_conv",102,0,0,2,['Other']
77375,support kl_div function with bfloat16,19,0,5,4,['enhancement']
77360,PrimTorch clone prim meta is incorrect,5,1,2,2,['Other']
77355,[GHA] Rerunning a test attempts to download a nonexistent build artifact,0,0,2,2,['Other']
77346,Deleted,0,0,0,0,['Other']
77341,"The input of the forward part of my model is a tuple, which cannot be converted to onnx format according to the existing methods. Can you tell me how to solve it",5,0,3,2,['Other']
77338,DISABLED test_ref_small_input_prod_cuda_int16 (__main__.TestReductionsCUDA),197,0,2,3,['Other']
77337,DISABLED test_ref_small_input_prod_cuda_int8 (__main__.TestReductionsCUDA),194,1,1,4,['Other']
77336,DISABLED test_ref_small_input__masked_prod_cuda_int16 (__main__.TestReductionsCUDA),194,1,2,4,['Other']
77335,DISABLED test_ref_small_input__masked_prod_cuda_int8 (__main__.TestReductionsCUDA),194,1,2,4,['Other']
77334,DISABLED test_ref_small_input__masked_prod_cuda_int32 (__main__.TestReductionsCUDA),194,1,1,4,['Other']
77333,DISABLED test_ref_small_input_prod_cuda_int32 (__main__.TestReductionsCUDA),221,0,9,3,['Other']
77326,`is_wrapped_number` isn't being set for args to `__torch_dispatch__`,0,0,2,0,['Other']
77320,DISABLED test_ref_small_input__masked_prod_cuda (__main__.TestReductionsCUDA),194,1,2,4,['Other']
77319,Torch distributed runtime check failure when using pipeline parallelism,0,0,1,1,['Other']
77316,[ONNX] Design ONNX exporter errors,137,1,1,3,['Bug']
77305,DISABLED test_ref_small_input_prod_cuda_int16 (__main__.TestReductionsCUDA),194,1,7,4,['Other']
77299,"No checks on noncontiguous inputs for convolution on CUDA devices, produces incorrect output.",0,0,2,0,['Other']
77286,XLA test jobs generate huge amounts of log spew,12,1,8,2,['Other']
77280,Backward compatibility concerns with Softmax-like modules,3,1,4,5,['Critical']
77260,DISABLED test_slow_tasks (__main__.TestFunctionalAutogradBenchmark),223,0,2,4,['Other']
77252,Add gatekeeper to mergeBot in cases of CI SEVs,55,1,1,3,['enhancement']
77249,Branch listing from git pull should be suppressed in CI,5,1,0,2,['Other']
77248,torch.linalg method cause cusolver error when run for the first time,0,0,4,2,['Bug']
77246,`gradcheck` fails for `torch.angle` in forward mode,1,0,0,5,['Other']
77245,`gradcheck` will trigger INTERNAL ASSERT FAILED for `torch.diagonal` in forward mode,55,1,1,6,['Critical']
77242,Wrong torchvision version installed,2,0,1,2,['Other']
77237,DISABLED test_broadcast_in_dim_cuda_float32 (__main__.TestPrimsCUDA),225,0,5,4,['Other']
77236,test_broadcast_in_dim_cuda_float32 (__main__.TestPrimsCUDA) error,6,0,5,2,['Bug']
77228,How can i  remove  'lib/libtorch_cuda.so'  gracefully to make deploy more small.  【Questions and Help】,0,0,2,1,['Question']
77225,"`linalg.lstsq` fails to backward due to ""Dimension out of range""",233,1,6,2,['Other']
77222,Error converting the pointnet++ model to ONNX,190,0,10,3,['Bug']
77221,"The grad of `f(x) = torch.div(x, 0)` should be `NaN`",0,0,1,2,['Other']
77218,[primTorch] view and reshape are not testing 0 numel -> 0 numel views and reshapes,0,0,3,2,['Other']
77210,Cross Compile MacOS binaries for MPS feature,15,0,6,4,"['enhancement', 'Critical']"
77206,`torch.svd_lowrank` isn't reproducable,26,1,7,3,['Other']
77196,Runtime Checkable Protocol,0,0,5,2,['Other']
77194,GitHub API rate limits causing CI failures - please don't merge PRs with no proper signal,7,0,4,1,['Other']
77181,[ONNX] Use function type hints to wrap torch Values,9,0,1,2,['Other']
77178,ROCM 5.0 libtorch builds has been broken for 7+ days,1,0,4,4,['Critical']
77163,ios-12-5-1-x86-64 simulator tests failing after aten::stft revert,7,1,3,4,['Critical']
77139,Significant perf reduction on Python GIL contention with dataloader pinning thread.,100,0,15,4,['Other']
77138,torch.library.Library should prevent registration to 'prim' namespace,57,0,0,3,['Other']
77135,torch.memory_format are not singletons,6,0,0,2,['Other']
77134,"py::cast(c10::complex<double>(1.0, 2.0)) segfaults",199,1,3,3,"['Bug', 'Critical']"
77133,Overriding `__getattribute__` is not enough in `stateless.functional_call`,7,0,2,2,['Other']
77119,"torch.bitwise_{left,right}_shift should not support non-integral types",0,0,4,0,['Other']
77092,Cannot build PyTorch from source on Mac M1 with x86 Conda,0,0,2,4,['Other']
77090,all_gather not working with NCCL Backend,44,0,15,3,['Other']
77085,DISABLED test_data_parallel_module_cuda_float32 (__main__.TestDataParallelDeviceTypeCUDA),87,0,2,2,['Other']
77081,Did Dropout2d change for Pytorch 1.11?,38,1,23,6,['Critical']
77074,DISABLED test_nvfuser_correctness_clamp_scalar_cuda_int64 (__main__.TestCudaFuserOpInfoCUDA),0,0,2,1,['Other']
77073,DISABLED test_nvfuser_correctness_clamp_scalar_cuda_int32 (__main__.TestCudaFuserOpInfoCUDA),0,0,2,1,['Other']
77072,DISABLED test_nnc_correctness_clamp_scalar_cpu_int64 (__main__.TestNNCOpInfoCPU),0,0,2,1,['Other']
77071,DISABLED test_nnc_correctness_clamp_scalar_cpu_int32 (__main__.TestNNCOpInfoCPU),0,0,2,1,['Other']
77070,DISABLED test_nnc_correctness_clamp_scalar_cpu_bool (__main__.TestNNCOpInfoCPU),0,0,2,1,['Other']
77069,DISABLED test_nvfuser_correctness_clamp_scalar_cuda_bool (__main__.TestCudaFuserOpInfoCUDA),0,0,2,1,['Other']
77068,torch.jit.Attribute is broken,1,0,2,1,['Other']
77063,`collect_env.py` can fail to detect pip packages on Windows,1,1,2,3,['Other']
77055,fix Elu docs,28,1,4,5,['Other']
77054,elu CUDA does not use opmath,0,0,0,4,['Other']
77048,torch.fftn gives wrong results on V100,24,0,8,5,['Critical']
77040,DISABLED test_ldl_factor_cuda_complex64 (__main__.TestLinalgCUDA),222,0,2,3,['Other']
77038,DISABLED test_ldl_factor_cuda_complex128 (__main__.TestLinalgCUDA),228,0,2,3,['Other']
77030,"[FSDP] Crashing at end of training epoch, e1 on clusters, e7+ on single node - collective timeouts, NCCL comm aborts",4,0,9,2,['Critical']
77015,Jacobian gives the wrong result,0,0,0,0,['Other']
77014,Unnecessary _verify_batch_size check in F.batch_norm?,4,0,4,2,['Other']
76970,Alexnet mode inference slows down after importing sklearn package,39,1,0,2,['Other']
76961,DISABLED test_comprehensive_linalg_ldl_factor_cuda (__main__.TestDecompCUDA),2,1,10,4,['Critical']
76957,Libtorch Linker Error in Debug Mode Since 1.11.0,0,0,1,0,['Other']
76953,Building with `USE_TBB=1 ATEN_THREADING=TBB` fails,5,0,0,4,['Other']
76952,`TORCH_WARN` is very slow,45,1,0,2,['Other']
76950,Faster BatchSampler,4,0,10,2,['Other']
76949,"[FSDP] ""Expected no more all-gathers but got an all-gather for the FSDP module wrapping [param]"" during model evaluation",30,1,2,2,['Other']
76941,DISABLED test_backward_index_put_cuda_float32 (__main__.TestCompositeComplianceCUDA),220,0,2,4,['Critical']
76939,F.cross_entropy and nn.CrossEntropy raise exception if no batch dimension is provided,49,0,2,2,['Other']
76932,DISABLED test_collect_callgrind (__main__.TestBenchmarkUtils),230,0,4,4,['Other']
76904,Cannot install PyTorch from nightly,33,1,5,3,['Other']
76894,Torch.distributed.elastic is not stable,59,0,5,3,['Other']
76886,More informative load_state_dict error message,5,0,1,3,['Bug']
76883,NVFuser internal failures,4,1,4,2,['Other']
76872,Add Tensor.is_cpu,32,0,0,2,['enhancement']
76866,DISABLED test_fs (__main__.TestMultiprocessing),237,0,2,4,['Other']
76863,"Periodic jobs have not been running, invalid workflow file",0,1,0,3,['Critical']
76850,Fix test_wait_all_workers_sparse/test_wait_all_workers_twice_sparse/test_my_parameter_server_sparse,0,0,0,1,['Other']
76846,Document nested_tensor.to_padded_tensor(),29,0,0,3,['Other']
76843,Support indexing of the underlying tensors for nested tensors,35,0,1,2,['Other']
76829,LTS installation instructions are outdated and index is not set up correctly,5,2,6,4,['Other']
76826,[LTC] Mark step indicator,11,0,7,2,['Other']
76813,TestCase.assertEqual does not respect longMessage,167,1,4,2,['Other']
76811,torch.cuda.memory_allocated(device) ignores argument,0,0,1,0,['Other']
76805,torch.ne and torch.eq float x complex scalar type promotion is broken,31,0,0,3,['Other']
76803,Complex x float type promotion is incorrect,16,0,6,4,['Other']
76801,Scalar x scalar type promotion is incorrect,176,0,6,3,['Other']
76800,Non symmetry of torch.median(),0,0,2,0,['Other']
76799,torch.jit.script unable to fuse elementwise operations,0,0,4,1,['Other']
76797,DISABLED test_comprehensive_nn_functional_binary_cross_entropy_cuda_float16 (__main__.TestDecompCUDA),0,0,3,1,['Other']
76796,DISABLED test_quick_nn_functional_binary_cross_entropy_cuda_float16 (__main__.TestDecompCUDA),0,0,3,1,['Other']
76795,torch.clamp doesn't propagate nan values from boundaries,8,0,3,3,['Other']
76791,torchvision failures with NVFuser,5,1,8,3,['Other']
76782,`rrelu` will backward fail if `training = True` and `upper=True`,83,0,1,3,['Other']
76781,DISABLED test_peak_memory (__main__.TestImportTime),49,0,2,4,['Other']
76762,[Profiler] Store correlation_id implicitly,114,1,0,1,['Other']
76752,Misleading statement in optim.Optimizer docs,6,0,2,4,['Other']
76742,DISABLED test_fsdp_memory_ckpt_ckpt (__main__.TestFSDPMemory),0,0,1,2,['Other']
76741,DISABLED test_fsdp_memory_ckpt_no_ckpt (__main__.TestFSDPMemory),0,0,1,2,['Other']
76739,RuntimeError while optimizing a TorchScript model,0,0,1,1,['Bug']
76737,had_cuda_in_fwd is not defined in _checkpoint_without_reentrant if preserve_rng_state is False,2,0,3,4,['Other']
76728,Error on GenerateEmbeddingSpMDM while building from source,0,0,1,0,['Other']
76721,DISABLED test_checkpoint_fsdp_wrapping_cpu_offload_CPUOffload(offload_params=True)_offload_activations_False (__main__.TestFSDPCheckpoint),1,0,1,2,['Other']
76715,Check all input parameters k and l,0,0,0,3,['Bug']
76708,Rerun Red on Trunk,217,1,4,2,['Other']
76704,Need to add `expecttest` in the deps list,0,0,1,0,['Other']
76702,"torch.matmul copies instead of broadcasting, while F.linear doesn't",269,1,11,3,['Other']
76700,Migrate viable/strict promotion to GHA,63,1,1,2,['Other']
76697,DISABLED test_checkpoint_fsdp_wrapping_cpu_offload_CPUOffload(offload_params=False)_offload_activations_False (__main__.TestFSDPCheckpoint),1,0,1,2,['Other']
76696,DISABLED test_basic_checkpoint_end_to_end_cpu_offload_CPUOffload(offload_params=True)_offload_activations_False (__main__.TestFSDPCheckpoint),1,0,1,2,['Other']
76684,[ONNX] Improve error handling wrt missing symbolic for autograd.Function,196,1,1,3,['Bug']
76681,[FSDP] Pre-backward hook race,0,0,2,1,['Other']
76680,DISABLED test_basic_checkpoint_end_to_end_cpu_offload_CPUOffload(offload_params=False)_offload_activations_False (__main__.TestFSDPCheckpoint),1,0,2,2,['Other']
76667,Add note about Dev Infra Office Hours in CONTRIBUTING.md,18,1,0,2,['Other']
76666,GHA Retry: Install CUDA and CUDNN (for Windows),4,1,1,2,['Other']
76662,[nvFuser] failing correctness tests in torchbench.py ,4,0,24,2,['Other']
76660,tensor.shape[0] return a tensor not a constant,196,0,2,3,['Other']
76658,A problem related to math formula of the RNN Model,8,0,4,5,['Other']
76652,Fix import in torch.profile to satisfy py.typed conventions and allow type checking by Pylance,31,1,4,1,['Other']
76645,`torch.pow` and `torch.float_power` have different gradient with `bfloat16` input tensor ,1,0,2,2,['Other']
76631,GTK4 segfault on Ubuntu 22.04,53,1,5,3,['Bug']
76630,`torch.clamp` type promotes strangely,7,0,1,3,['Other']
76616,`nn.ChannelShuffle` will crash with empty input tensor,54,1,1,4,['Critical']
76602,`ParameterDict` doesn't work in TorchScript,14,0,3,1,['Other']
76599,DISABLED test_pointwise_op_fastpath__foreach_addcmul_cuda_int8 (__main__.TestForeachCUDA),228,0,4,4,['Other']
76595,Testing pytorch quantized model export into onnx,178,1,4,3,['Other']
76593,Wrong list representation in `default_collate` docstring,2,0,0,0,['Other']
76588,torch.cross outputs incorrect results,0,0,3,1,['Other']
76587,`max_pool` behaves differently with normal input and autograd input,153,1,1,4,['Critical']
76586,Custom CUDA operator only work well on cuda:0,0,0,1,0,['Other']
76583,Can the quantized model trained by pytorch qat be converted to the onnx model?,41,0,2,1,['Other']
76582,inconsistent result between vector_norm and norm,1,0,2,0,['Other']
76572,Resetting random seed in data loader for every epoch,2,0,1,0,['Other']
76568,`fbsync merge to master` failing for some PRs,0,0,4,0,['Other']
76567,`fbsync merge to master` failing for some PRs,0,0,1,0,['Other']
76553,[FSDP] Investigate Execution Order on T5-Large,155,1,0,2,['Other']
76540,"String repr for nested tensors no longer includes ""nested_tensor("" prefix",3,0,2,6,['Critical']
76534,Canonical way to put methods on tensor subclasses?,4,0,6,3,['Other']
76531,NaNs in torch.linalg.eigh backward,0,0,2,1,['Other']
76516,torch.log has unexpected gradient over negative domain,88,0,3,2,['Other']
76511,DISABLED test_init_rpc_without_world_size (__main__.TensorPipeRpcTest),179,1,2,3,['Other']
76501,"[RFC][FSDP] Rework `FlatParameter`, `FlattenParamsWrapper`",25,1,3,2,['Other']
76497,CUDA distributed tests set WORLD_SIZE=2 while ROCm distributed tests set WORLD_SIZE=3,5,0,1,3,['Other']
76462,FX function normalization broken for some cases due to FX operator schema change,0,1,2,1,['Other']
76444,check params shape for mkldnn_convolution,0,0,1,0,['Other']
76443,Add ciflow/trunk label to PRs touching certain files,184,0,1,2,['Other']
76440,RFC: Controlling fp32 matmul’s internal precision,8,0,10,2,['Other']
76434,`torch.nn.Module` keeps an owning reference that prevents it from properly deleting Module,14,0,5,2,['Other']
76432,"Results of MaxPool2d are different using cpu and cuda when dilation is 2, input is transposed numpy array ",150,0,5,4,['Critical']
76431,Torch.utils.mobile_optimizer.optimize_for_mobile is resulting different output than torch model and jit model,5,0,1,1,['Other']
76430,[regression] int_tensor.mean(dtype=float32) should work,18,0,6,3,['Other']
76422,Saving T5-3B model on multi-nodes using FSDP Fails,0,1,2,3,['Critical']
76413,rocm averages 20m to pull docker image,0,0,2,1,['Other']
76401,404 when trying to get pytorch-mutex-1.0-cuda.tar.bz2 from Conda,0,2,9,3,['Critical']
76390,8 bits Quantization Inference overflow provide unexpected results,0,0,0,0,['Other']
76386,[WIP]Checkpoint state_dict and enable resharding for Sharded Tensor,108,0,1,2,['Other']
76382,[RFC] Support Multiple Parameter Groups in FSDP,26,1,2,2,['Other']
76379,`Tensor.to(dtype)`on SparseCSR Tensor raises an error,9,0,0,2,['Bug']
76378,[ONNX] Format ONNX exporter code with Black,10,0,1,3,['Other']
76373,"""Address already in use"" from DataLoader on different process with num_workers > 1",35,0,6,3,['Other']
76368,Inconsistent behavior when using Adam optimizer with PyTorch's CUDA Graphs API,114,0,8,5,['Critical']
76367,torch.distributed.launch don't set the right MASTER_ADDR,0,0,8,2,['Other']
76361,ComplexFloat support for clamp() in Pytorch?,0,0,2,0,['Other']
76329,[ONNX] Reduce import inside functions,24,1,0,3,['Other']
76315,NotSupportedError,0,0,1,1,['Bug']
76308,TypeError: round() got an unexpected keyword argument 'decimals',0,0,1,0,['Other']
76305,lose precision when convert numpy array to torch tensor and execute matrix multiplication,0,0,2,0,['Other']
76302,libtorch gives different results on each run on certain machines,3,0,13,4,['Other']
76298,qint8 support for activation of Eager mode QAT,7,0,4,1,['Other']
76290,Unexpected error when running autograd.grad with is_grads_batched=True,1,0,1,2,['Bug']
76285,'NoneType' object has no attribute 'fill_',1,0,1,0,['Other']
76284,recurrent network wrong GPU,1,0,1,0,['Other']
76283,[ubsan] Undefined behaviour when a running forwardAD CompositeCompliance on `batch_norm`,117,0,1,5,['Critical']
76280,Google Colab Cuda 11.1 module 'torchvision.models.detection' has no attribute 'fcos_resnet50_fpn',1,0,2,2,['Other']
76276,The document's representation of the underlying document,1,0,1,0,['Other']
76271,Module 'Bottleneck' has no attribute 'conv2_offset',1,0,3,2,['Other']
76254,[ONNX] Remove the function _graph_constant in utils if not needed,207,0,2,3,['Other']
76243,XLA Tests are broken,0,0,8,2,['Other']
76241,NVFuser multithreading tests,5,1,0,4,['Other']
76236,Question about suspicious nonzero behavior with scalar input,11,0,8,3,"['Question', 'Critical']"
76229,libtorch crashing core dump,5,0,1,3,['Critical']
76227,[masked operators] UBSAN failure for new test with masked tensor ops,81,0,0,3,['Other']
76224,torch.cuda.mem_get_info ignores device,3,0,2,2,['Critical']
76219,"Function ""forward"" has memory leak by LeakSanitizer",4,0,7,5,['Other']
76215,[ONNX] Use pytorch style docstrings in the onnx module,34,0,0,3,['Other']
76201,X10 slower when computing Hessian-vector product multiple times,2,0,3,0,['Other']
76198,Elastic agents cannot properly shutdown/restart after failure,4,0,2,2,['Other']
76195,[vulkan] Shaders generated incorrectly when precision or format options turned on,3,0,0,3,['Other']
76169,Issues with typehints of F.multi_head_attention_forward,5,0,0,4,['Other']
76168,stop removing old cuda support completely while keeping every small update to recent cuda online,15,0,2,2,['Other']
76165,Variable names created dynamically using python are not added to Module.parameters(),0,0,2,0,['Other']
76162,DISABLED test_multiple_joinables (__main__.TestJoin),98,0,3,3,['Other']
76133,DISABLED test_binary_ops (__main__.TestCudaFuser),0,0,2,1,['Other']
76124,Calling storage() on lazy tensor does not work,42,1,2,2,['Other']
76110,Test failures for `test_batch_norm_impl_index_correctness` and `test_batch_norm_half`,5,0,3,2,['Other']
76109,DISABLED test_multiple_joinable_disable (__main__.TestJoin),99,0,4,4,['Other']
76107,"test_native_layer_norm_bfloat fails with ""Non-divisible split with vectorization is detected. Extent: 975. Factor: 2""",8,1,7,2,['Other']
76101,[No Feedback] Could NOT start training on RTX A6000 but runs well on TITAN RTX and 2080ti ,36,0,8,3,['Other']
76095,memory cross-border access on the ROCM platform,103,0,0,3,['Other']
76094,Address out of range for architecture x86_64,36,0,9,5,['Other']
76088,"The shape inference of ::LearnablePerTensorAffine type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.",15,0,13,3,['Other']
76086,Torchscript: nonexistent 'momentum' for BatchNorm,6,0,2,1,['Other']
76063,`make quicklint` no longer runs `mypy`,9,0,4,2,['Other']
76061,DISABLED test_success (__main__.ForkTest),238,0,4,4,['Other']
76052,LayerNorm does not give exactly the same result on GPU vs on CPU,0,0,2,2,['Other']
76051,Can 'aten::to_dense' be suppored by 'CUDA' backend,0,0,3,2,['Other']
76046,NVFuser opinfos failing accuracy & dtype checks,42,0,9,2,['Other']
76042,Re-running test jobs does not work,48,1,3,2,['Other']
76034,python3 -OO option does not work,13,0,8,3,['Other']
76033,Awful official IOS benchmark tutorial from pytorch.org,166,1,1,4,['Other']
76027,Torchvision - crash during import,0,0,2,0,['Other']
76023,How to disable check onnx in torch.onnx.export in pytorch1.11 version?,15,0,4,3,['Other']
76022,[ONNX] torch.minimum() could not be exported successfully if given parameters have different dtypes.,0,1,0,1,['Other']
76020,"An unknown bug, just appears for a few times",0,0,3,2,['Bug']
76018,Add an option to summon_full_params() for gathering full gradients in FSDP,180,1,3,2,['Other']
76009,DISABLED test_first_argument_index (__main__.ForkTest),241,0,4,4,['Other']
76008,set data permits requires_grad=True on integer tensor,56,0,0,3,['Bug']
75999,PR failures in BC check `_validate_sparse_compressed_tensor_args`,1,0,3,3,['Critical']
75992,Build PyTorch to be supported by Cuda 11.4,0,0,9,3,['Other']
75973,DISABLED test_data_parallel_module_kwargs_only_empty_dict_cuda_float64 (__main__.TestDataParallelDeviceTypeCUDA),104,0,2,3,['Other']
75948,Gradient accumulation does not work with `torch.distributions.categorical`,1,0,1,0,['Other']
75941,[feature request] Raising exception when a custom Dataset class defined by user does not have __len__ and __getitem__ method,0,0,0,0,['Other']
75939,Add distinction between Tensor and NestedTensor in python,0,0,2,1,['Other']
75932,"Python garbage collector can deallocate a tensor, even when C++ still has strong references to it.",3,0,5,3,['Critical']
75927,Upgrade CI version of mypy,17,0,0,2,['Other']
75893,Improve FSDP model initialization time ,30,1,3,2,['Other']
75892,[FSDP] Root module post-backward behavior when in `no_sync()`,3,1,1,2,['Other']
75889,forward() method of ConvTranspose2d does not respect output_size parameter,10,0,2,6,['Critical']
75886,[testing] deprecate field `default_test_dtypes` from OpInfo,3,0,1,2,['Other']
75870,FSDP should verify / broadcast model similar to DDP,49,1,1,5,['Critical']
75866,[JIT] [Autocast] Autocast Pass induce warning in Jit Trace,23,2,3,1,['Other']
75852,torch.stack backward does not automatically cast real float to complex float,157,1,2,4,['Critical']
75825,[Quant][fx] get_default_qconfig_dict doesn't work with fused modules,1,1,2,3,['Critical']
75817,Standardize workflow job names,197,0,2,3,['Other']
75795,Deadlock occurs when using nccl distributed training.,0,0,2,1,['Other']
75787,Unable load pretrained Alexnet model,1,0,2,2,['Other']
75781,UserWarning when running backward on output of irfft with real input,5,1,7,4,['Other']
75769,`torch.linalg.vector_norm` should not support `tensor` as `ord` argument,0,0,1,2,['Other']
75768,[NVFuser] Linear decomposition fails when input or weight don't have concrete shapes,5,0,1,2,['Other']
75762,Cannot compile on mac os due to flatbuffer issue,0,0,7,5,['Critical']
75761,[ONNX] Remove extra trace step required for exporting quantization models,13,1,0,3,['Other']
75758,nvfuser opinfos for extremal values,27,1,0,1,['Other']
75755,`new_group()` returns same group for unique rank inputs,1,0,1,1,['Other']
75752,Don't tightly couple FSDP checkpoint_wrapper in auto_wrap_policy,91,0,0,2,['Other']
75751,Add checkpoint_wrapper composability when FSDP module is being auto_wrapped,91,1,1,2,['Other']
75748,Make ONNX DepthToSpace op mode accessible,72,0,2,3,['Other']
75746,INTERNAL ASSERT FAILED error,171,0,7,2,['Bug']
75735,torch.autograd.grad needs an extra tuple when handling single outputs and is_grads_batched=True,5,0,1,2,['Other']
75734,GET “CUDA error: an illegal memory access was encountered” with nn.Conv2d,5,0,5,5,"['Critical', 'Bug']"
75731,DISABLED test_large_cumprod_cuda_float16 (__main__.TestTorchDeviceTypeCUDA),242,1,2,4,['Other']
75730,`torch.unique` for zero-length `dim` doesn't preserve the input size,7,0,1,3,['enhancement']
75728,torch.cuda.is_available() returns False,0,0,1,0,['Other']
75726,DISABLED test_large_cumsum_cuda_float16 (__main__.TestTorchDeviceTypeCUDA),249,1,2,6,['Critical']
75723,[ONNX] How to export fx quantized model to onnx?,216,1,5,4,['Other']
75722,LocalResponseNorm seems mismatch with onnx,6,0,4,3,['Other']
75719,RuntimeError: derivative for aten::cudnn_convolution_relu is not implemented,1,0,4,1,['Bug']
75708,NVFuser failing autogen-33 benchmark,12,0,15,2,['Other']
75705,Unpin cmake across our repo,268,1,2,3,['Other']
75704,MultiheadAttention for the case when query size and key size are different,40,0,2,2,['Other']
75677,use ONNX symbolic shape inference in torch.onnx.export,80,0,2,3,['Other']
75666,checkpointing of DDP comms hook,78,1,3,5,['Critical']
75665,DISABLED test_join_kwargs (__main__.TestJoin),27,0,1,3,['Other']
75664,DISABLED test_fft_plan_repeatable_cuda (__main__.TestFFTCUDA),107,0,12,4,['Other']
75658,"`torch.distributed.init_process_group` hangs with 4 gpus with `backend=""NCCL""` but not `""gloo""`",7,0,2,1,['Other']
75640,cpu only pip3 install preview (Nightly) has CUDA dependency,0,0,2,3,['Other']
75638,Add list of supported prim/quantized ops by ONNX converter into torch.onnx page,195,0,0,3,['Other']
75637,[ONNX] automatic type checking during export inside autocast,217,0,1,3,['Other']
75636,[ONNX] Run tests with ASan in CI,192,0,1,3,['Other']
75635,[ONNX] Add API to torch.onnx to unregister custom ops,10,1,7,3,['Other']
75633,[ONNX] Remove reliance on broken behavior of list append,195,0,0,3,['Other']
75631,[ONNX] Export should ensure both branches of if statement produce same type,195,0,1,4,['Other']
75630,[ONNX] Make it obvious when a test failure is scripting vs tracing in test_pytorch_onnx_onnxruntime.py,71,1,0,3,['Other']
75629,[ONNX] Fix or delete test_embedding_bag_dynamic_input,203,0,0,3,['Other']
75627,Move test/jit/test_onnx_export.py to test/onnx,57,1,5,4,['Other']
75624,[build] File `torch/csrc/lazy/generated/README.md` gets cleaned by `python setup.py clean` but it's tracked by git,1,1,2,4,['Other']
75623,[ONNX] `ONNX_ATEN_FALLBACK` supports ONNX Runtime,14,1,2,3,['Other']
75622,NVFuser incorrectly computes max for extremal values,1,1,2,1,['Other']
75621,[ONNX] Export embedding_bag with 2d input,2,1,1,3,['Other']
75619,`all_gather_object` not working with NCCL Backend,0,0,4,4,['Critical']
75598,amax to ONNX opset version 12 is not supported,217,0,4,3,['Other']
75597,ONNX: ones_like may result in a large ONNX,218,1,2,3,['Other']
75595,Inference mode throws RuntimeError for `torch.repeat_interleave()` for big tensors,0,0,3,2,['Bug']
75591,DISABLED test_pointwise_op_fastpath__foreach_addcmul_cuda_int32 (__main__.TestForeachCUDA),252,0,4,4,['Other']
75579,'torch.nn.quantized' has no attribute 'FloatFunctional',16,0,3,1,['Other']
75567,Smart make lint ala arc lint,27,0,1,3,['Other']
75566,CI should advertise `make lint`,25,1,6,3,['Other']
75551,Undefined reference while building libtorch_cpu.so,0,0,2,0,['Other']
75541,Linking failed when building pytorch from source,0,0,0,0,['Other']
75534,Unable to install pytorch with pip on macOS Monterey 12.0.1 (M1 chip),90,0,12,4,['Other']
75532,"Remove conda-forge dependency for cuda 11.5, 11.6",277,0,2,3,['Other']
75529,Data race and unaligned access in TensorImpl,6,0,4,3,['Critical']
75515,Error while installing pytorch,0,0,2,0,['Other']
75508,ONNX scripting description mentions removed argument,0,0,1,2,['Other']
75501,make_dual works with non-float `tangent`,53,0,0,2,['Other']
75496,RocksDB 7 may have C++17 dependency,66,0,2,1,['Other']
75482,Windows actions failing during setup,3,0,1,4,['Critical']
75478,Make FSDP Mixed Precision work with BatchNorm,126,2,1,6,['Critical']
75476,issue with pow() & different argument dtypes in NNC,279,0,1,1,['Other']
75475,PyTorch can not be compiled with CUDA acceleration using Clang as host compiler,3,1,0,3,['Other']
75470,Segmentation fault in zero_grad(),1,0,5,3,['Critical']
75464,Strict torch.jit.script fusion mode,17,0,7,3,['Other']
75457,[WIP] microbenchmark codegen error,0,0,1,0,['Other']
75442,"when inputs includes str, scatter() in dataparallel won't split them correctly.",0,0,1,4,['Other']
75434,"Cuda 11.6 Linux test_linalg_lu_factor_and_lu, test_lu_unpack_check_input and test_lu_unpack failures",7,0,9,3,['Other']
75428,ONNX export of torch.minimum,13,1,4,3,['Other']
75417,DISABLED test_torch_nn_CrossEntropyLoss_2d_indices_target_smoothing_weight_cuda (__main__.TestCppApiParity),257,0,4,9,['Critical']
75414,Dataset combined with pycuda issue，Cannot set num_worker>=1,1,0,1,2,['Other']
75413,RuntimeError: Exporting the operator bucketize to ONNX opset version 14 is not supported,4,0,2,3,['Bug']
75411,operating tensor got unexpected output on aarch64 machine,4,0,5,6,['Critical']
75409,DISABLED test_exception_single (__main__.ForkTest),252,0,4,4,['Other']
75405,torch.pow() return `nan` for negative values with float exponent,0,0,3,0,['Other']
75404,Calling state_dict on nested modules falsely raises DeprecationWarning,27,0,0,3,['Critical']
75402,[shard] make sharded_tensor.cpu() a `__torch_function__` op instead,55,0,2,3,['Other']
75373,[RFC] Validate FSDP modules execution order is the same across ranks,19,1,7,2,['Other']
75369,Profiler SegFault on a single Linear layer,15,1,20,4,"['Critical', 'Bug']"
75356,Dictionary input parameter gets interpreted as multiple parameters during pytorch onnx conversion,27,0,1,2,['Other']
75323,pytorch1.6.0 rsub op float32 compute result is different from c++ calculation  result,1,0,2,0,['Other']
75322,[torch.fx] proxy-retracing example code not working properly,105,0,2,2,['Other']
75321,PyTorch Profiler typo. collecton -> collection,1,0,1,0,['Other']
75312,Parameter of g in backward function is buggy.,0,0,2,1,['Bug']
75282,nvfuser fails on benchmark,6,1,2,2,['Other']
75281,normal_ with generator produces different results if input is noncontiguous,1,0,2,2,['Other']
75272,[shard] support ShardedTensor setters,122,0,0,3,['Other']
75269,`torch.multiprocessing` does not propagate global PyTorch options when `forkserver` is used,261,0,2,2,['Other']
75255,[RFC] Add ability to ignore parameters / modules in FSDP,20,1,3,3,['Other']
75252,Batchnorms force set to training mode on torch.onnx.export when running stats are None,202,0,8,3,['Other']
75249,Inconsistent summation when done before/after conversion to cuda,0,0,1,3,['Other']
75224,Avoiding cast of certain tensors in in the optimizer state dict when load_state_dict() is called,274,0,4,4,['Critical']
75219,convolution forward-over-reverse mode AD fails for certain inputs,41,0,6,4,['Other']
75218,tree_map doesn't work over return_types,14,1,1,2,['Other']
75185,RuntimeError: falseINTERNAL ASSERT FAILED,0,0,1,0,['Other']
75182,libfb dependency breaks pytorch build,0,0,1,2,['Other']
75181,pytorch 1.11 cross entropy loss returns nan with ignore index labels,1,0,8,4,['Other']
75179,REPRODUCIBILITY about torch_geometric of Gat,0,0,1,2,['Other']
75177,[Libtorch C++] `torch::save` crash if the folder is not created,18,0,5,6,['Critical']
75169,ROCm test reports not found,29,1,6,2,['Other']
75167,Exporting the operator amax to ONNX opset version 9 is not supported,2,1,1,2,['Other']
75153,TLS certificate of download.pytorch.org is expired,0,1,7,2,['Critical']
75145,Why GroupNorm and BatchNorm have weights ans bias?,2,0,2,3,['Other']
75144,python 3.10 cannot use pytorch,1,0,2,2,['Other']
75143,Maybe a bug about pytorch==1.9.0+cu111,1,0,2,0,['Other']
75131,[Codegen] pyi files are not included in the wheel,0,0,0,0,['Other']
75130,Change torch_dispatch TLS restoration to be opt-in,19,0,2,3,['Other']
75122,"test_linear_1d_weight_mismatch_bias_dtype (M60, https://github.com/pytorch/pytorch/runs/5775045801?check_suite_focus=true)",0,0,1,0,['Other']
75112,Debug with ssh instructions incorrect on CONTRIBUTING.md,0,0,0,3,['Bug']
75104,Rename cosine distance with cosine similarity,3,0,2,5,['Other']
75100,Preserve original scope names in exported ONNX graph,179,1,14,4,['enhancement']
75098,"TypeError when exporting model to ONNX because of missing ""allow_tf32"" argument",7,1,0,2,['Bug']
75093,Feature request: CUDA scatter_reduce(),146,0,3,3,['enhancement']
75089,NVFuser takes a fallback with bfloat16 inputs on V100,10,1,1,2,['Other']
75088,NVFuser produces wrong outputs for extreme values in clamp,10,1,2,2,['Other']
75042,"[Quant] Quantizable LSTM uses asterisk unpacking, not supported by torchscript",147,1,4,4,['Critical']
75029,2022-03-31 disabled nvfuser tests,6,0,5,2,['Other']
75018,RuntimeError: aten::grid_sampler_2d_backward() is missing value for argument 'output_mask'.,22,0,12,4,['Bug']
75015,Inconsistency with the definition of aten::index_put.hacked_twin op,33,1,3,1,['Other']
75011,`TORCH_DISTRIBUTED_DEBUG=DETAIL` raises runtime errors in ddp tests,188,1,6,6,['Bug']
75009,torch.fake_quantize_per_tensor_affine will affect the results of the model if the input memory is not contiguous,19,0,3,3,['Critical']
75004,ONNX export regression in main (NVIDIA pytorch container 22.03),6,1,2,2,['Other']
74995,test_post_localSGD_optimizer_parity_with_hierarchical_sgd error,8,0,4,6,"['Critical', 'Bug']"
74990,clang_format failures are not reported as failures,53,0,1,3,['Other']
74985,cmake==3.23.0 breaks the build with `CMAKE_CUDA_COMPILE_WHOLE_COMPILATION`,284,0,6,2,['Other']
74970,`dim` argument for `DDP` is not documented,212,0,0,1,['Other']
74968,Linux CUDA builds are failing to configure the system,1,0,6,2,['Other']
74967,Linux CUDA builds are failing due to missing deps,0,0,2,2,['Other']
74957,Does pytorch1.11 support pypy3.7 interpreter？,0,0,1,0,['Other']
74955,cmake dependency causing failures on Windows Builds,0,0,1,2,['Other']
74950,No support for AVX512 in torch 1.11.0+cpu python package,41,2,8,4,['Critical']
74949,Building from source does not respect USE_MKLDNN flag,109,0,6,3,['Other']
74933,Combine `torch._UntypedStorage` and `torch.cuda._UntypedStorage`,50,1,0,2,['Other']
74916,Virtualize TensorImpl::Layout for sparse formats,35,1,13,2,['Other']
74914,DISABLED test_script_module_construction (__main__.TestJitDisabled),0,0,3,3,['Other']
74905,"Lookup in my code ,i got NameError: name 'x' is not defined",0,0,1,0,['Other']
74890,.gitignore core.* regex needs refinement,12,0,5,3,['Other']
74874,Gradient computation on modified tensor by in-place operator,0,0,1,0,['Other']
74868,DISABLED test_early_exit (__main__.TestDataLoaderPersistentWorkers),265,0,5,4,['Other']
74853,Data Parallel / Distributed Data Parallel not working on Ampere System?,1,0,12,1,['Other']
74832,Gradient w.r.t. parameters or modules,0,0,2,2,['Other']
74831,full backward hook won't release grad_outputs,133,0,7,3,['Other']
74815,Can I set different regularization parameters for different parameters in Adam optimizer? ,143,0,2,3,['Other']
74812,BytesWarning causes exception in torch.load() when running Python with -bb flag,82,0,1,2,['Other']
74811,Linker Error MacOSX libtorch for arm64,3,0,6,5,['Bug']
74810,[FSDP] full_state_dict: FSDP details can exist in key names,16,1,1,6,['Critical']
74808,yolov5 in jupyter error: self = reduction.pickle.load(from_parent) EOFError: Ran out of input,0,0,0,0,['Other']
74806,Gradient computation on modified tensor by in-place operator,13,0,11,2,['Other']
74805,Failure to build with clang because of unknown warning option error,81,0,8,3,['Bug']
74802,Use automatically calculated derivative inside custom autograd function,121,0,17,2,['Other']
74800,[ONNX] Failed to export aten::flatten of input with unknown rank,212,0,2,3,['Other']
74798,Heap buffer overflow in third_party: miniz-2.0.8,89,1,5,3,['Other']
74781,DISABLED test_pointwise_op_fastpath__foreach_addcmul_cuda_int64 (__main__.TestForeachCUDA),263,0,4,4,['Other']
74779,Missing `libcudnn.so.8` in pytorch-nightly build using conda,0,1,2,6,['Critical']
74777,with-ssh does not wait on ssh connections to drain before releasing the node on linux,3,1,2,2,['Other']
74770,torch.scatter_reduce was erroneously released in 1.11,53,0,3,4,['Other']
74757,Lint for Bazel Syntax,0,0,1,0,['Other']
74752,TorchBench V2 nightly run detects 10% slowdown on dcgan model cpu test,5,0,3,2,['Other']
74751,TorchBench V2 nightly run detects 12% slowdown on dlrm model test,5,0,1,3,['Other']
74747,DISABLED test_batch_norm (__main__.TestTEFuserDynamic),0,1,1,3,['Other']
74743,num_heads incorrectly represented in math expression,2,0,2,3,['Documentation']
74742,Adding Backward Control Flow Dependencies/Triggers,4,0,1,3,['enhancement']
74741,[FSDP] How to use fsdp in GPT model in Megatron-LM,0,0,1,0,['Other']
74740,How to export onnx with dynamic batch size for models with multiple outputs?,0,0,0,0,['Other']
74733,torch.cuda.is_available() return False,0,0,1,0,['Other']
74732,Inference result is different between Pytorch and ONNX model,304,1,8,2,['Other']
74725,ParameterList breaks autograd.Function,4,0,1,2,['Other']
74724,"CosineSimilarity() requires the two input tensors to have exact same shape, but it shouldn't be the case according to docu",4,0,4,3,"['Bug', 'Documentation']"
74694,[FSDP][BE] Update `state_dict_type` documentation,12,1,1,2,['Documentation']
74693,CI jobs are not scheduled due to GHA issues,0,1,1,2,['Other']
74692,Optional[int] argument to RandomSampler is not optional,3,0,3,3,['Other']
74689,torch.combinations raises a warning casued by torch.meshgrid,24,1,5,4,['Critical']
74688,Gradient doesn't satisfy Taylor expansion,0,0,2,0,['Other']
74684,test linux-docs / build-docs (python) is broken,0,1,3,0,['Other']
74682,doc issue in AUTOGRAD MECHANICS,5,0,1,2,['Other']
74681,Does stable 1.11.0 version support rocm 4.2?,98,0,1,2,['Other']
74678,Composite Compliance testing for forward-mode AD formulas,32,1,0,3,['Other']
74661,Support channel first(or any dim) LayerNorm,0,0,4,0,['Other']
74630,Add log_ndtr (reserved for @krshrimali),0,0,0,0,['Other']
74628,Decouple LTC from TS backend,13,0,10,2,['Other']
74626,torch.jit.Attribute does not work as advertised,48,1,1,1,['Other']
74625,"RuntimeError: ""slow_conv2d_cpu"" not implemented for 'Half'",2,0,1,0,['Other']
74624,torch.utils._pytree should support torch.return_types,105,0,1,2,['Other']
74622,`torch.jit.set_fusion_strategy` doesn't check for valid inputs,0,0,2,1,['Other']
74618,CI is experiencing elevated amount of errors due to outage of GitHub,0,0,3,2,['Bug']
74609,why don't pytorch website have the version 1.10 with the corresponding cuda version and torchvision version?,21,0,3,4,['Critical']
74598,DISABLED test_multiple_dataloaders (__main__.TestDataLoader),119,0,3,4,['Other']
74571,[pkg] Automatically extern C++ dependencies,5,1,0,3,['enhancement']
74559,Improve NVFuser fallback performance,43,0,1,1,['Other']
74556,[Reliability Improvement] Record the step # in the optimizer state of PostLocalSGDOptimizer,79,1,4,3,['Other']
74548,DISABLED test_shuffle_batch_workers (__main__.TestDataLoader),266,0,4,4,['Other']
74541,RuntimeError: Preprocessing function for backend coreml is not registered.,188,1,3,3,['Bug']
74538,Quantizer::equalTo missing const qualifier,16,0,1,3,['Other']
74536,Different pytorch version consume a different amount of VRAM,4,0,2,1,['Other']
74534,torchscript model got different results from first and subsequent inferences ,10,1,6,1,['Other']
74522,RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB with 8 Ampere GPU's .,3,0,1,0,['Other']
74501,test/onnx/test_pytorch_onnx_onnxruntime.py::TestONNXRuntime_opset12::test_quantized_linear is flaky,16,1,0,3,['Other']
74498,DISABLED test_multiprocessing_iterdatapipe (__main__.TestDataLoader),268,0,5,4,['Other']
74494,[FSDP] summon_full_params + named_buffers clean full path,21,1,2,6,['Critical']
74489,cannot log in into with-ssh ci jobs via jumphost,25,0,4,3,['Other']
74488,[BE] Update TCPStore pybinded definition to use c10::optional world_size,51,1,0,3,['Other']
74487,scatter_add is slow with fp16 inputs when the index tensor is concentrated,23,0,4,3,['Other']
74480,Migrate binary build and upload jobs off codegen,125,0,9,3,['Other']
74478,Cleanups after workflow consolidation migration,204,0,0,2,['Other']
74476,with-ssh regression as now the relevant login information is hidden within a composite action,6,1,3,2,['Other']
74475,CI workflow consolidation tracking issue,204,0,2,2,['Other']
74473,Installing conda package from pytorch-nighly fails with `libcupti.so.X.Y` not found,183,1,8,4,['Other']
74459,Problem on Dirichlet distribution,92,0,3,2,['Other']
74453,"“TypeError: forward() got an unexpected keyword argument 'log_target'” when running the demo of ""nn.KLDivLoss""",18,0,4,4,['Bug']
74448,imagenet22k trained model weights,0,0,0,0,['Other']
74445,c10 and c10_cuda compiled with clang-cl produce less symbol than if compiled by msvc cl,305,1,5,3,['Other']
74443,cuda memory allocated doesn't match what I have declared,17,0,2,2,['Other']
74440,[BE] Consolidate duplicated rendezvous code,123,0,0,2,['Other']
74439,torch.sign() giving wrong gradients,127,0,1,2,['Other']
74438,cuda low-precision reductions on large tensors produce wrong results,205,1,0,6,['Critical']
74612,mask parameter in Transformer support 3D tensor but not mentioned,22,0,1,3,['Other']
74437,JIT operations not found in latest NVIDIA Pytorch Docker container,5,0,17,1,['Other']
74433,Bad formatting of code in documentation,3,1,2,4,['Documentation']
74426,nn.Module.parameters() returns nothing with nn.DataParallel,0,0,1,0,['Other']
74424,"Tensor ""step"" in optimizers causing major performance regression in PyTorch XLA after loading optimizer state dict",18,1,8,4,['Critical']
74419,Copying tensors sometimes doesn't copy last N elements when using cuda graphs,187,0,2,5,"['Critical', 'Bug']"
74405,Android nightly builds failing,59,1,1,2,['Other']
74404,Module parameterlist attr script error,18,0,2,1,['Bug']
74400,Type promotion semantics not handled properly for `__torch_dispatch__`,52,0,13,6,['Critical']
74388,Deprecation warnings don't help the user identify their bad code,3,0,2,2,['Other']
74380,`dim` argument not checked for any of the fixed dimensional `fft` functions,85,0,1,2,['Other']
74366,Problem with beta and threshold parameters of nn.Softplus(),0,0,0,0,['Other']
74358,lshift and rshift are supported for non-integral inputs and shifts,55,0,2,3,['Other']
74352,python setup.py develop fails,0,1,2,3,['Other']
74341,ci: Add lint to check for trailing whitespaces in filenames,77,1,22,4,['Other']
74334,SystemError: <class 'UserWarning'> returned a result with an error set  ,5,0,2,2,['Bug']
74316, init_process_group constructor hangs when using gloo,1,0,3,1,['Other']
74310,[BUG] replicate/reflect padding fails for 2D tensor,44,0,1,3,"['Bug', 'enhancement']"
74304,GitHub Outage: No Github Actions workflows can be run,1,0,4,2,['Other']
74303,NotImplementedError Description,23,0,11,3,['Bug']
74302,Training MLM model XLM Roberta large on google machine specs not fast,13,0,3,2,['Other']
74288,How to Minimize Rounding Error in torch.autograd.functional.jacobian?,1,0,7,3,['Bug']
74279,"xlogy, xlog1py are all skipping TestGradients",155,0,2,5,['Critical']
74249,Workflow changes can break PR CI ,0,0,1,2,['Other']
74246,Investigate and update DDP tutorials,0,1,1,6,['Critical']
74240,FX QAT Untraceable Modules are still converted to qat versions if possible,16,1,0,2,['Other']
74238,Hugging face code with Pytorch throwing error when running using vertex-ai,14,0,1,1,['Bug']
74232,AttributeError: 'NoneType' object has no attribute '_free_weak_ref',0,0,1,0,['Other']
74223,DISABLED test_exception_all (__main__.SpawnTest),273,0,4,4,['Other']
74203,General policy for supported Python version,58,0,5,3,['Other']
74196,Lazy Tensor Core - Autograd mechanics not working,0,0,5,2,['Other']
74188,intermittent SIGSEGV segfault when plotting during training_step,2,0,10,4,"['Critical', 'Bug']"
74182,"OOM: tacotron2, densenet121, timm_nfnet, demucs",0,1,0,2,['Other']
74177,"get_dropout_state, seed and reproducibility",275,0,0,5,['Critical']
74168,Specify partial inverses using torch.linalg.inv,10,0,7,2,['Other']
74166,[FSDP] Investigate summon_full_params with CPU offloading,94,1,1,6,['Critical']
74165,[FSDP] Generalize `summon_full_params()` to non-FSDP root module,28,1,1,3,['Other']
74158,torch.no_grad() removes requires_grad from weight tensor while updating it by non-compound-operation,0,0,4,0,['Other']
74157,post local sgd  decreases accuracy,30,1,25,3,['Other']
74154,DISABLED test_pdist_norm_large_cuda (__main__.TestTorchDeviceTypeCUDA),280,1,7,5,['Critical']
74147,Typesetting in torch.nn.MultiheadAttention,1,0,0,2,['Other']
74145,conv2d with large kernel uses all the memory on M1 mac,126,0,3,5,['Other']
74144,Couldn't convert pytorch model to ONNX,2,1,2,2,['Other']
74142,[Bug][ONNX] Specification Inconsistency in Flatten,10,0,3,2,['Bug']
74139,Running `tensorboard_profiler_tutorial.py` intermittently crashes with Pytorch-11.1,123,0,7,4,['Critical']
74136,`torch.diagonal` can not  take a batch diagonal with correct `dim1` and `dim2`,0,0,2,0,['Other']
74132,Edit disable bot to also re-enable tests for issues mentioned in commit msg,23,1,1,2,['Other']
74122,Override tests in test/test_overrides.py failing for some functions,23,1,1,3,['Other']
74120,libtorch 1.11.0 libiomp5.dylib contains erroneous link to /DLC/torch instead of using @rpath,86,1,10,5,['Critical']
74116,VC++ does not auto-capture constexpr variables,207,0,3,2,['Other']
74114,for_blob Tensor building API runs into an issue when specifying device,90,1,3,2,['Other']
74102,Create complete release matrix and validation script,59,2,3,4,['Other']
74097,Pre trained faster rcnn model not deterministic.  Run time error thrown when using torch.use_deterministic_algorithms(True),2,0,2,2,['Bug']
74094,inference_mode decorator cannot disable inference_mode,0,0,1,0,['Other']
74091,at::unfold is not present in the C++ docs even though it's an available function,11,0,2,3,['Other']
74087,PyTorch-nightly can not me imported using python-3.7.0,4,1,2,4,['Critical']
74086,Excessive printing for certain ONNX exports,0,1,1,2,['Other']
74079,Any bug triggers device-side assert,3,0,4,2,['Bug']
74075,DISABLED test_get_worker_info (__main__.TestDataLoaderPersistentWorkers),280,0,3,4,['Other']
74073,android prebuilt workflow builds wrong binary (I think),3,1,0,2,['Other']
74068,Add Python Version to Torch.Package metadata,19,1,0,2,['Other']
74056,REGR: Accessing dict in JITed code in 1.11,21,1,4,1,['Other']
74047,tensor.numel() traced as constant,47,1,0,1,['Other']
74037,Lazy Tensor Core - Hardcoded `TsNode` instances,6,0,3,2,['Other']
74033,LayerNorm issue with cuda,0,0,1,0,['Other']
74028,torch.quantization.fuse_modules is not backward compatible in PyTorch 1.11,4,0,7,1,['Other']
74026,Have a `torch.tensor_like` creation op?,4,0,2,3,['Other']
74020,Why convert to float and then convert back for c10::Half operators?,1,0,1,3,['Other']
74016,AttributeError: 'NoneType' object has no attribute '_free_weak_ref',83,1,51,2,['Bug']
74015,Test `test_reduce_add_coalesced` failed,5,1,4,6,['Other']
74004,Alpha dropout documentation or implementation is wrong,1,0,2,2,['Documentation']
73984,"[JIT] cannot parse IR for ""prim::Constant[value=annotate(List[int], []))]""",62,0,0,1,['Other']
73971,cudatoolkit version in docker builds needs a bump,0,1,4,4,['Critical']
73967,`torch.mv` report `CUBLAS_STATUS_INVALID_VALUE` error with cuda 11.3,1,0,2,1,['Bug']
73964,"RuntimeError: CUDA out of memory: hf_Reformer, fastNLP_Bert, hf_BigBird",0,0,1,0,['Other']
73963,"RuntimeError: approximate argument must be either none or tanh: hf_Bart, hf_Bert, hf_Longformer, timm_vision_transformer",1,1,1,0,['Other']
73958,Libtorch torch::einsum(...) need support real tensor and complex tensor do einsum. ,0,0,2,0,['Other']
73955,DISABLED test_seqential_batch_workers (__main__.TestDataLoaderPersistentWorkers),282,0,4,4,['Other']
73935,[shard] use dist.gather instead of dist.gather_object,69,1,4,2,['Other']
73933,Calling super().__torch_dispatch__ with arguments list causes segfault,15,1,1,4,['Bug']
73923,DISABLED test_data_parallel_module_kwargs_only_empty_list_cuda_float32 (__main__.TestDataParallelDeviceTypeCUDA),149,0,4,5,['Other']
73919,LazyTensorCore Overriding Kernel Registrations,15,0,6,2,['Other']
73915,"""clamp_min_cpu"" not implemented for 'ComplexDouble'",0,0,14,2,['Other']
73913,.,0,0,0,0,['Other']
73912,libtorch model predict cuda convert to cpu: C10::error at memory location,6,0,8,5,['Bug']
73911,Libtorch dosen't has the function like python api (TORCH.SET_PRINTOPTIONS) ,6,0,2,3,['enhancement']
73907,the `DistributedSampler` instance can not iterate the dataset in each process when using `Process` in `torch.multiprocessing`.,1,0,1,3,['Other']
73905,"`torch.amax` and `torch.amin` returns random values, if `dim` arg is not provided",8,0,3,3,['Other']
73902,No option for Keyword Arguments (**kwargs) in torch.multiprocessing.spawn,15,0,1,2,['Other']
73891,[FSDP] summon_full_params gradient access issues,222,0,1,3,['Other']
73890,[FSDP] summon_full_params + named_params clean full path,14,0,1,3,['Other']
73884,FSDP optimizer full state dict APIs,23,1,1,2,['Other']
73880,Both HUDs (HUD 1 and HUD 2) down,0,1,1,2,['Other']
73862,Get different gradients by torch.autograd.grad and torch.gradients,0,0,6,2,['Other']
73859,ci: Check if docker daemon is running and start it if it isn't,6,1,3,4,['Other']
73835,ENH: Adding dropdown panels to the documentation,1,0,0,0,['Other']
73827,Layer name mismatched in RNN,5,0,1,2,['Other']
73813,AArch64 Python 3.10 wheel accidentally released?,2,0,3,3,['Other']
73812,Enable squid proxy to use TLS + work with HTTPS,20,1,3,2,['Other']
73790,A6000 Docker Ligthning ddp NCCL WARN Failed to open libibverbs.so ,1,0,16,3,['Other']
73789,JIT: Fuser failures when calling a script function from multiple threads,2,0,2,1,['Other']
73782,TORCHTEXT.DATASETS.IWSLT2017,3,0,1,0,['Other']
73779,Poor performance when chaining operations,3,0,1,0,['Other']
73778,Feature Request: Hausdorff distance,16,0,4,4,['enhancement']
73775,NCCL Error 2: unhandled system error of `DataParallel`,2,0,6,0,['Other']
73757,[FSDP] Hide ConfigAutoWrap,0,0,0,3,['Other']
73737,torch.jit.trace will fail on nn.Module with nn.ParameterList,33,0,1,1,['Other']
73735,Cannot load faster-rcnn model with libtorch in C++,0,0,1,0,['Other']
73726,RuntimeError: An attempt has been made to start a new process before the current process has finished its bootstrapping phase.         ,0,0,1,0,['Other']
73701,GHA Retry step: Build and upload nightly docker,0,0,0,4,['Other']
73688,/usr/include/c++/11.2.0/cstdlib:75:15: fatal error: stdlib.h: No such file or directory,19,0,3,2,['Bug']
73682,c10d/TCPStore: hostname lookup failures are fatal causing jobs to fail on Kubernetes,21,1,0,4,['Other']
73662,Harden Alerts so that they are actionable most of the time,240,1,2,1,['Other']
73659,Measure OSS DevX KPIs and have dashboards on Grafana for it,160,1,2,1,['Other']
73658,Add functionality to allow a comment to rebase a PR,125,1,5,2,['Other']
73657,Develop Required Status Checks/MergeQueue,180,1,2,1,['Other']
73645,DDP training hangs when one GPU returns zero loss,1,0,3,0,['Other']
73644,Unable to open shared memory object </torch_5566_0> in read-write mode,1,0,2,4,['Critical']
73639,JIT decompose pass: To enable decomposition only for GPU device,51,0,2,1,['Other']
73631,[docs bug] wrong indexing of class name,0,0,0,0,['Other']
73628,`kthvalue` triggers segmentation fault,5,0,3,4,"['Critical', 'Bug']"
73624,"`FractionalMaxPool{2,3}d` trigger segmentation fault when `output_size` contains 0",1,0,2,4,"['Critical', 'Bug']"
73622,torch.det behaviour for large batch sizes on cuda,12,1,12,3,['Other']
73620,[JIT] NVFuser tests that fail on windows,48,1,8,2,['Other']
73619,ONNX export fails with a `resolve_conj` op when a tensor slice is printed.,229,1,4,4,['Bug']
73616,`create_feature_extractor`  V.S. `_utils.IntermediateLayerGetter`,0,0,4,2,['enhancement']
73605,Migrate nightly Android builds to Github Actions,99,1,0,3,['Critical']
73603,Multiworker dataloader with persistent workers is non-deterministic after first epoch,7,0,1,3,['Other']
73588,Skip ROCm test using profiler due to latest Kineto Submodule Update,10,0,4,2,['Other']
73587,Deterministic indexing operation fails in indices size check,0,0,1,0,['Other']
73584,Consider to have something like torch.distributions.functional,0,0,2,2,['Other']
73582,Add torch.distributions.MultivariateNormalDiag,0,0,1,2,['Other']
73566,Log spew from quantization reference modules,189,1,2,1,['Other']
73565,C++ ModuleList/ModuleDict segfault with at<ModuleType>() method,331,0,1,4,"['Critical', 'Bug']"
73562,<c10d/debug.h> included in c10d/ProcessGroup.hpp makes <c10d/ProcessGroup.hpp> unable to expose to users,3,0,4,1,['Bug']
73561,`torch.msort` is not consistent with `torch.sort`,0,0,2,2,['Other']
73559,torch.linspace exports incorrectly to ONNX,3,1,1,2,['Other']
73557,Forward AD silently loses tangent of dual number tensor subclass,52,0,10,4,['Other']
73552,DISABLED test_custom_sharding_spec_shard_tensor (__main__.TestCustomShardingSpec),9,1,2,4,['Other']
73547,Check mismatched number of parameters in DDP _verify_params_across_processes,14,1,0,7,['Critical']
73541,forward ad failure with F.batch_norm,1,0,0,2,['Other']
73539,Tensor subclasses cannot interpose make_dual via __torch_dispatch__,3,0,10,3,['Other']
73520,Missing THC/THC.h: No such file or directory with PyTorch v1.11.0-rc4,0,0,2,0,['Other']
73518,[FSDP] sharded_state_dict,229,0,1,3,['Other']
73512,Unknown CUDA graph CaptureStatus119,0,0,0,0,['Other']
73503,`torch.nn.init.orthogonal_` does check tensor with zero rows,44,0,1,4,['Other']
73500,"RuntimeError: falseINTERNAL ASSERT FAILED at ""../aten/src/ATen/MapAllocator.cpp"":263, please report a bug to PyTorch. unable to open shared memory object </torch_3853_0> in read-write mode",1,0,1,2,['Bug']
73499,"`{std, var}_mean` and `mean` output different mean for `float16` and `bfloat16` tensor",7,0,4,3,['Other']
73498,"torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.10.2+cu102 which is incompatible.",1,0,1,0,['Other']
73496,I solved this problem by set NCCL_P2P_LEVEL=NVL.,0,0,1,0,['Other']
73495,Windows workflows frequently failing with timeout,0,0,2,2,['Other']
73489,Windows tests frequently timeout,273,1,3,5,['Critical']
73485,Problem with Einsum,1,0,1,0,['Other']
73482,precision issue with complex numbers in torch,1,0,2,0,['Other']
73481,WeightNorm causes Memory Leak,47,0,6,5,['Other']
73480,MNIST data in torchvision is corrupt!,0,0,2,0,['Other']
73473,DISABLED test_python_ir_utils_graph (__main__.TestJit),292,0,7,2,['Other']
73465,[torchelastic] properly format (or don't log) trace info in structured error when the agent process is killed prematurely,3,1,13,3,['Bug']
73463,[quant][graphmode] kwargs breaks convert handling of functional.linear,133,1,1,2,['Other']
73458,"MacOS tests sometimes failing with ""botocore.exceptions.ClientError: An error occurred (AccessDeniedException)""",2,0,6,2,['Bug']
73454,Support tensor_split in ONNX export,102,1,9,2,['Other']
73448,[JIT] Disable NVFuser for ROCm builds,52,1,2,4,['Other']
73427,'pip install torch' does not work for the case without cuda,0,0,4,0,['Other']
73426,Converting an empty dense tensor to sparse_coo makes an uncoalesced tensor,201,1,12,2,['Other']
73421,Missing header causes build failures for c10d extensions,2,0,2,3,['Critical']
73420,export yolor_p6.pt to onnx ,249,0,3,3,['Other']
73418,[onnx export] toy model export onnx,0,0,1,0,['Other']
73416,torch.max() has a bug,2,0,1,0,['Other']
73401,Move F.pad into ATen,228,1,2,2,['Other']
73395,[JIT] fix test_jit_cuda_fuser.py - test_category_rule ,45,1,3,2,['Other']
73391,DISABLED test_variant_consistency_jit_sort_cpu_float32 (__main__.TestJitCPU),54,1,2,3,['Other']
73388,ONNX export failed for torch_scatter ops in TAPAS model,264,1,5,2,['Other']
73384,[FSDP] full_state_dict offload to CPU,118,1,0,2,['Other']
73383,[FSDP] full_state_dict only on rank 0,118,1,0,2,['Other']
73382,Integrate Hierarchical Model Averaging with PostLocalSGDOptimizer,34,0,1,1,['Other']
73377,Stop CUDA-11.1 binary builds/tests in CI,4,1,2,5,['Other']
73363,TestSparse misses out on TestCase.setUp() + thus disabling doesn't work,1,1,2,2,['Other']
73356,bad_alloc after np.exp when creating a tensor,22,0,2,3,['Critical']
73353,big discrepancies between torch.jit.trace'd eval results an original model eval results,2,0,3,1,['Other']
73347,"""object is not iterable""  in lightning.toggle_optimizer when using single optimizer ",0,0,0,0,['Other']
73346,DISABLED test_variant_consistency_jit_mean_cpu_float32 (__main__.TestJitCPU),28,1,2,5,['Critical']
73341,DISABLED test_terminate_signal (__main__.SpawnTest),300,0,5,4,['Other']
73340,DISABLED test_success_first_then_exception (__main__.ForkTest),301,0,4,4,['Other']
73339,"Windows conda builds failed in GHA, blocks windows conda migration",12,1,10,5,['Critical']
73328,TorchBench V2 nightly run detects a 7.8% regression on nvidia_deeprecommender model,29,1,16,3,['Other']
73320,torch.distributed.run to discover an available port automatically by default or with a simple switch (proposed workaround is easy to get wrong),5,0,21,1,['Other']
73319,[docs] distributed docs still mention/recommend deprecated torch.distributed.launch,7,0,6,1,['Other']
73315,DISABLED test_pure_fp16_cpu_offload_CPUOffload(offload_params=False) (__main__.TestPureFP16),300,1,5,5,['Other']
73305,Utility of max_lr in OneCycleLR?,1,0,2,0,['Other']
73302,DISABLED test_expanded_weight_forward_nn_functional_embedding_cuda_float32 (__main__.TestExpandedWeightFunctionalCUDA),1,0,4,4,['Other']
73301,DISABLED test_expanded_weight_forward_nn_functional_embedding_cuda_bfloat16 (__main__.TestExpandedWeightFunctionalCUDA),1,0,1,4,['Other']
73298,torch.where does not handle scalar type correctly,68,0,3,2,['Other']
73291,[JIT] Removing a `print` statement causes `RuntimeError: split_with_sizes expects split_sizes to sum exactly`,1,0,2,1,['Bug']
73289,Protect the branch name `main`,2,1,0,1,['Other']
73288,CrossEntropyLoss calculation for target containing class probabilities,6,0,3,3,['Other']
73267,DISABLED test_expanded_weight_forward_nn_functional_embedding_cuda_float64 (__main__.TestExpandedWeightFunctionalCUDA),2,0,1,4,['Other']
73266,DISABLED test_first_argument_index (__main__.SpawnTest),293,0,4,4,['Other']
73259,Debug optimizer overlap tests with NCCL_ASYNC_ERROR_HANDLING,255,1,0,5,"['Bug', 'Critical']"
73248,DISABLED test_expanded_weight_forward_nn_functional_embedding_cuda_float16 (__main__.TestExpandedWeightFunctionalCUDA),2,0,6,6,['Critical']
73228,TorchScript not computing the correct type for complex scalar,2,1,1,1,['Other']
73213,RNN allocates memory on wrong GPU in distributed setting,0,0,1,1,['Other']
73212,Enable use of Pytorch codegen from external libraries,62,0,4,3,['enhancement']
73206,DDP gets stuck on A40 GPUs,1,0,5,0,['Other']
73204,different result of variable in autograd backward between pytorch and libtorch,7,0,3,3,['Other']
73200,Change the prefix path of model (Load failed if the skeleton of model is in different folder),7,0,1,0,['Other']
73199,PyTorch Profiler Problem: Can not load GPU kernal!!!!,3,0,2,0,['Other']
73194,Floating point exception in native_group_norm,43,0,0,3,['Critical']
73193,Floating point exception in mkldnn_convolution,161,0,5,6,"['Critical', 'Bug']"
73192,Segmentation fault in max_pool3d_with_indices,37,0,3,4,['Bug']
73189,Segmentation fault in im2col,37,0,1,4,['Bug']
73188,Floating point exception in group_norm,99,0,6,6,"['Critical', 'Bug']"
73187,grid_sampler_3d_backward aborts due to heap corruption,41,1,28,5,['Critical']
73184,Segmentation fault in col2im,37,1,0,5,['Bug']
73183,Segmentation fault in adaptive_avg_pool3d,37,0,1,4,['Bug']
73177,Source build error: use of undeclared identifiers (`half2half2` and `h2div`),45,0,0,2,['Bug']
73169,`abs` can cast `ComplexDouble` to `Double` but other APIs cannot,1,0,1,0,['Other']
73168,Got error about invalid header or archive is corrupted,140,0,7,3,['Bug']
73165,`CrossEntropyLoss` triggers floating point exception,29,0,6,5,['Critical']
73163,Support Passing Participating Group Ranks and Options to 3rd Party Distributed Backends,220,0,1,2,['Other']
73159,`logcumsumexp` succeeds when `dim` is out of range on cuda,100,1,1,5,"['Critical', 'Bug']"
73156,Don't have an op for metal_prepack::conv2d_prepack,0,0,1,0,['Other']
73153,Bug in Dataloader,31,0,10,3,['Bug']
73152,"I found a BUG in Pytorch 1.10.*, please help me to deal with this.",0,0,2,1,['Bug']
73135,Should we remove `aten::_s_where` and make `aten::where` a primitive?,10,0,5,0,['Other']
73133,[shard] init_from_local_tensor API improvement,6,0,1,1,['Other']
73129,I get an error when exporting to onnx but cannot find what it means,23,1,5,2,['Bug']
73114,nightly: excessive The server socket on ... is not yet listening,75,1,0,2,['Other']
73096,ShardedTensor._init_from_local_shards(...) API not working correctly,13,0,8,1,['Other']
73079,github-actions pings the merger to add release note labels even after the PR has correct release note and topic labels,283,0,3,2,['Other']
73068,Windows nightly libtorch debug package in pytorch.org is out of date.,14,1,1,5,['Bug']
73059,test issue,0,0,2,0,['Other']
73055,DISABLED test_iterable_style_dataset (__main__.TestDataLoader),299,0,4,4,['Other']
73047,pytorch compilation cuda,1,0,1,1,['Other']
73044,Add full_state_dict testing in `test_fsdp_state_dict`,230,1,1,2,['Other']
73039,rocm jobs are consistently queuing for 1h+ during working hours,105,1,31,4,['Critical']
73030,`ciflow/win` no longer schedules full testsuite run on Windows,0,0,5,3,['Other']
73025,Windows builds are broken,0,0,8,2,['Other']
73024,CircleCI Windows builds are broken,0,0,2,2,['Other']
73022,CI: Remove code that differentiates between PR and trunk,253,1,1,3,['Other']
73015,Grammatical Mistake,4,0,3,2,['Other']
73010,.github/README.md is rendered as main README instead of /README.md,0,1,9,3,['Critical']
73004,Tensor's .size() method returns wrong type during jit.script() ,0,0,1,1,['Other']
72992,"dropout(inplace=True) raises error : one of the variables needed for gradient computation has been modified by an inplace operation:Tensor [], which is output 0 of ReluBackward0, is at version 2; expected version 1 instead.",0,0,1,0,['Other']
72957,no kernel image is available,0,0,1,0,['Other']
72956,Migrate binary_smoketest.py from CircleCI -> GHA,19,1,3,3,['Critical']
72950,MacOS test jobs failing with botocore.exceptions.NoCredentialsError: Unable to locate credentials,0,1,4,2,['Bug']
72947,Segfault when assigning scalar to `.imag` or `.real` attributes,19,0,3,5,"['Critical', 'Bug']"
72931,FSDP issue on wrapping  models,241,1,3,2,['Other']
72927,DISABLED test_terminate_signal (__main__.ForkTest),300,0,5,4,['Other']
72926,DISABLED test_success_non_blocking (__main__.SpawnTest),301,0,4,6,['Critical']
72921,Issue with no_grad() doc,83,0,4,6,['Other']
72920,Mask-RCNN Tracing fails,1,0,2,1,['Other']
72918,Extension with stable build: fatal error: thrust/complex.h: No such file or directory,0,0,4,3,['Bug']
72910,`irfft2` and `irfftn` INTERNAL ASSERT FAILED,6,1,4,4,"['Critical', 'Bug']"
72908,DISABLED test_transformer_module_apply (__main__.TestApply),65,1,8,5,['Other']
72907,official binary package with _GLIBCXX_USE_CXX11_ABI=1,99,0,3,2,['Other']
72902,publish_android_snapshot job were lost during migration,1,0,1,5,['Critical']
72901,Support dataclasses in TorchScript,111,0,25,1,['Other']
72900,`tril_indices` and `triu_indices` have strange behavior when `row=0`,51,0,3,6,['Critical']
72893,DISABLED test_coalesce_cuda_bfloat16 (__main__.TestSparseCUDA),12,1,1,4,['Other']
72892,DISABLED test_Sparse_to_Sparse_copy__cuda_bfloat16 (__main__.TestSparseCUDA),12,1,3,6,['Critical']
72885,Support c10::IntArrayRef in c10::IValue,33,0,0,2,['Other']
72870,DISABLED test_dtypes_argsort_cuda (__main__.TestCommonCUDA),0,0,2,1,['Other']
72868,DISABLED test_data_parallel_module_cuda_float64 (__main__.TestDataParallelDeviceTypeCUDA),166,0,2,3,['Other']
72863,IterableDataset concrete subclasses are protocols which breaks isinstance checks,0,0,1,2,['Other']
72862,Doc issue in `nn.Module`,1,0,3,3,['Other']
72860,Some tests misusing assertTrue for comparisons,1,0,3,1,['Other']
72852,Type signature for tools.codegen.api.lazy.isValueType is a bit suspect,2,0,0,2,['Other']
72848,request about perspective grid generator,0,0,1,0,['Other']
72816,[distributed] tell which address for RuntimeError: Address already in use,0,0,4,2,"['Bug', 'enhancement']"
72815,Allow `nn.Sequential` to take a normal dict (along with OrderedDict),23,0,2,2,['Other']
72813,DISABLED test_conv_noncontig_weights_and_bias_cuda (main.TestNNDeviceTypeCUDA),21,0,1,1,['Other']
72812,DISABLED test_fast_tasks (main.TestFunctionalAutogradBenchmark),16,0,1,1,['Other']
72807,Missing headers in ATen/cuda/DeviceUtils.cuh,0,0,10,0,['Other']
72793,`sum` and `sparse.sum` have different behavior for scalar tensor,0,0,4,3,['Other']
72790,Export torch.maximum() op in ONNX format,141,0,7,3,['Other']
72787,grad strides do not match bucket view strides,8,0,2,3,['Other']
72779,support for modern python,0,0,3,1,['Other']
72778,BUG (potential crash) with `state_dict()` implementation and overload,10,0,13,3,"['Bug', 'Critical']"
72776,Determinism for MaxPool3d and AvgPool3d,0,0,0,0,['Other']
72774,How can I load and use a HDF5 format model in C ++ using libtorch ,0,0,1,0,['Other']
72772,Gradient estimator methods like straight through estimators for gradient approximation of non-differentiable landscapes of a model's graph.,1,0,1,3,['enhancement']
72771,devices or gpus in pytorch_lightning.Trainer,0,0,1,0,['Other']
72765,[KL divergence] Adding details in error when KL divergence registered between two distributions and improving the doctstring. ,7,0,2,3,['Bug']
72763,"RuntimeError: input_values.size() == param_count_list.size()INTERNAL ASSERT FAILED at ""..\\torch\\csrc\\jit\\python\\script_init.cpp"":480",166,1,6,2,['Bug']
72762,TorchVision Tries To Install Torch Again,2,0,3,1,['Other']
72753,Problem with typing for cudnn.allow_tf32,2,0,0,4,['Other']
72747,[ROCm] ERROR test_fast_tasks and test_conv_noncontig_weights_and_bias_cuda ,24,0,1,2,['Bug']
72743,"[JIT] torch.jit.fuser(""fuser1"") should enable cpu fusion",61,1,0,2,['Other']
72721,torch.complex32 is missing from the PyTorch 1.11 RC,0,0,2,2,['Other']
72720,jit.script mis-optimizes code causing cpu fallbacks,0,0,1,1,['Other']
72718,[ZeRO] Investigate ROCm test flakiness,305,0,2,2,['Other']
72716,"Investigate support for parameters(), named_parameters() in FSDP",246,0,1,2,['Other']
72713,FileOpenerIterDataPipe should support an encoding argument,3,0,4,2,['Other']
72707,Torch typing: `load_state_dict` overconstrained,80,0,4,2,['Other']
72698,GeneralTensorShapeOpQuantizeHandler skip unless reference mode,66,1,4,2,['Critical']
72696,kernel assertion with torch 1.10.2 and CUDA 11.3,1,0,4,3,['Bug']
72693,Create a CI workflow for XLA testing using the XLA test image,5,0,4,3,['enhancement']
72681,`test_qconv_transpose3d`  test run-time failure,119,0,1,1,['Other']
72674,[JIT] Add pass that compares outputs of nvfuser & non-fused implementations,60,0,0,1,['Other']
72661,Tests should be disabled in forks when they are expected to fail,32,1,6,5,['enhancement']
72655,Builder repo is not pinned in release branch,1,1,2,3,['Critical']
72654,deit_small_patch16_224 weights not working,126,0,1,1,['Other']
72653,C++ linking to Pytorch on Linux (CPU) fails with libtorch 1.10.1 - cannot find MKL,7,1,7,5,['Critical']
72651,discuss.pytorch.org is down,0,0,2,0,['Other']
72648,Pytorch should not log to python root logger,1,0,0,3,['enhancement']
72640,Calculation is different from decimal point.,0,0,1,3,['Other']
72636,Code in torch/_masked is getting executed during `import torch`,7,1,0,3,['Other']
72630,`torch.kaiser_window` fails for meta tensors and `window_length >= 2`,33,0,1,3,['Other']
72625,DISABLED test_success_first_then_exception (__main__.SpawnTest),307,0,4,6,['Critical']
72624,DISABLED test_terminate_exit (__main__.SpawnTest),307,0,4,6,['Critical']
72612,Custom function recent change introduces bad refcounting,0,0,0,4,['Critical']
72610,binary_linux_manywheel_3_7m_cu102_devtoolset7_test is broken,0,0,1,2,['Other']
72597,"Functional version of `MultiheadAttention`, `torch.nn.functional.multi_head_attention_forward` has no documentation",1,0,7,4,['Documentation']
72594,torch.no_grad() can cause nan and random results,1,0,4,6,['Critical']
72589,[DDP][FSDP][BE] Refactor `no_sync()` context,233,0,0,4,['Other']
72588,"Update torch.testing.make_tensor ""device"" and ""dtype"" arguments to be kwarg-only",15,1,0,2,['Other']
72579,pip install does not work for LTS (1.8) - wheel index page might be broken,0,0,3,0,['Other']
72571,Installing torch_nighly using pip shows error,0,0,4,3,"['Critical', 'Bug']"
72569,RuntimeError: set_sizes_and_strides is not allowed on a Tensor created from .data or .detach().,0,0,1,2,['Bug']
72554,Implement fsdp.apply(),15,1,1,2,['Other']
72553,Add a way to debug when our runners are at capacity,23,0,1,2,['Bug']
72552,Add a flip switch to go back to circleci when there is a capacity issue.,23,0,1,1,['Other']
72550,TestSpectralOps tests incompatible with updated librosa 0.9.0,14,1,2,2,['Other']
72548,Implement clip_grad_norm for FSDP models,30,1,1,3,['Other']
72546,[FSDP] `no_sync()` correctness test requires double precision,0,0,1,1,['Other']
72541,[FSDP] Root frees params in `_post_backward_hook()` though `reshard_after_forward=False`,0,1,3,3,['Other']
72539,Remove/refactor BucketReplica in DDP reducer,19,1,1,4,['Other']
72538,Enable documentation improvements to be able to land through GH1,14,0,2,2,['Documentation']
72528,onnx.export not producing the same results as torch model ,57,1,3,2,['Other']
72527,Checkpoint erronously warn due to autocast,122,0,3,4,['Other']
72521,"`Only 2D, 3D, 4D, 5D padding with non-constant padding are supported` on 3D array",71,0,6,4,['Other']
72520,[FSDP][BE] Remove multiple param logic in FSDP code,249,0,1,4,['Other']
72519,"DOCS, CI: pushing a tag is not triggering a docs build",1,0,4,4,['Other']
72517,trunc_normal_ not in Docs,87,0,1,4,['Other']
72515,Unable to manually assign grad,0,0,6,2,['Other']
72512,Inconsistent output when using contiguous,0,0,1,5,['Other']
72511,libtorch cudaDeviceSynchronize() operation is VERY SLOW?,0,0,4,2,['Other']
72510,TripletMarginLoss : weird formatting in doc,9,0,0,4,['Other']
72509,MultiMarginLoss : weird formatting in doc,9,0,0,4,['Other']
72507,PairwiseDistance : weird formatting in doc,9,0,0,4,['Other']
72506,linear : weird formatting in doc,9,0,0,4,['Other']
72505,AdaptiveAvgPool3d : Incorrect input shapes,9,0,0,4,['Other']
72504,AvgPool1d : unclosed bracket for shape,9,0,0,4,['Other']
72503,fold : weird formatting in doc,9,0,0,4,['Other']
72502,conv_transpose3d : weird formatting in doc,9,0,1,4,['Other']
72501,conv3d : weird formatting in doc,9,0,0,4,['Other']
72494,onnx.export() of Batch1dNorm generates invalid ONNX under torch.cuda.amp.autocast(),59,2,12,4,['Other']
72493,XLA is broken on master again,0,0,1,3,['Other']
72471,Tool for capturing script-able logging output,56,0,1,1,['Other']
72466,Add nvfuser tests to CI,57,0,1,1,['Other']
72434,DDP debug mode: Throw when static_graph and unused parameter sizes are different across ranks,10,0,3,4,['Bug']
72432,Newest librosa update causing test breakages in CI,0,0,1,2,['Other']
72422,GHA binary pipeline uploads nightly builds via PR CI,0,0,0,4,['Critical']
72417,Bidirectional LSTM gets val_score: 0.0,1,0,2,3,['Other']
72416,Quantized torchscript fails on second inference,16,0,2,1,['Other']
72400,macOS Monterey 12.2 PyTorch-1.7.1 SGD Optimizer Segfaults with libomp.dylib`__kmp_suspend_initialize_thread,9,0,8,7,"['Critical', 'Bug']"
72399,PyTorch 1.10.2 failed to create workable onnx for sequential LSTMs,5,1,1,4,['Other']
72396,libtorch with Cuda 11.3 not linked properly on Windows using Visual Studio 2022,2,0,8,5,['Other']
72395,About the pseudocode in the torch.optim.SGD document,87,0,1,3,['Other']
72394,Inconsistent behavior between torch.nn.functional.pad and torchvision.transforms.functional.pad when setting padding to be an eight-element lists,2,0,3,4,['Other']
72392,DeepLung pretrained weights gets changed while importing weights from Pytorch to ONNX.,3,1,4,2,['Other']
72371,Windows GHA automatic sharding broken,18,0,0,2,['Other']
72368,ASAN shards are very unbalanced,46,1,25,3,['enhancement']
72365,How is Tensor.type supposed to work with strings?,2,0,1,3,['Other']
72360,Add ZeroTensor fastpath for torch.addr,65,0,1,2,['Other']
72337,ONNX tests are broken,0,0,1,3,['Other']
72334,Make cholesky_inverse documentation mention that batching is supported,2,0,5,4,"['Documentation', 'enhancement']"
72331,AttributeError: 'NotImplementedError' object has no attribute 'message',0,0,2,0,['Other']
72328,Wrong operation in stft's center attribute,3,0,8,3,['Other']
72307,Export maximum / minumum to ONNX,252,1,5,2,['Other']
72298,DISABLED test_success (__main__.SpawnTest),314,0,13,6,['Critical']
72282,torch.tensor : Inconsistent UX (Python 3.10),4,0,7,2,['Other']
72281,DISABLED test_linalg_lstsq_cpu_float64 (__main__.TestLinalgCPU),48,0,4,6,['Critical']
72267,[v.1.11.0] Release Tracker,32,0,58,2,['Other']
72250,Support ffmpeg 5.x/libavcodec 59,0,0,3,0,['Other']
72248,nn.ConvTranspose2d with metal any way,1,0,4,0,['Other']
72245,nn.BatchNorm2d with metal,1,0,4,0,['Other']
72243,optimizer contains a parameter group with duplicate parameters,1,0,1,0,['Other']
72234,Seeing several addmm_sparse_csr_cuda float16/bf16 failures,6,0,7,4,['Other']
72212,[Perf request] Make index_select on sparse COO tensors as fast as that from rusty1s/pytorch_sparse (1000x),95,1,15,2,['Other']
72205,ROCM jobs fail due to outdated git version,0,0,8,3,['Other']
72204,`test_neg_view_linalg_det_singular_cuda_float64` fails with Illegal Memory Access failure for singular matrices,60,1,5,3,['Critical']
72203,torch.linalg.det's gradcheck fails with Illegal Memory Access failure for singular matrices,12,1,0,3,['Critical']
72202,"torch.no_grad, enable_grad, etc should document their behavior with forward-mode AD",1,0,1,3,['Other']
72188,MacOS jobs in queue for 18+ hours,6,1,5,2,['Other']
72187,Add intra-backwards gradient accumulation in FSDP,255,0,1,2,['Other']
72186,[discussion] `torch.nn.init` functions should not support `__torch_function__` directly,0,0,8,3,['Other']
72185,Support gradient accumulation without no_sync context manager in FSDP,76,1,1,2,['Other']
72183,Add no_sync context manager for FSDP,26,1,1,2,['Other']
72180,"pip==22.0.2 throws warning for `torch_stable.html`: ""not a proper HTML 5 document [...] violates PEP 503""",1,0,4,3,['Other']
72177,test_sampled_addmm_zero_sized causes CUDA memory exception,2,0,0,4,['Critical']
72174,TorchScript to ONNX conversion failing,0,0,1,1,['Other']
72173,[JIT] Models recently failing at specific resolutions (Tensorexpr),1,0,5,1,['Other']
72172,Library not loaded: @rpath/libtorch_cpu.dylib,0,0,2,3,['Other']
72167,Build issue with protobuf 3.15+,0,0,2,4,['Other']
72129,torch.save does not save python attributes attached to Tensors or Parameters,168,1,3,4,['Critical']
72120,Non contiguous target prevents learning using F.cross_entropy on GPU,0,0,1,0,['Other']
72115,Composite Compliance testing should support case where only some inputs are Tensor Subclasses,104,1,1,3,['Other']
72114,Composite Compliance testing for autograd formulas,104,1,1,4,['Other']
72113,forward-mode AD testing does not test inputs with requires_grad=False,8,1,0,3,['Other']
72092,[PT-D] More efficient ShardedTensor construction from local tensor.,51,0,1,2,['Other']
72091,Windows Cuda 11.5 cudnn 8.3.2.44 fails tests with RuntimeError: cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.,0,0,4,4,['Bug']
72086,"torch.distributed.run segfault, probably with python 3.10",182,0,4,3,['Bug']
72074,PyTorch CI should somehow track number of tests executed for PR and notify about sudden changes,270,1,2,4,['enhancement']
72073,FBGEMM submodule has not been updated in PyTorch repo in a while,18,0,2,3,['Critical']
72069,Compiling pytorch from source on Apple M1 makes clang crash,0,0,3,4,['Critical']
72057,[INSTANCENORM] Instance Normalization ignores track_running_stats=True when exporting to ONNX.  ,16,0,3,3,['Other']
72056,cross_entropy_loss edge case,1,0,2,3,['Other']
72054,[FSDP] Summon full parameter on CPU,247,1,1,2,['Other']
72049,Fusing Linear + BatchNorm1d Fails,77,1,2,4,['Critical']
72047,Counter intuitive behavior of nn.CrossEntropy/nn.NLLLoss with weights and issue with gradient accumulation,3,0,5,3,['Other']
72026,Test fail on windows with cudnn v8.3.2.44 and cuda 11.5 ,2,1,2,2,['Other']
72012,Compiler warning with GCC11 (torch/csrc/jit/frontend/ir_emitter.cpp),3,0,1,1,['Other']
71994,TorchScript doesn't support `input` keyword argument,27,1,5,3,['Critical']
71991,How to make an LSTM Bidirectional?,0,0,2,0,['Other']
71987,Improve autograd codegened automatic inplace formulas,79,1,0,5,['Other']
71980,Torch.tensor.sum() has severe precision issue even with a small amount of numbers with FP64,0,0,0,0,['Other']
71975,"PyTorch/XLA jobs are not being run on PR CI, even with ciflow/all",0,0,2,2,['Other']
71973,[UBN!] Not all tests are being run,6,1,16,3,['Critical']
71969,[REBASE ON MASTER] CI broken for forked pull requests,0,0,0,2,['Other']
71967,Windows: Support Jiterator Cache,5,0,1,2,['Other']
71964,XLA broken on master after https://github.com/pytorch/pytorch/commit/84f168539725292d0b824c30d1d872fb30811803,11,0,10,4,['Other']
71946,Remove Python 3.6 references from the codebase,11,1,0,3,['Other']
71914,"RuntimeError: Caffe2 -The tensor has a non-zero number of elements, but its data is not allocated yet",15,0,2,2,['Bug']
71910,untimeError: cuDNN filters (a.k.a. weights) must be contiguous in desired memory_format,4,0,3,0,['Other']
71878,docker builds are broken after AMI update,0,0,2,6,['Critical']
71857,DISABLED test_neg_view_linalg_det_singular (__main__.TestMathBits),0,0,4,4,['Critical']
71848,Incorrect usage of `TORCH_INTERNAL_ASSERT` and `TORCH_CHECK`,0,0,2,3,['Other']
71844,Migrate master to main: https://github.com/pytorch/examples ,34,1,0,3,['Other']
71829,Migrate master to main: https://github.com/pytorch/cpuinfo ,314,0,1,2,['Other']
71827,Migrate master to main: https://github.com/pytorch/contrib ,33,0,3,2,['Other']
71811,Migrate master to main: https://github.com/pytorch/dr-ci ,57,0,1,2,['Other']
71809,DISABLED test_fn_fwgrad_bwgrad_gradient (__main__.TestGradients),0,0,4,3,['Critical']
71808,DISABLED test_fn_grad_linalg_det_singular_cuda_float64 (__main__.TestGradientsCUDA),6,0,8,5,['Critical']
71786,ONNX export for sparse_coo_tensor,8,0,1,3,['Other']
71770,DISABLED test_data_parallel_module_cuda_float16 (__main__.TestDataParallelDeviceTypeCUDA),187,0,2,4,['Other']
71754,PyTorch convert function for op 'deform_conv2d' not implemented.,0,0,1,1,['Other']
71753,Bug of pytorch 1.10 for NVIDIA RTX a6000,0,0,4,3,['Bug']
71736,tensors with more elements than the int32 max val don't quantize correctly,23,1,2,1,['Other']
71732,XLA tests are failing,2,0,2,3,['Other']
71720,Old warnings from F.interpolate docs should be cleaned up,8,0,4,5,['Other']
71716,Nightlies not building since 1/21/22,0,0,1,2,['Other']
71712,BLAS options: OpenBLAS vs Accelerate,16,0,11,4,['Other']
71701,"[feature request] [discussion] torch.lerp: optimize exact 0.0, exact 1.0 weight to force exact copy",9,0,4,3,['enhancement']
71695,torch.onnx.export creates model with TopK node that may be invalid,273,1,6,3,['Other']
71686,Support the `bitwise_invert` alias to `bitwise_not` ,1,1,0,1,['Other']
71676,Caffe(PyTorch)-on-Spark? ,8,0,0,1,['Other']
71674,`torch.set_default_dtype` will crash with `complex` dtype,32,1,13,4,['Critical']
71672,PAGE_FAULT_IN_NONPAGED_AREA,320,0,4,5,['Other']
71657,libtorch cannot be consumed by C++20 project,163,0,3,2,['Other']
71652,Sparse CSR tensors crash `state_dict()` (1.11 nightly),39,0,2,3,['Critical']
71645,INTERNAL ASSERT in svd_cpu,6,1,3,4,['Critical']
71638,[feature request] Upstream to core PyTorch antialiased interpolation,4,0,5,2,['enhancement']
71632,[Pytorch 1.10.1] fail to install using pip and python 3.10.1,0,0,2,2,['Other']
71617,iOS tests were dropped from CI during CircleCI->GHA migration,18,1,2,5,['Critical']
71616,Effective memory leak due to head-of-line blocking in CUDACachingAllocator `process_events`.,12,0,5,2,['Other']
71614,Complex GRU does not work,0,0,1,2,['Other']
71610,`torch.linalg.solve` INTERNAL ASSERT FAILED,53,1,3,2,['Other']
71592,Merge to master currently blocked,0,0,5,2,['Other']
71572,Can't except IndexError when indexing a CUDA Tensor with a Tensor,0,0,3,2,['Bug']
71563,GHA: Use retryable steps,281,0,2,2,['Other']
71553,DISABLED test_interval_stat (__main__.TestMonitor),0,0,3,2,['Other']
71550,Assert Tripped in cross entropy when using expanded tensor,0,0,4,6,"['Critical', 'Bug']"
71549,ONNX: Wrong output shape for ceil_mode Pooling,281,1,2,4,['Bug']
71547,An #define error in THC,0,0,1,0,['Other']
71544,Typo in torch.optim.lr_scheduler.LinearLR example,1,0,1,3,['Other']
71496,DISABLED test_auto_wrap_smoke_test_fsdp_init_mode_FSDPInitMode_CUDA_BEFORE_cpu_offload_CPUOffload(offload_params=False) (__main__.TestAutoWrap),1,1,3,2,['Other']
71478,DISABLED test_pointwise_op_fastpath__foreach_addcmul_cuda_int16 (__main__.TestForeachCUDA),329,0,2,5,['Critical']
71468,Unexpected behaviour of `torch.nn.CosineSimilarity`,0,0,1,0,['Other']
71458,[rpc] Wrong usage of RRefContext::handleException,232,0,7,3,['Other']
71454,Randperm changes when moving to GPU,0,0,1,0,['Other']
71418,DISABLED test_basic_checkpoint_end_to_end_cpu_offload_CPUOffload(offload_params=False)_offload_activations_True (__main__.TestFSDPCheckpoint),163,1,3,4,['Other']
71415,grid_sample backward pass performance scales poorly with input size,36,0,2,5,['Other']
71408,onnx export output wrong dynamic axes,97,0,3,3,['Other']
71406,torch.linalg.solve updates are causing GPyTorch tests to fail,56,1,1,3,['Critical']
71405,torch.bincount doesn't seem to output the result based on minlength,3,0,2,1,['Other']
71402,Could not run 'aten::empty_strided' with arguments from the 'CUDA' backend,37,1,8,2,['Other']
71400,rnn module uses cuda:0 even it moved into cuda:1 by to('cuda:1'),0,0,2,3,['Other']
71394,"Onnx export in different version behaves differently, BatchNorm operator has multi output ",139,0,3,3,['Other']
71385,`torch.linalg.solve` is not consistent with `A.inv @ B`,35,0,6,4,['Other']
71384,"`torch.linalg.tensorsolve(A, B)` is inconsistent with `tensordot(inv(A), B)`",35,0,1,2,['Other']
71382,Possible improvements for `torch.linalg.cholesky` and `torch.linalg.cholesky_ex` to handle positive-semidefinite matrix inputs,1,0,7,3,['enhancement']
71381,Cannot import PyTorch in Alpine Docker Container,0,0,4,0,['Other']
71380,torch.fx not support collective communication operators,0,0,1,1,['Other']
71365,"{TypeError}pad_sequence(): argument 'sequences' (position 1) must be tuple of Tensors, not Tensor",25,0,2,6,"['Critical', 'Bug']"
71362,Unequal padding for MaxPooling,3,0,6,4,['enhancement']
71361,Adding node and cell names for tensorboard graph,2,0,5,0,['Other']
71360,"Trying to run build_libtorch.py getting, ""No module named 'typing_extensions'",2,0,3,1,['Other']
71347,[ZeRo] Parameter group support in constructor,39,1,5,3,['Other']
71346," UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/aten/src/ATen/native/BinaryOps.cpp:467.) Exception ignored in: <_io.FileIO name='test_augmented.txt' mode='wb' closefd=True> ResourceWarning: unclosed file <_io.TextIOWrapper name='test_augmented.txt' mode='w' encoding='utf-8'>",0,0,1,0,['Other']
71339,locally installed PyTorch upgraded or superseded on windows/macos conda tests,0,0,0,0,['Other']
71325,[RFC] Hierarchical Model Averaging (Hierarchical SGD),113,2,8,3,['enhancement']
71320,numpy dependency issue causing many test failures across CI,0,1,9,2,['Other']
71314,Structured Kernel Precompute codegen should handle fields that don't replace anything,24,0,0,3,['Other']
71313,import of pandas makes import of torch much slower,4,1,1,3,['Other']
71297,TestSparseCSRCUDA.test_block_triangular_solve_cuda_complex128 fails on A100,74,1,4,4,['Other']
71280,torch dependencies aren't fully specified + pkg_resources import is slow,5,1,13,3,['Other']
71278,Lowering arbitrary ops in Lazy Tensor Core,206,0,0,2,['Other']
71265,Move `AT_ERROR` to `TORCH_CHECK(false`,0,0,3,1,['Bug']
71264,expected scalar type Float but found UNKNOWN_SCALAR when running model using vulkan backend on Android,25,1,8,1,['Other']
71262,torch.save saves unneccessary information ,0,0,2,0,['Other']
71260,No nightly builds after 2022-01-10,0,1,3,4,['Critical']
71257,`functional.max_poolNd` warnings are spamming the CI (~15000 times),50,1,0,2,['Other']
71229,DISABLED test_multiprocessing_contexts (__main__.TestDataLoader),336,0,6,3,['Other']
71221,`StreamWrapper` does not work with `open`,28,1,2,2,['Other']
71208,Typos in channel-last docs,7,0,0,2,['Other']
71207,ONNX: export custom model to ONNX leads to different output,307,0,2,3,['Other']
71206,Why is Multi-processing Pool slower than Singleprocessing?,0,0,1,2,['Other']
71188,Regression Bug in `torch.nn.functional.interpolate`,23,0,3,5,"['Bug', 'Critical']"
71160,ZeroTensor with 'cuda' device doesn't correctly set the CUDA dispatch key,19,0,1,2,['Other']
71154,``nn.Conv2D`` is not translation-equivariant.,1,0,2,3,['Other']
71150,RuntimeError: Exporting the operator uniform to ONNX opset version 12 is not supported.,0,0,0,0,['Other']
71131,[JIT] Allows nested dictionaries to store Hyperparameters alongside models.,79,0,0,1,['Other']
71127,[RFC] Make `c10/util/complex.h` include-free,21,0,4,2,['Other']
71124,Activation checkpointing breaks bfloat16 AMP,16,0,6,4,['Other']
71119,Custom function forward-mode AD internal assert when returning same tensor,22,0,3,4,['Critical']
71118,Custom function forward-mode AD segfaults when non-tensor argument precedes tensor argument,17,0,0,4,"['Critical', 'Bug']"
71112,PyPI wheel for Python 3.10 missing,1,0,1,3,['enhancement']
71109,Sort produces incorrect indices when run on a complex tensor viewed as real,0,0,0,2,['Other']
71108,Convolution for complex tensors,295,1,6,5,"['Critical', 'enhancement']"
71105,[docs] Make examples in docs into auto-runnable smoke tests,213,0,3,3,['Other']
71098,in-place version API does not match the broadcast shape,0,0,2,0,['Other']
71096,Obliviate ALL_TENSORTYPES and ALL_TENSORTYPES2,15,1,3,4,['Other']
71094,`embedding_bag` will trigger segmentation fault in Linux,22,1,3,6,"['Critical', 'Bug']"
71092,falseINTERNAL ASSERT FAILED,72,0,7,6,['Other']
71090,`rand_like()` function with same `manual_seed` give transposed results given contiguous and non-contiguous argument.,0,0,5,0,['Other']
71089,Segfault using `torch.unique` on tensor with NaNs with `dim=0` on PyTorch 1.10,10,1,4,4,"['Critical', 'Bug']"
71085,`Tensor.baddbmm_` unexpectedly succeeds!,2,0,2,4,['Critical']
71083,No module named 'torch',0,0,4,0,['Other']
71080,Floating point exception when `groups=0`!,144,1,5,6,"['enhancement', 'Bug']"
71079,[C++] Inference Pytorch and TensorRT got errors on Windows,30,0,18,2,['Bug']
71075,Let size=() by default,0,0,2,0,['Other']
71074,I can't build for LibTorch on aarch64. Cannot find libcublas.so,1,0,1,0,['Other']
71070,"Mypy error with Tuple[torch.Tensor, ...], error: <nothing> has no attribute ""shape""",0,0,0,0,['Other']
71068,"grad_in, grad_out during ""full backward hook"" is not freed and memory leak occurs.",0,0,0,0,['Other']
71067,Sparse -> Dense Tensor Assertion Error,0,0,1,0,['Other']
71066,Add dim to view_as_real and view_as_complex,178,0,5,2,['Other']
71063,Noisy warning raised by 'default_collate',12,0,2,2,['Other']
71062,RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.,9,0,10,3,['Bug']
71037,DISABLED test_builtin_collection_conversion (__main__.TestDataLoader),341,0,6,3,['Other']
71009,DISABLED test_checkpoint_fsdp_wrapping_cpu_offload_CPUOffload(offload_params=False)_offload_activations_True (__main__.TestFSDPCheckpoint),174,1,2,4,['Other']
71005,Automatically Detect and Remove Flaky Tests,234,1,3,2,['Other']
71003,CI: Removing Network Connectivity Risks,294,0,3,2,['Other']
71002,Torch RNN allocating memory on the wrong GPU device during forward pass,0,0,1,0,['Other']
70994,no wheel for Python 3.10.1,3,1,2,4,['Critical']
70992,The strides of input_grad tensor of backward function of torch::autograd::Function<> of torch's C++ API.,0,0,0,0,['Other']
70985,Gather tensor in different gpu,3,0,3,0,['Other']
70984,ModuleNotFoundError: No module named 'torch.nn.modules.instancenorm',194,0,4,4,['Bug']
70976,DISABLED test_sampler (__main__.TestDataLoaderPersistentWorkers),80,0,2,2,['Other']
70975,Error in `Tensor.ravel` documentation,4,1,2,2,"['Documentation', 'Bug']"
70972,Error in `Tensor.triu` and `Tensor.tril` documentation,4,1,4,2,"['Documentation', 'Bug']"
70969,fx2trt tests not running?,301,1,8,3,['Critical']
70968,DISABLED test_no_segfault (__main__.TestDataLoaderPersistentWorkers),340,0,6,3,['Bug']
70959,`_dp_init_subclass` fails on `typing.Annotated`,1,1,2,3,['Other']
70947,DISABLED test_multiple_dataloaders (__main__.TestDataLoaderPersistentWorkers),343,0,6,3,['Other']
70923,type promotion is broken in `torch.where`,0,0,2,3,['Other']
70912,Tests in test_nn fail when compiled without LAPACK support ,5,0,1,2,['Other']
70909,`finfo(...).tiny` should be aliased to `finfo(...).smallest_normal`,133,1,1,2,['Other']
70902,Bilinear upsampling is very slow when quantized for channels last format,5,0,0,1,['Other']
70898,`libtorch.a` is not in pytorch `static` zip archives,159,0,3,3,['Other']
70890,DISABLED test_median_nan_values_cuda_float64 (__main__.TestReductionsCUDA),0,0,2,2,['Other']
70886,operator nan_to_num to ONNX,55,1,5,4,['Other']
70885,"Convert torch model metts error : """"number of dims don't match in permute",2,0,2,2,['Bug']
70883,DISABLED test_median_nan_values_cuda_float64 (__main__.TestReductionsCUDA),83,0,1,2,['Other']
70882,Undefined references in libtorch_python.so when linking custom ops in C++,16,0,11,1,['Other']
70881,Fix docker update race condition,148,1,4,5,['Critical']
70878,DISABLED test_median_nan_values_cuda_float32 (__main__.TestReductionsCUDA),84,0,1,2,['Other']
70877,DISABLED test_broadcast_stress_cuda (__main__.ProcessGroupGlooTest),112,0,4,3,['Other']
70876,DISABLED test_median_nan_values_cuda_float16 (__main__.TestReductionsCUDA),84,0,1,3,['Other']
70875,DISABLED test_caching_pinned_memory_multi_gpu (__main__.TestCuda),159,0,4,3,['Other']
70874,DISABLED test_sort_cuda (__main__.TestSortAndSelectCUDA),84,0,1,2,['Other']
70868,Long queue times for GHA workflows,0,0,3,2,['Other']
70756,DISABLED test_batch_sampler (__main__.TestDataLoaderPersistentWorkers),342,0,6,3,['Other']
70751,rocm jobs failing on master due to no space on device,289,0,1,3,['Other']
70700,"Received `t == DeviceType::CUDAINTERNAL ASSERT FAILED at ""../c10/cuda/impl/CUDAGuardImpl.h"":24, please report a bug to PyTorch. `",0,0,4,0,['Other']
70676,Tests fail if built with USE_DISTRIBUTED=0,1,0,1,1,['Other']
70675,`torch.index_select` will return a random value if input tensor is empty,146,1,4,4,['Other']
70674,`torch.amax` and `torch.amin` will return random value if input tensor is empty,62,0,5,3,['Other']
70670,Tests in test_constraints fail when compiled without LAPACK support,41,0,1,2,['Other']
70667,TORCH_DISTRIBUTED_DEBUG not effective,118,2,10,4,"['Bug', 'Critical']"
70664,torch.fft.rfft2 doesn't support half dtype,356,0,5,4,['Other']
70657,torch.ravel does not return contiguous flattened tensor (as documented),82,1,4,2,['Other']
70655,DISABLED test_no_segfault (__main__.TestDataLoader),82,0,3,3,['Bug']
70645,Improve CI timeout debuggability,5,0,3,3,['Bug']
70640,DISABLED test_conv_double_backward_cuda (__main__.TestNN) (dtype=torch.float64),1,0,5,3,['Critical']
70620,dbr quantization: add support for functional convolution variants,35,1,1,1,['Other']
70611,test_numba_integration passes tuple into cuda instead of array,9,0,1,2,['Other']
70607,test_jit_fuser_te not testing failures properly due to unexpected implicit string concatenation ,20,1,1,1,['Other']
70600,torch.cat without copying memory,0,0,3,3,['Other']
70598,[Nightly][1.2.0][CPU] Importing `torch.autograd.forward_ad` causes `ImportError: cannot import name '_DecoratorContextManager' from 'torch.autograd.grad_mode'`,0,0,1,0,['Other']
70595,Make MAX_NAME_COLUMN_WIDTH modifiable in PyTorch profiler,265,0,2,1,['Other']
70591,`torch.asarray` does not detect dtype of Python scalars,29,0,3,3,['Other']
70589,torch.nn.functional.conv2d produces different results on CPU and GPU,0,0,3,0,['Other']
70587,Provide an option to statically link MKL,62,0,1,3,['enhancement']
70578,"[torch.autograd.Function] The gradient function of the same result, but different gradients are obtained",48,0,4,2,['Other']
70572,JIT: strange timing with logical operators,20,0,2,1,['Other']
70570,Incorrect ONNX Export for Unidirectional Broadcasting in PReLU,44,1,8,2,['Other']
70562,DISABLED test_barrier_group (__main__.TestDistBackendWithSpawn),153,0,2,6,['Critical']
70560,Tests fail on viable/strict,2,0,1,3,['Other']
70548,amp fp16 is a fake one?,0,0,1,0,['Other']
70547,DISABLED test_proper_exit (__main__.TestDataLoaderPersistentWorkers),200,0,4,3,['Other']
70537,"After pytorch fixes the random seed, why can the results be repeated only in the first few epochs ?",154,0,4,3,['Other']
70536,torch.multiprocessing.Queue can not pass Tensor after the putting sub-process exits,82,0,1,2,['Other']
70525,C++ extension JIT import: module 'importlib' has no attribute 'abc' ,104,0,0,2,['Other']
70524,Unable to get attributes from Dataset,2,0,6,0,['Other']
70523,Segmentation fault in big enough grouped convolutions,188,0,13,8,"['Critical', 'Bug']"
70518,Weird output size of ConvTranspose3d!,0,0,0,0,['Other']
70517,DISABLED test_proper_exit (__main__.TestDataLoader),356,0,8,4,['Critical']
70516,DISABLED test_random_seed (__main__.TestDataLoaderUtils),357,0,10,3,['Other']
70515,Sigmoid result all zeros in the exported onnx model,0,0,1,0,['Other']
70512,Add docs for setting engines correctly for fbgemm/qnnpack,0,0,1,1,['Other']
70503,[not-user-facing] We should not use modules in test_quantized_op.py,0,0,1,1,['Other']
70497,RuntimeError: Exporting the operator uniform to ONNX opset version 10 is not supported,110,1,6,3,['Bug']
70495,at::real for real tensors.,35,0,8,2,['Other']
70492,`linear` works much slower for the tensor with float16 than float32,0,0,1,0,['Other']
70489,`torch.RRELU` will crash when the input tensor is empty when running on cuda,50,0,1,6,['Critical']
70486,"`torch.{addcmul,addcdiv}` triggers INTERNAL ASSERT FAILED",125,1,28,4,['Critical']
70466,Channel order changes the value of channel-wise sum,0,0,1,0,['Other']
70458,Rocm builds are failing since Nov 12,0,0,2,2,['Other']
70457,Python 3.6 decomission for Pytorch 1.11 release in the build pipeline,0,0,0,0,['Other']
70445,Error in `torch.dsplit` documentation,16,0,1,2,"['Documentation', 'Bug']"
70441,[feature request] - ModuleList concatenation,16,0,7,4,['enhancement']
70440,3D Convolution Transpose + Layer norm leads to error RuntimeError: ones needs to be contiguous,0,0,2,0,['Other']
70431,deleting model does not free space,1,0,2,0,['Other']
70426,"""INTERNAL ASSERT FAILED"" in torchmetrics.Accuracy#_accuracy_compute",14,0,4,3,['Critical']
70422,[libtorch] Is torchscript model thread-safety on GPU?,93,0,0,2,['Other']
70418,Rprop Algorithm Missing settng g_t =0 if gprev*g_t<0 :,140,0,1,5,['Other']
70417,Inconsistent results when running `cross_entropy` on CUDA and CPU,1,0,2,0,['Other']
70411,How to use custom dataset with SSD,2,0,1,0,['Other']
70405,Unable to use cuda with libtorch,1,0,1,0,['Other']
70404,DistributedDataParallel: GRU module gets additional processes on GPU 0 (1st GPU) and takes more memory,1,0,6,2,['Other']
70402,Run into MemoryError when loading Imagenet22K,88,0,2,2,['Bug']
70400,Technologies without activation function with more accurate data.,3,0,0,0,['Other']
70393,Windows build fails with Oneapi and DISTUTILS_USE_SDK=1 - Could NOT find OpenMP_CXX,395,1,6,4,['Other']
70390,[Bug] Failed to compile extension due to the latest setuptools,4,0,2,2,['Bug']
70389,[W accumulate_grad.h:184] ,45,0,2,3,['Other']
70382,"When I update `torchaudio` from 0.9.0 to 0.10.0, it raise an error `formats: amr-nb can't encode AMR-NB to 16-bit`",0,0,1,0,['Other']
70368,DISABLED test_basic_checkpoint_end_to_end_cpu_offload_CPUOffload(offload_params=True)_offload_activations_True (__main__.TestFSDPCheckpoint),188,1,3,6,['Critical']
70362,[nn] LSTMCell grad failure.,0,0,1,3,['Other']
70357,torch.sparse_coo_tensor._values() incorrectly returns a detached tensor,18,0,16,3,['Other']
70344,The DataLoader can't work in Apple Silicon.,340,0,14,5,['Other']
70303,"Compiling the Libtorch's minimum example failed with ""ld: library not found for -lmkl_intel_ilp64""",0,0,0,0,['Other']
70301,The signature of `multilabel_soft_margin_loss` in the doc misses `reduction` parameter,6,0,1,4,['Other']
70299,Exporting the operator inverse to ONNX opset version 10 is not supported,306,0,3,3,['Other']
70297,"fails to build with: no matching function for call to max(int, long int)",173,0,9,3,['Other']
70292,`lu_solve` will frequently crash,1,0,5,3,['Critical']
70289,Hubert onnx model inference problem,328,0,4,3,['Other']
70285,torch.fft.fftshift function switches color channels when the input tensor is 3D or higher dimension.,0,0,1,0,['Other']
70283,torch.utils.data.DataLoader - returned views support,13,0,5,5,['enhancement']
70280,How to create build-in buffers which is writable during onnx inference?,13,1,2,2,['Other']
70258,Multigpu tests timing out frequently ,0,0,1,3,['Critical']
70252,Norm function is not working for Tensors.,0,0,5,0,['Other']
70244," [feature request]how to merge many models to one model with shared backbone just use some code ,not a create a new model",2,0,1,0,['Other']
70237,“RuntimeError: std::bad_alloc” doing forward pass on CPU during deployment on certain hardware,15,0,4,3,['Bug']
70234,Why is the function 'torch.topk' inconsistent on cpu and cuda?,0,0,5,0,['Other']
70232,`AdaptiveAvgPool{2|3}d` should not create tensor with negative dimension!,9,1,0,5,"['Critical', 'Bug']"
70226,DISABLED test_cuda_memory_leak_detection (__main__.TestCuda),36,0,7,4,['Critical']
70211,The master doc on pytorch.org is stuck on the 12/3/21 version,1,1,3,1,['Other']
70186,Inconsistent interface of fuse_conv_bn_eval and fuse_linear_bn_eval,0,0,1,0,['Other']
70185,Missing Google Analytics from the pytorch-sphinx-theme in rendered docs,15,0,0,2,['Other']
70182,`torch.all` the result tensor of Conv2d triggers INTERNAL ASSERT FAILED!,21,0,4,4,['Critical']
70179,Invalid result when casting tensor from int64 to float16,0,0,1,0,['Other']
70177,"Inference mode complains about inplace at torch.mean call, but I don't use inplace",112,0,4,3,['Other']
70176,Error in Ubuntu cross-compiling,3,0,3,3,['Bug']
70175,Exception has occurred: NotImplementedError You must implement the backward function for custom autograd.Function.,0,0,1,0,['Other']
70134,Allow saved tensor hooks to be composed and nested,25,0,3,2,['Other']
70122,CUSOLVER_STATUS_EXECUTION_FAILED when using `torch.linalg.solve`,256,0,12,4,['Other']
70117,`torch.cuda.caching_allocator_alloc` and `torch.cuda.caching_allocator_delete` are undocumented,26,0,0,3,['Other']
70116,multiprocessing ProcessException (and subclasses) can't be pickled/unpickled,12,0,1,2,['Other']
70110,Dynamic axes incorrectly traced in nn.Embedding when exporting to ONNX,311,0,2,3,['Other']
70103,`FileLister` output should be sorted for distributed mode,46,0,2,2,['Other']
70097,Flatbuffers dependency causing dirty git checkout,13,1,12,4,"['Critical', 'Bug']"
70096,Nightly PyTorch is not updated the latest master branch previous day code,0,0,2,3,['Critical']
70094,how to get the pre operator of current opeartor in PyTorch？,0,0,1,0,['Other']
70091,use $(MAKE) instead of make -j in CMake Exterproject,0,0,1,2,['Other']
70083,FX: log spew during FX graph mode quantization due to get_attr targeting packed_params,0,0,1,1,['Other']
70053,[shard] determine if there's device overlap in pg,232,0,0,3,['Other']
70046,DISABLED test_fn_fwgrad_bwgrad_linalg_pinv_singular_cuda_complex128 (__main__.TestGradientsCUDA),1,0,2,3,['Critical']
70044,Anaconda channel has obsolete packages for old nightlies,1,1,1,2,['Other']
70043,Anaconda nightly builds don't prune osx-arm64 platform,4,0,0,2,['Other']
70042,"Run f.conv2d backward two times, grad not equal",2,0,1,3,['Other']
70032,Unresolved Symbol Linker Error c10::OperatorHandle::~OperatorHandle(void) ,5,0,3,6,"['Critical', 'Bug']"
70028,Pytorch profiler presents negative memory allocations,186,0,3,1,['Other']
70027,[rocm] Memory Exception on virtual address,49,0,3,6,['Critical']
69997,cdist backward fails if inputs to cdist are not contiguous,1,1,1,2,['Other']
69989,torch._C._jit_pass_dce removes code which is not dead,0,0,6,1,['Other']
69979,Use fmt::format instead of string concat,13,1,1,3,['Other']
69977,fx graph mode quant - torch.sort after quantization not scriptable,85,1,3,2,['Other']
69971,distributed linear algebra solutions,62,0,4,2,['Other']
69963,LayerNorm has extremely low SM Efficiency & is slow for large inputs,0,0,5,4,['Other']
69948,Windows Compilation failure with VS2022,36,0,5,3,['Other']
69925,Forward-over-reverse gradgradcheck fails for `torch.gradient` on CUDA,50,0,7,3,['Other']
69913,Forward-over-reverse gradgradcheck fails on CUDA for `div.floor_rounding`,55,0,5,3,['Critical']
69911,Instance check of subclass of `IterableDataset` fails on python 3.10,6,1,17,3,['Other']
69905,`torch.jit.operator_upgraders` introduces new runtime dependency to `yaml`,7,0,3,4,['Critical']
69903,RuntimeError: UNSUPPORTED DTYPE,6,0,1,1,['Bug']
69897,Forward-over-reverse gradgradcheck fails on ROCm for `cumulative_trapezoid` due to memory exception,58,0,3,3,['Other']
69894,AttributeError: module 'distutils' has no attribute 'version' : with setuptools 59.6.0,1,0,24,4,['Bug']
69887,Conflict between dataloader and cupy in single thread,1,0,1,4,['Other']
69868,Forward-over-reverse gradgradcheck failing for `trapz` and `trapezoid` on `meta` device,84,0,2,2,['Other']
69866,Forward-over-reverse gradgradcheck fails for `cumulative_trapezoid` on CUDA,58,0,0,2,['Other']
69865,Obliviate repeat_test_for_types usage in pytorch,27,0,1,4,['Other']
69859,[NNC] Fusion Error When Running With XNNPACK=0,1,0,1,1,['Bug']
69855,Some inplace ops fail for forward AD because they mutate ZeroTensor,10,1,5,2,['Other']
69847,Is torch.linalg.svd serial between GPUs?,0,0,2,3,['Other']
69842,Error exporting TorchScript model to ONNX - “ Module contains attributes values that overlaps”,312,1,4,6,['Bug']
69839,Using Autograd before and after forking should be possible,60,0,10,3,['Other']
69833,DISABLED test_conv_double_backward_cuda (__main__.TestNN),23,0,1,5,['Critical']
69832,Optionally return multiple tensors in forward call always returns multiple tensors,0,0,3,0,['Other']
69821,torch.argsort does not return correct order,0,0,0,0,['Other']
69813,Reduce boilerplate for the `_out` overload of structured kernels that require specific strides.,156,0,24,3,['Other']
69812,Wrong dependency specification in libc10.so,1,0,2,0,['Other']
69811,[feature request] Tensor.cuda_if(arg.cuda == True),1,0,2,0,['Other']
69808,quantized batchnorm parameters/buffers not saved in state_dict,15,0,1,2,['Other']
69797,[quant] Add support for ConvTranspose2d + BN fusion,27,1,1,1,['Other']
69792,Local build on MacOS is broken after flatbuffers update,2,0,4,5,['Critical']
69781,Python-3.6 based docker builds are broken,0,0,0,3,['Critical']
69779,Add summon_full_params API in PyTorch FSDP ,55,1,0,2,['Other']
69773,ROCM 4.1 nightly builds are broken since Nov12th,42,0,3,4,['Critical']
69761,torch.hub.set_dir() not expanding ~,103,0,0,4,['enhancement']
69746,nightly: missing `THC/THCDeviceUtils.cuh`,0,0,14,0,['Other']
69731,[RFC] Require users to set `torch.cuda.current_device()` appropriately for ShardedTensor,153,0,2,4,['Other']
69730,"Windows CI ""No module named 'torch'""",59,0,4,5,['Critical']
69722,[mitigated] The self hosted runner lost communication with the server,1,0,10,2,['Other']
69698,test_adadelta from test_optim.py fails on about 1/3 of seeds from exceeding the error threshold,27,0,8,4,['Bug']
69691,Follow Up on the usage for cudatoolkit across pytorch projects,285,1,7,4,['Other']
69683,Nightly/release conda builds are failing,85,0,5,2,['Other']
69679,"Is there an description for ""torch.nn.init.trunc_normal_()""?",0,0,2,0,['Other']
69675,hyperlink's displayed text,0,0,1,0,['Other']
69673,[torch.onnx.export] Some operations were disappeared when converting pytorch model to onnx model by torch.onnx.export,362,0,2,3,['Other']
69671,Quantized model (qnnpack) is slower than floating point counterpart and the output is corrupted,18,0,1,1,['Other']
69669,[Torch testing] TypeError: Type List cannot be instantiated; use list() instead,0,0,2,1,['Bug']
69666,undefined symbol curandCreateGenerator for torch extensions,121,1,30,7,['Other']
69664,libtorch can't link library with protobuf using cuda,0,0,1,0,['Other']
69659,DISABLED test_fs_pool (__main__.TestMultiprocessing),384,0,3,5,['Critical']
69653,Allow users to write their own ShardedTensor ops,12,0,1,3,['Other']
69646,Libtorch 1.10 GPU package size doubles to 2GB,0,0,1,0,['Other']
69605,Wrong onnx export for v1.10. LTS was correct,320,0,7,3,['Other']
69604,Unable to train yolov5 model when running from python manage.py runserver,0,0,1,0,['Other']
69602,LTC quickstart run failed,1,0,2,3,['Other']
69581,Issues with the compilation of libtorch c++ frontend without python dependencies.,13,0,3,3,['Other']
69572,"Hello, my laptop has AMD Ryzen 7 5700U processor with AMD Ryzen integrated graphic and Windows 11. I am trying to install Pytorch using pip and have tried every command I could find over Pytorch Installation discussion but none are working. Please help. working.",0,0,0,0,['Other']
69543,"[CircleCI, GHA] Runner capacity reduced, AWS services partially unavailable in us-east-1, expect long queues",0,1,7,2,['Other']
69542,Outdated PyTorch Distributed Documentation,0,0,0,1,['Documentation']
69540,GHA: fully clean our workspace between runs and remove problematic non-ephemeral runners,31,1,3,2,['Other']
69529,[Andrey] Research on possible managed solution to replace  Grafana Metrics,78,0,1,3,['Other']
69528,why 'torch.linalg.eigh' slow on GPU enven than that on CPU?,0,0,2,4,['Other']
69526,Why the reserved_memory space generated by the forwarding of Net can't be released?,6,0,0,4,['Other']
69525,Why not using welford algorithm in batchnorm (cpu)?,222,0,5,4,['Other']
69523,Meta definition of normal_ doesn't allow std equal 0,84,1,2,3,['Bug']
69518,`torch.sparse.addmm` does not check the dtype of zero tensor,73,1,5,3,['Other']
69515,libtorch at::Tensor::print() linking error,9,0,1,4,"['Critical', 'Bug']"
69509,Hippify script does not work,1,1,2,3,['Other']
69507,cross_entropy,0,0,1,0,['Other']
69500,flake8_hook.py incompatible with flake8 4.x,121,1,1,3,['Other']
69468,Distribution `kl_divergence` method,0,0,2,0,['Other']
69466,Distribution `mode` property,155,0,0,2,['Other']
69464,Update elementwise binary tests,118,0,2,4,['Other']
69463,Tracker: Jiterator improvements,385,0,4,4,['Critical']
69457,Replace instances of batchCheckErrors with new at::_linalg_check_errors,64,1,1,3,['Bug']
69455,Gradient Issue with Updating Parameters post-Initialisation,0,0,3,3,['Other']
69454,DISABLED test_type_promotion (__main__.TestBinaryUfuncs),0,1,1,2,['Other']
69449,'NAN' in model features,0,0,3,3,['enhancement']
69447,torch.stft() need to support 3D tensor,0,0,0,0,['Other']
69446,Unexpected Float64 type output for float input to default_collate,7,0,1,2,['Other']
69445,[Feature Request] Expose default_collate as a public method,8,0,1,2,['enhancement']
69444,[PYTORCH]: log error,88,0,6,3,['Bug']
69443,PyTorch profiler crash with segment fault,85,0,5,2,['Critical']
69441,How can I write my own activation function with cuda C++?,0,0,2,3,['Other']
69440,add python 3.10 support,0,0,2,2,['Other']
69429,"Why max(a, b) != relu(b-a)+a?",0,0,3,0,['Other']
69426,[quantization] Failed to save & reload quantized model,8,1,2,1,['Other']
69418,About the low GPU utilization！,3,0,2,2,['Other']
69417,import torch macos m1 --> ModuleNotFoundError: No module named 'torch',2,0,1,2,['Bug']
69414,"`torch.combinations(tensor, r)` should not fail when r=0",108,0,2,4,['enhancement']
69413,[bug] `parametrize` can't be used together with `swa_utils.AveragedModel`,223,0,2,5,['Bug']
69409,Docs: `torch.cartesian_prod` failed when input tensors have different dtypes,9,0,6,3,['Other']
69389,GHA: Mac test stats are not getting reported when tests fail,10,0,0,2,['Other']
69388,[ONNX] export of F.pad  with boolean pad  fails in constant_pad_nd,302,0,3,3,['Other']
69380,Ensure that the message for disabled tests is printed for disabled tests in CI,112,1,1,3,['Other']
69346,Dynamic output of Upsample causes InstanceNorm2d error in onnx.,192,1,8,3,['Bug']
69345,torchrun rerendezvous with different master addr and port,1,0,2,1,['Other']
69339,"`CrossEntropyLoss` doesn't work using all of `weight`, `label_smoothing`, and ignoring indices",5,0,5,3,['Critical']
69322,First and second derivatives for `nn.functional.fractional_max_pool2d` and `nn.functional.fractional_max_pool3d` are implemented incorrectly,21,0,2,5,['Other']
69307,torch.max/torch.min in Fx quantization might have a tuple ouput,53,1,2,3,['Other']
69305,Update conda `build_pytorch.sh` script and add conda binaries,3,0,0,2,['Other']
69302,PyTorch CUDA-11.5 readiness,157,1,2,4,['Other']
69300,Omicron,0,0,0,0,['Other']
69295,Add 11.5 to torchvision CI,83,0,1,3,['Other']
69293,[FR],0,0,2,0,['Other']
69285,"WARNING:root:This caffe2 python run failed to load cuda module:No module named 'caffe2.python.caffe2_pybind11_state_gpu',and AMD hip module:No module named 'caffe2.python.caffe2_pybind11_state_hip'.Will run in CPU only mode.",0,0,0,0,['Other']
69284,"`torch.hub` defaults to `master` branch, crashes if it is `main`",13,0,4,2,['Critical']
69283,how to get required arguments name in forward,0,0,1,0,['Other']
69279,Open source,0,0,1,0,['Other']
69275,skip pytorch errors,0,0,1,0,['Other']
69270,"torch.{h, v, d}split crash when sections = 0",50,0,3,4,['Critical']
69246,[Quant] Extra entries in model state_dict after FixedQParams refactor,1,1,1,1,['Other']
69240,Issues with build from source,0,0,3,2,['Other']
69235,The quantization scripts of TorchVision no longer work using the latest nightly of Core ,8,1,6,2,['Other']
69230,`torch.nn.functional.kl_div` silently ignores wrong inputs,215,0,0,4,['Other']
69223,MacOS test are failing after unrelated revert,1,0,6,5,['Other']
69222,Build of master failed with extra semicolons,146,0,3,2,['Other']
69220,Python3.10 Support,0,0,1,0,['Other']
69217,should I use with torch.no_grad() mode if my loss function needs to compute the gradients,0,0,1,0,['Other']
69214,Parameters of a model after .cuda() will be different objects with those before the call ?,0,0,1,0,['Other']
69209,Runtime Error when multipling complex32 with float32,228,1,6,4,"['Critical', 'Bug']"
69208,layer_norm cuda kernel generates wrong result when either `gamma` or `bias` is missing,0,0,1,2,['Other']
69205,The `extra_repr` of `nn.ZeroPad2d` is not correctly implemented,0,0,1,1,['Other']
69204,How to assign tensor to tensor,0,0,1,0,['Other']
69201,Support for cdist export to ONNX,330,0,3,3,['Other']
69200,warnings.warn('PyTorch is not compiled with NCCL support'）,0,0,1,1,['Other']
69196,Possible bug in torch.nn.init ?,0,0,0,0,['Other']
69190,"subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--target', 'install', '--config', 'Release', '--', '-j', '32']' returned non-zero exit status 2.",0,0,1,0,['Other']
69189,SGD: why not update gradient inplace when using weight decay?,1,0,2,2,['Other']
69187,Distributed tests are having a hard time on mac,0,0,2,3,['Critical']
69168,Run distributed tests with TORCH_CPP_SHOW_STACKTRACES=1,7,0,0,2,['Other']
69100,[v1.10.1] Release Tracker,15,1,12,2,['Other']
69081,Add CUDA 11.5 to install to windows AMI,13,0,0,2,['Other']
69077,Why the `torch.distributions.MultivariateNormal` did not inherited `torch.distributions.ExponentialFamily`? ,21,0,0,2,['Other']
69076,need to check manual_cpp_binding in gen_backend_stubs.py,121,0,5,4,['Other']
69073,Exporting the operator broadcast_tensors to ONNX opset version 12 is not supported,167,1,2,4,['enhancement']
69070,how to compute the real Jacobian matrix using autograd tool,1,0,2,2,['Other']
69068,how to build libtorch without mkl?,0,0,1,2,['Other']
69065,CircleCI MacOS builds are broken,0,0,1,3,['Other']
69047,LTC: Same backend being registered multiple times,56,0,2,3,['Other']
69042,output argument never used in softplus_backward?,30,0,3,3,['Other']
69034,"forward-mode AD: minimum, min, maximum, max formulas are loudly incorrect",128,0,2,4,['Other']
69017,distributed/algorithms/ddp_comm_hooks/test_ddp_hooks and distributed/algorithms/quantization/test_quantization don't run in OSS CI,213,0,0,4,['Other']
69016,CTCLoss value issue,0,0,2,0,['Other']
69014,Print details of why a test has been skipped in CI,116,2,2,5,['enhancement']
69005,Stop Python-3.6 nightly/binary builds,45,1,6,3,['Other']
69003,GLOO/NCCL connection issues [build from source],240,0,3,2,['Other']
68986,Shared Memory with mp.spawn doesn't seem to work,0,0,0,0,['Other']
68985,Graph API crashing when allocating memory,6,0,4,4,['Critical']
68980,Torchscript torch.jit.trace nvrtc: error: failed to open libnvrtc-builtins.so.11.1.,49,0,6,3,['Bug']
68975,RuntimeError: !node->kind().is_aten() && !node->kind().is_prim() && !node->kind().is_attr()INTERNAL ASSERT FAILED,91,0,2,3,['Bug']
68974,RuntimeError: Exporting the operator roll to ONNX opset version 11 is not supported. Please open a bug to request ONNX export support for the missing operator.,77,0,2,3,['Bug']
68973,torch.cuda.set_device documentation misleading,3,0,3,4,['Documentation']
68971,meshgrid index params,1,0,5,1,['Other']
68970,`torch.dsplit` will crash when `sections = 0`,7,0,1,5,"['Critical', 'Bug']"
68964,No AdaptiveAvg2dPool in Libtorch1.3?,2,0,2,3,['Other']
68960,"Add testing workflows for 11.5, Build Nvidia images",2,0,0,0,['Other']
68957,`torch.broadcast_shapes` should not handle shape with negative dimension,96,0,2,3,['Bug']
68956,Add the attr `_last_lr` for the schedular `SequentialLR`.,41,0,0,4,['enhancement']
68943,Couldn't export Python operator _FunctionCorrelation,4,0,2,2,['Other']
68941,Is the trick for hard gumbel_softmax is correct?,0,0,0,0,['Other']
68934,The dim is not checked strictly for a model in GPU,0,0,1,0,['Other']
68928,"[docs] {select, slice, diagonal}_scatter not available in documentation",4,0,1,4,['Documentation']
68918,Support for movedim export to ONNX,196,0,2,4,['enhancement']
68910,Add support for deform_conv2d export to ONNX,83,0,7,3,['enhancement']
68903,`torch.jit.freeze` and `torch::jit::freeze` are inconsistent,103,1,5,1,['Other']
68894,Tensor.copy_ to a slice fails silently,5,0,2,3,['Other']
68876,Two missing header files in package list.,280,1,8,3,['Other']
68875,`unfold` should not raise such error,7,1,2,5,"['Critical', 'Bug']"
68873,MaxUnpool2d docs have a misleading example using `output_size`,9,0,4,3,['Other']
68872,reduction parameter in nn.NLLLoss() depricated?,0,0,2,2,['Other']
68868,Weight gradient computation is incorrect with mkldnn,74,0,6,7,"['Critical', 'Bug']"
68865,pytorch build from souce code third_party <ios-cmake>  error,0,0,0,0,['Other']
68850,DISABLED test_server_process_global_profiler (__main__. TensorPipeRpcTest),6,0,2,4,['Critical']
68849,DISABLED test_RNN_dropout_state (__main__.TestNN),384,0,3,6,['Critical']
68848,DISABLED test_async_function_raise (__main__.TensorPipeRpcTest),6,0,2,4,['Critical']
68847,DISABLED test_variant_consistency_jit_dist_cpu_complex64 (__main__.TestJitCPU),120,0,2,5,['Critical']
68846,DISABLED test_kineto_profiler_api (__main__.TestProfiler),390,0,2,5,['Critical']
68845,DISABLED test_common_errors (__main__.RendezvousEnvTest),6,0,2,4,"['Critical', 'Bug']"
68844,DISABLED test_timeout (__main__.TestDataLoaderPersistentWorkers),385,0,4,5,['Critical']
68833,[DDP] Static graph should print out unused parameters when they are detected. ,246,2,1,5,['Other']
68832,DISABLED test_owner_rref_backward (__main__.TensorPipeRpcTest),7,0,2,4,['Critical']
68831,DISABLED test_fd_sharing (__main__.TestMultiprocessing),385,0,5,5,['Critical']
68820,ChainedScheduler get_last_lr not working,9,1,2,4,['Critical']
68813,torch.kthvalue returns random value when the k is invalid,9,1,1,5,"['Critical', 'Bug']"
68811,pytorch GPU version for Mac,8,1,5,2,['Other']
68805,Recursive update in `ShardedTensor.state_dict` hook is inefficient,20,0,2,1,['Other']
68799,the example of torch.empty_like is torch.empty,1,0,1,3,['Other']
68796,Figure out why sccache is not working for Windows CPU builds,1,0,1,3,['Other']
68760,gradgrad of `nn.functional.prelu` is broken for noncontiguous inputs,402,1,6,6,['Critical']
68747,PyBind11 doesn’t recognize `torch._C.ScriptModule` as `torch::jit::Module`,0,0,5,1,['Other']
68741,torch.cartesian_prod throws warning when running example from docs,25,0,3,2,['Other']
68739,GIL is not released in THPVariable_setitem,64,1,1,5,['Critical']
68735,Cannot use DDP with NCCL backend on A100 GPUs,137,0,24,4,['Critical']
68729,How to specify the backends when running on CPU,0,0,1,0,['Other']
68727,"nn.MaxUnpool{1,2,3}d does not handle the invalid input when running in CUDA",182,1,8,6,"['Critical', 'Bug']"
68724,Exported onnx graph is invalid when using a traced module with Conv and BatchNorm inside a scripted module with If,358,1,2,2,['Other']
68716,DISABLED test_default_store_timeout_nccl (__main__.TimeoutTest),51,0,3,4,['Other']
68702,MultiHeadAttention docs are unnecessarily confusing.,1,0,3,0,['Other']
68700,Typos of documents,1,0,0,3,['Other']
68698,Questions about the inconsistent (slightly different) results obtained from multiple runs of nn.NLLLoss,1,0,3,4,['Question']
68686,the center loss ,2,0,4,0,['Other']
68685,1.10 build error on windows (CUDA 10.2),2,0,3,4,['Bug']
68684,discuss.pytorch.org is down,2,0,1,0,['Other']
68667,Linux + add MAGMA to CI conda,0,0,0,0,['Other']
68646,docker bug,1,0,5,3,['Bug']
68642,Encountered 'internal compiler error: Segmentation fault' when compile pytorch on linux,0,0,10,3,['Bug']
68635,quantization of basic 3D ops missing?,18,0,3,2,['Other']
68634,[Numeric Suite] support for multiple inputs,66,1,2,1,['Other']
68621,Missing operators for SparseCsrCUDA,137,1,19,2,['Other']
68611,torch.cuda.is_available() ---> false,3,0,4,3,['Other']
68598,ONNX Export of LayoutLMv2,362,0,5,3,['Other']
68592,Add support for comparing meta tensors,97,0,8,3,['Other']
68590,sparse COO comparison strategy,97,1,13,3,['Other']
68589,`nn.functional.max_unpool`: shape deductation is not universal -- needs documentation,0,0,1,3,['Documentation']
68585,Encountered ./gen_rules.sh: not found error when compile pytorch on linux.,0,0,2,6,['Bug']
68582,Wrong check in optimize_for_inference,14,0,5,1,['Other']
68581,Quantization test `test_embedding_bag_linear` raises error when looping over three qengines,62,1,3,2,['Bug']
68577,Pytorch 1.9.1 cannot be built against cuda 11.4.2,0,0,2,3,['Other']
68576,"When `num_workers=0`, `prefetch_factor` is enforced to be `2` but this is missing from documentation",364,0,4,3,['Documentation']
68561,Unexpected conversion using .int(),0,0,3,0,['Other']
68558,[docs] SmoothL1Loss to document behavior at beta=0,48,0,1,4,['Other']
68554,torch.ops.aten is very broken internally,0,0,1,3,['Critical']
68548,Change comparison strategy for quantized tensors,55,1,25,2,['Other']
68543,PyTorch CI TTS Tracker,345,0,2,2,['Other']
68541,retry_on_connect_failures decorator appears to no longer work,2,0,3,4,['Other']
68540,Improve documentation about meaning of different qschemes,67,1,1,1,['Documentation']
68539,[DataPipe] Grouper causes perf regression,4,0,0,2,['Other']
68525,Deterministic integer indexing operation fails in indices size check / missing broadcast,13,0,4,4,['Other']
68524,UserWarning: Casting complex values to real discards the imaginary part,0,0,1,0,['Other']
68517,Torch.square(a-b)   != a^2 -2ab + b^2,0,1,2,0,['Other']
68515,Dependent dll library,0,0,1,0,['Other']
68502,[subgraph_rewriter] Subgraph rewriter removes unused argument from graph,252,0,1,2,['Other']
68501,"RuntimeError: falseINTERNAL ASSERT FAILED at ""../aten/src/ATen/MapAllocator.cpp"":300, please report a bug to PyTorch. unable to write to file </torch_85217_8371>",1,0,5,3,"['Bug', 'Critical']"
68482,Documentation for AdamW is wrong,51,0,2,3,['Documentation']
68480,"CI test clang-format failed to run, but shown as success",220,0,1,2,['Other']
68478,[c10d] ProcessGroupNCCL work inconsistent with ProcessGroupGloo,198,0,4,5,['Critical']
68476,ParameterDict should implement `.get` and `.setdefault`,30,0,4,4,['enhancement']
68459,Soft mandatory labeling for release notes ,187,1,24,5,['enhancement']
68425,`torch.where` produces nan in backward pass for differentiable forward pass,251,0,40,4,['Other']
68421,Removal Note in `parametrizations.spectral_norm`,2,1,6,4,['Other']
68418,"Why do I get ""CUDA error: illegal memory access"" instead of ""Cuda error: out of memory""? (at maxpool2d step)",300,0,8,5,"['Critical', 'Bug']"
68414,"I used libtorch train a model,how to convert it to onnx?",0,0,1,2,['Other']
68406,Previous Version out of date,27,0,1,3,['Other']
68392,[subgraph_rewriter] A small bug in subgraph_rewriter,253,0,1,2,['Bug']
68391,DISABLED test_forward_overlap (__main__.TestForwardOverlapWorldSizeTwo),143,1,3,6,['Critical']
68384,ONNX export support for torch.lerp,204,0,3,3,['Other']
68383,CUDA initialization makes DataLoader slower,86,1,6,6,['Critical']
68379,CI: Run tests in parallel on multi-gpu runner,108,0,2,2,['Other']
68362,"Autograd mechanics documentation (grad_fn._saved_self, .save_result)",52,0,2,4,['Documentation']
68327,Spectral Normalization issue.,0,0,1,0,['Other']
68326,Tensor.norm() returns incorrect results with float32 and large CPU tensors,189,0,1,4,['Other']
68322,Quantization: torch._make_per_channel_quantized_tensor doesn't work well,17,0,8,1,['Other']
68321,expected dtype XXX but got dtype XXX,4,0,2,3,['Bug']
68299,test_caching_pinned_memory_multi_gpu: Test has a race condition leading to flakiness,213,0,1,5,['Critical']
68278,quantized linear dynamic should get reduce range from the observer rather than overwritting it in qnnpack/fbgemm,214,1,0,1,['Other']
68270,CI: test cases run in subprocesses cannot be disabled,0,1,0,2,['Critical']
68265,_make_wrapper_subclass's storage_offset arg doesn't work,6,1,2,1,['Other']
68261,CI: Further shard ASAN tests,33,0,0,2,['Other']
68260,Shard mac tests on CI,16,1,0,2,['Other']
68259,Support CUDA 11.5,20,1,0,2,['Other']
68250,FX graph mode quantization broken for torchvision MobileNetV3,104,2,9,1,['Other']
68243,Can we register forward hooks for functional calls?,0,0,1,0,['Other']
68241,[FSDP] Implement a standalone _recursive_wrap that is not dependent on ConfigAutoWrap,54,1,1,3,['Other']
68222,DISABLED test_ddp_profiling_torch_profiler (__main__.TestDistBackendWithSpawn),264,1,6,5,['Critical']
68221,[JIT][C++ Parser] Bug in processing ternary expressions,109,0,3,1,['Bug']
68195,[FX] Canonical retracing procedure breaks for n-ary operator dispatch,74,1,0,1,['Other']
68189,DISABLED test_ddp_profiling_torch_profiler (__main__.TestDistBackendWithSpawn),131,0,2,6,['Critical']
68181,Out of gpu memory error when consolidate_state_dict,1,0,6,0,['Other']
68173,DISABLED test_ddp_sync_bn_training_vs_eval (__main__.TestDistBackendWithSpawn),259,0,19,5,['Critical']
68172,DISABLED test_Conv2d_naive_groups_cuda_float16 (__main__.TestNNDeviceTypeCUDA),193,0,2,6,['Critical']
68171,DISABLED test_nadam (__main__.TestOptim),403,0,23,5,['Critical']
68170,Can’t convert PyTorch model to ONNX: Multiple dynamic inputs needed,74,0,2,3,['Other']
68167,Why there isn't a `set_to_none` option for `zero_grad()` in libtorch?,18,0,1,5,['Other']
68145,Do pytorch 1.10.0 possibly support cuda 10.1?,0,0,2,2,['Other']
68132,Torchlib: Cannot instantiate a float tensor with {floatitem/2.} in constructor,0,0,1,0,['Other']
68125,DISABLED test_addmm_baddbmm_overflow_cuda_float16 (__main__.TestLinalgCUDA),6,0,4,4,['Critical']
68120,_all() takes 2 positional arguments but 4 were given. Occurred when translating all,0,0,1,2,['Other']
68117,`nn.functional.max_pool2d`: JIT shape checks fail in OpInfo tests.,105,1,2,2,['Other']
68116,In-place indexing like tensor.resize_,0,0,1,0,['Other']
68112,Question about wait() for asynchronous collective operations with NCCL,0,0,2,1,['Question']
68086,TorchBench V1 performance signal on 20211106,127,2,20,4,['Other']
68079,"""test_nadam"" is flaky on ROCm",281,0,3,5,['Critical']
68059,conda install does not seem to have files in torch/fx/experimental/fx2trt/passes,1,1,3,2,['Other']
68057,undefined reference to `at::native::DispatchStub` on ppc64le,27,0,7,3,['Other']
68053,[docs] `nn.Transformer` is not possible to be used to implement BERT,198,0,1,3,['Other']
68052,Add the `maximize` flag to all optimizers,330,0,11,3,['enhancement']
68050,Distributions for Symmetric Matrices.,42,0,2,2,['Other']
68048,[1.10.0]Conv2d grad bias gets wrong value for bfloat16 case ,29,0,5,5,['Critical']
68047,Windows Libtorch nightly tests have failed since last Saturday.,0,1,0,3,['Other']
68039,Upgrade macOS and iOS workflows to xcode 12.4+,15,0,1,4,['Other']
68034,1D convolution is broken for mkldnn tensors,6,1,1,7,['Critical']
68003,"Output shape of ONNX exported ""index_select"" function is wrong on pytorch 1.10.0",120,0,7,3,['Other']
68002,error: use of undeclared identifier 'FaultyTensorPipeRpcBackendOptions',2,0,4,3,"['Critical', 'Bug']"
67997,trying to install on jetson xavier NX,0,0,1,0,['Other']
67992,"INTERNAL ASSERT FAILED at ""/opt/conda/conda-bld/pytorch_1634272068185/work/aten/src/ATen/MapAllocator.cpp"":263",7,0,8,2,['Critical']
67991,"""Error1: torch._C._cuda_init() RuntimeError: No CUDA GPUs are available"" ALSO Error2:""NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.""",0,0,1,0,['Other']
67988,How can I get a Model Comparison Chart?,0,0,2,0,['Other']
67976,Why instance norm doesn't propagate channels last suggest memory format?,91,0,2,2,['Other']
67975,Trivial Bug in some of the torch.distributions.constraints implementations.,0,0,2,2,['Bug']
67974,USE_SYSTEM_PYBIND11 option ignored,357,0,1,3,['Other']
67971,Pytorch doesn't use last GB of GPU memory,1,0,3,3,['Other']
67967,Support for quantized model's function,30,0,5,1,['Other']
67966,1.9.1 Docker image is not available,1,1,4,3,['Other']
67965,how to set the quantized data type in QAT,2,0,1,1,['Other']
67959,Intellectual property owned by me,2,0,1,0,['Other']
67957,The `SequentialLR` Scheduler cannot use `ChainedScheduler`,2,0,1,0,['Other']
67956,Intel OpenFL: RuntimeError: mat1 and mat2 shapes cannot be multiplied (128x512 and 2048x4096),9,0,2,1,['Bug']
67947,`TestCommonCUDA.test_noncontiguous_samples_linalg_pinv_hermitian_cuda_float32` fails when TF32 is enabled,3,0,0,3,['Other']
67938,CMake Error at torch_generated_THCTensorIndex.cu.o.Release.cmake:281,6,0,1,2,['Bug']
67923,Unexpected lack of error when using nn.Linear and cuda,0,0,1,0,['Other']
67919,`torch.gradient` ignores dim argument when checking edge_order ,81,0,1,2,['Other']
67910,`test_softmax_64bit_indexing` requires >20GB CPU memory,32,0,3,4,['Other']
67907,Backwards-incompatible nn.GroupNorm in torch 1.10,0,0,2,3,['Other']
67906,"Dataloader----Why When multiple threads read data, only one thread is activated?",0,0,1,2,['Other']
67905,CUDNN 8.3.0 static library names have changed,111,1,8,5,['Other']
67904,Feature Request: zeros_like() from a dense tensor to a sparse tensor,6,0,0,5,['enhancement']
67903,The ONNX model is incomplete,374,0,4,3,['Other']
67897,Compile from source -> libublas.so undefined reference error,0,0,1,0,['Other']
67896,a syntax error in pytorch/torch/cuda/__init__.py ,3,0,0,1,['Bug']
67892,"[Docs] `torch.nn.Dropout2d` accepts 2D inputs, but it's not listed",178,0,2,3,['Other']
67866,[Cuda Stream/Event] Python API acces to cudaStreamWaitEvent,2,0,4,3,['Other']
67864,"INTERNAL ASSERT FAILED at ""../aten/src/ATen/MapAllocator.cpp"":263",194,0,40,4,['Critical']
67863,Feature Request: label smoothing CE loss for semantic segmentation ,19,0,2,4,['enhancement']
67852,Remove THStorage and THCStorage,25,1,0,3,['Other']
67849,[ONNX] Broken url for ONNX Runtime custom ops,3,0,2,3,['Other']
67848,`Generator` needs to be removed after iteration ends for `Demux` and `Forker`,5,1,1,2,['Other']
67842,Pytorch 1.10.0 missing fft support on android? RuntimeError: fft: ATen not compiled with FFT support,88,0,4,3,['Bug']
67839,nn.Linear / F.linear doesn't check for input shapes and instead throws CUDA OOM,0,0,3,0,['Other']
67831,DataLoader w/ memory pinning doesn't allow returning custom dict objects from custom data collator,78,0,2,3,['Other']
67827,"Can't backward through torch.lobpcg when using ""largest"" kwarg",4,1,1,4,['Other']
67800,forward AD inplace over view silently copies in some cases,1,0,0,2,['Other']
67774,[FX] wrap() statements for called functions not emitted in jupyter notebook environment,0,0,2,1,['Other']
67771,"When the result is negative, // operator behaves differently with a torch.Tensor than with a np.ndarray or a standard python value",1,0,3,2,['Other']
67770,torch.Tensor floor division with negative numbers behaves differently than python's //,0,0,0,0,['Other']
67767,Gradient test `test_fn_grad_linalg_det_singular_cpu_complex128` failing on CPU,232,0,6,4,['Other']
67764,"PyTorch 1.10.0, `distributed/optim/test_zero_redundancy_optimizer` fails on A100",1,0,4,1,['Other']
67763,Feature request: torch.special.gammainc backward pass support,10,0,6,4,['enhancement']
67762,A computer with 4 GPUs has different error.,0,0,1,0,['Other']
67757,How to build libtorch on aarch64 machine?,1,0,1,0,['Other']
67753,Enable profiling optional tensor types in Profiler,127,1,11,2,['Other']
67742,"[torch/elastic] Scale down does not work correctly when agent is killed with SIGINT, SIGTERM",2,1,3,3,['Other']
67724,runHealthCheck in ProcessGroupNCCL constructor causes extra cuda-context ,5,0,4,1,['Other']
67723,DISABLED test_pointwise_op_fastpath__foreach_addcmul_cuda_uint8 (__main__.TestForeachCUDA),415,0,5,5,['Critical']
67720,Alleviate sccache connectivity issues on CI,118,1,5,5,['Other']
67714,Add some profiling ranges to FSDP,213,1,0,4,['Other']
67713,CI: Add timeouts for GHA jobs,2,1,1,3,['Other']
67710,Preserve core dump as artifacts,131,1,1,3,['Other']
67699,Add retries to ecr get-login call: https://github.com/pytorch/pytorch/runs/3948026530,100,0,2,2,['Other']
67696,Warnings being produced when testing optim.,5,0,8,3,['Other']
67693,`test_svd_errors_and_warnings` tests fail on CPU,86,1,5,3,['Bug']
67685,VNNI detection in PyTorch 1.10.0 test suite fails,21,0,0,3,['Other']
67681,PicklingError encountered when using multiple GPUs,3,0,5,2,['Bug']
67678,Type torch::jit::Module converted to torch._C.ScriptModule,12,0,0,1,['Other']
67675,test_cond_cpu tests fail when running with `numpy` compiled against `OpenBLAS 0.3.15`,13,1,1,4,['Other']
67670,[ONNX] torch.flatten for 1D tensor results in wrong ONNX,377,0,2,3,['Other']
67669,[Python-3.10] Not Being Able to install PyTorch,0,0,11,2,['Other']
67660,Gradient tests failing for `max_unpool2d`,184,1,5,7,['Critical']
67658,Gradient tests failing for `max_unpool3d` (`test_fn_grad`),184,1,2,7,['Critical']
67657,Gradient tests failing for `max_unpool1d`,184,1,1,7,['Critical']
67654,CSR to COO conversion,37,0,1,3,['enhancement']
67644,Migrate macOS workflows to GHA,34,1,2,4,['enhancement']
67643,Migrate iOS workflows to GHA,0,1,1,4,['enhancement']
67627,Pytorch AssertionError: Torch not compiled with CUDA enabled [Pytorch],0,0,1,0,['Other']
67626,Get rid of the blocking call in RRefProxy,79,1,1,4,['Other']
67625,"GHA Auto-Scaling outage, ParameterLimitExceeded",0,1,6,2,['Other']
67620,libtorch tensor.to(torch::kCPU) took a lot of time,0,0,1,0,['Other']
67616,[distributed elastic] rendezvous brain split with etcd backend,0,1,39,1,['Other']
67615,[elastic] Keep rank 0 static during the distributed elastic training,0,0,4,1,['Other']
67612,[testing] `gradient` OpInfo tests fail in Python 3.10,31,1,7,3,['Other']
67611,"Convert pytorch to onnx, Unsupported: ONNX export of operator adaptive_avg_pool2d",63,0,3,3,['Other']
67610,LTC execution segfaults with nvfuser backend,114,0,0,3,['Bug']
67608,Query regarding commits being used for CI builds,0,0,1,0,['Other']
67607,DISABLED test_remote_script_udf (__main__.TensorPipeJitRpcTest),0,0,2,4,['Other']
67606,DISABLED test_create_store_single_server (__main__.DistributedUtilTest),0,0,4,2,['Other']
67605,DISABLED test_remote_script_udf (__main__.TensorPipeJitRpcTest),29,0,2,6,['Critical']
67604,DISABLED test_ddp_comparison (__main__.TensorPipeDdpComparisonTest),29,0,4,6,['Critical']
67601,Add optimizer to `ChainedScheduler`,9,0,2,2,['Other']
67600,`torch.distributed.broadcast` silently fails if incorrect group is given,2,0,4,1,['Other']
67596,How to upgrade the NCCL version of pytorch 1.7.1 from 2.7.8 to 2.11.4? ,2,0,1,0,['Other']
67592,RuntimeError: quantile() input tensor is too large,2,0,3,0,['Other']
67591,DISABLED test_create_store_single_server (__main__.DistributedUtilTest),3,0,2,2,['Other']
67581,The connection to the C10d store has failed,0,0,0,1,['Other']
67568,Check if XLA-specific failures marked with `onlyOnCPUAndCUDA` in TestNNDeviceType can be skipped on the XLA side,5,0,3,4,['Other']
67566,Sharing file for init_process_group and init_rpc can potentially cause issues due to destructor of file,342,1,3,3,['Other']
67558,`fwAD.dual_level` and `fwAD.unpack_dual` are both public API but undocumented,129,0,0,3,['Other']
67551,"Using nn.Conv2d with padding=""same"" supports a stride of 2, however it currently fails due to an error message",7,0,3,3,['Bug']
67549,Strange nested exception during wrong call of load_state_dict,84,1,7,4,['Bug']
67547,The connection to the C10d store has failed,3,0,3,2,['Other']
67539,std_mean and var_mean fail test_noncontiguous_samples under ASAN,236,0,1,3,['Other']
67538,DDP Exception ,3,0,11,3,['Other']
67528,During the Build LibTorch-Lite for arm64 Devices,172,0,5,5,['Other']
67527,I could't build from source.,439,1,4,3,['Other']
67523,rsub fails test_noncontiguous_samples,0,0,1,4,['Critical']
67522,sort fails test_noncontiguous_samples,0,0,1,5,['Critical']
67521,tile fails test_noncontiguous_samples,0,0,1,5,['Critical']
67519,repeat fails test_noncontiguous_samples,0,0,1,5,['Critical']
67518,take and put both fail test_noncontiguous_samples,0,0,1,5,['Critical']
67517,torch.norm's inf variant is incorrect when given non-contiguous inputs,207,0,4,5,['Critical']
67516,nn.functional.grid_sample fails test_noncontiguous_samples,0,0,1,5,['Critical']
67514,nn.functional.dropout fails test_noncontiguous_samples,0,0,1,5,['Critical']
67513,linalg.householder_product is incorrect when given non-contiguous inputs,34,1,2,5,['Critical']
67512,linalg.det fails test_noncontiguous_samples,77,1,0,5,['Critical']
67511,Several indexing operations fail test_noncontiguous_samples,0,0,1,5,['Critical']
67510,float_power fails test_noncontiguous_samples,0,0,1,4,['Critical']
67509,Spectral functions fail test_noncontiguous_samples,0,0,1,5,['Critical']
67508,einsum fails test_noncontiguous_samples,0,0,1,5,['Critical']
67507,diag fails test_noncontiguous_samples,0,0,1,5,['Critical']
67506,cov fails test_noncontiguous_samples,0,0,1,4,['Critical']
67505,clamp_scalar fails test_noncontiguous_samples,0,0,1,4,['Critical']
67504,cholesky_inverse fails test_noncontiguous_samples,0,0,1,5,['Critical']
67503,Many reductions and reduction-like operations fail test_noncontiguous_samples,0,0,1,6,['Critical']
67502,addcdiv and addcmul fail test_noncontiguous_samples,0,0,1,5,['Critical']
67488,masked.sum fails test_noncontiguous_samples,0,1,2,5,['Critical']
67487,masked.prod fails test_noncontiguous_samples,0,1,2,5,['Critical']
67486,masked.amin fails test_noncontiguous_samples,0,0,1,5,['Critical']
67485,masked.amax fails test_noncontiguous_samples,0,1,2,5,['Critical']
67479,BatchNorn2D is not different for different input shapes when used with batch_size=1,0,0,1,0,['Other']
67466,Remove TH/THC Storage functions for unused dtypes,3,1,0,3,['Other']
67461,Jacobian mismatch for `nn.functional.poisson_nll_loss`,55,0,0,6,['Critical']
67447,DISABLED test_set_dir (__main__.TestHub),146,0,2,5,['Critical']
67438,how to use torch.jit.script with toch.nn.DataParallel,0,0,3,1,['Other']
67433,nn.functional.embedding fails test_noncontiguous_samples on CUDA,0,0,1,5,['Critical']
67432,isin is incorrect when given non-contiguous inputs on CPU,84,0,2,5,['Critical']
67431,Printing the shape instead of values by default,0,0,2,0,['Other']
67428,Avoid converting Tensors to Scalars for ops that have Tensor (including optional) argument overload,195,0,14,2,['Other']
67427,[jit] script doesn't support bool-bool comparison,53,0,1,1,['Other']
67426,LinearLR Scheduler returning incorrect learning rate,19,0,3,2,['Other']
67419,[default_collate] Batch with inconsistent sequence length: replace raising RuntimeError with flatten+offset handler,11,0,6,4,"['Bug', 'enhancement']"
67418,Confused about converting the model to onnx in libtorch.,0,0,1,0,['Other']
67415,torch.nn.Flatten()  docstring,12,0,2,4,['Other']
67414,`ExternalStream` is left undocumented,76,0,0,3,['Other']
67393,Missing doc for torch.onnx functions,8,1,1,4,['Other']
67391,Missing doc for torch.hub functions,13,0,4,3,['Other']
67386,add `set_deterministic_debug_mode`,14,1,2,2,['Bug']
67384,RFC: Should matmuls use tf32 by default?,190,0,15,2,['Other']
67383,Circle CI undergoing VM assignment issues,0,0,1,2,['Other']
67367,Multi-output forward grad codegen is wrong if output values are used,22,0,4,3,['Critical']
67361,"c10/util/variant.h is incompletely vendored into c10, resulting in build errors in some cases",1,0,3,2,['Bug']
67353,[BUG] Can't SSH into a CI-Build,0,0,1,0,['Other']
67352,[GHA] Long queue times for linux GPU workflows,0,1,2,3,['Other']
67338,how to get the rank list in a new group,8,0,5,1,['Other']
67330,Compiling error when using Libtorch 1.10.0  on windows ,0,0,2,2,['Bug']
67320,Exporting the operator affine_grid_generator to ONNX opset version 13 is not supported,383,1,4,3,['Other']
67318,`torch.optim.lr_scheduler.SequentialLR` doesn't have an `optimizer` attribute,1,0,2,2,['Other']
67305,PyTorch EmbeddingBag flag include_last_offset works very interestingly,0,0,4,3,['Other']
67302,Error when running torch.onnx._optimize_trace after torch.onnx.export,384,1,2,3,['Bug']
67301,Migrate `android-ndk` build from CircleCI to GHA,72,1,1,3,['Other']
67295,DISABLED test_sharding (__main__.TestZeroRedundancyOptimizerDistributed),415,1,2,2,['Other']
67291,TorchBench perf score increases 0.8% (speedup) on 20210620 ,0,0,1,0,['Other']
67290,PyTorch ModuleList doesn't work with DataParallel,100,0,1,3,['Other']
67288,[FSDP][BE] Rename some methods/streams,442,1,2,3,['Other']
67287,DISABLED test_add_param_group (__main__.TestZeroRedundancyOptimizerDistributed),400,0,4,2,['Other']
67285,CUDA Graphs (operation would make the legacy stream depend on a capturing blocking stream),244,0,1,2,['Other']
67244,Support automatic infer the ShardingSpec in init_from_local_shards,148,0,0,3,['Other']
67243,Is there anything wrong with the example of torch.argsort in docs?,0,0,2,0,['Other']
67239,channels_last significantly degrades accuracy,8,0,16,5,['Critical']
67235,Questions about the function or backward or autograd,0,0,1,0,['Other']
67233,`is_autocast_cpu_enabled` not working as expected,0,0,4,3,['Other']
67232,Issue with .version,0,0,1,0,['Other']
67227,Suggest adding the words 'Chi-squared' to the docstring of the Chi2 distribution to be explicit,3,0,1,3,['Other']
67224,[FSDP] CPU offload feature,204,1,1,3,['enhancement']
67212,Can not compile cpp/cuda extensions for any version of pytorch/cudatoolkit,0,0,1,0,['Other']
67186,RuntimeError: Found no NVIDIA driver on your system. - issue on linux screen,4,0,6,1,['Bug']
67185,Numerical inconsistencies on GPU when computing A.T@B vs (B.T@A).T,315,0,2,3,['Other']
67183,Exponential distribution constraint should be non-negative rather than positive,8,0,0,2,['Other']
67182,half model inference do not reduce memory usage,0,0,1,0,['Other']
67180,Gradient of nansum and nanmean wrongly produces `nan`,273,0,5,2,['Other']
67179,"how can I implement indexing operation in C++ like output[index, :] in python?",0,0,6,0,['Other']
67175,PyTorch Installation Error,0,0,4,0,['Other']
67173,[BUG]Multiprocessing conflicts with torch,0,0,0,0,['Other']
67172,TCPStore( TypeError: __init__(): incompatible constructor arguments. The following argument types are supported,93,0,10,1,['Bug']
67171,Libtorch has problems with expand(),0,0,2,0,['Other']
67170,[distributed.elastic] Setting elastic related args with environment variables,0,1,4,1,['Other']
67167,torch.nn.cross_entropy silently incorrect in PyTorch 1.10 on CUDA on non-contiguous inputs,7,1,7,4,['Critical']
67157,What is the replacement in PyTorch>=1.8 for `torch.rfft` in PyTorch <=1.6?,0,0,1,0,['Other']
67156,[ONNX] How to gathering on a tensor with two-dim indexing?,2,0,1,1,['Other']
67155,BUG:Occasionally Conv2d on Apple M1 returns NaN and INF in no_grad mode,3,0,6,4,"['Bug', 'Critical']"
67151,ImportError: cannot import name 'metanet_pb2' from partially initialized module 'caffe2.proto',2,0,4,3,['Bug']
67150,[website] torchaudio 0.10.0 windows build is missing for cuda 11.3,2,0,3,0,['Other']
67148,symbol lookup error: /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so.1: undefined symbol: __atomic_fetch_add_8,2,0,1,0,['Other']
67145,"OSError: [WinError 182] 操作系统无法运行 %1。 Error loading ""caffe2_detectron_ops.dll"" or one of its dependencies. ",3,0,2,0,['Other']
67141,Reproducing `torch.conj` example in release notes,2,0,3,3,['Other']
67140,cufft cache makes rfft with cuda tensors to return incorrect results in subsequent calls. ,9,0,3,5,['Critical']
67119,Request) draw_keypoints function,0,0,2,0,['Other']
67113,Support for torch.diagonal/torch.trace in ONNX models,73,0,2,4,['enhancement']
67112,Support torch.equal and torch.allclose for ShardedTensor,76,1,2,3,['Other']
67105,Add option to exclude first moment bias-correction in Adam/Adamw/other Adam variants.,299,0,2,2,['Other']
67101,DISABLED test_nccl_timeout (__main__.NcclErrorHandlingTest),39,1,4,5,"['Critical', 'Bug']"
67091,New un-declared dependency on libtinfo.so.5,0,0,8,3,['Other']
67089,Missing windows build for torchaudio-0.10.0 for the latest Pytorch ,3,0,24,6,['Critical']
67086,Issue regarding performance using dataloader,4,0,5,2,['Other']
67078,transformer results are not consistent for the case that src_key_padding_mask is define as None,0,0,2,0,['Other']
67073,CUDA extension with `TORCH_CUDABLAS_CHECK` throws undefined symbol error at import,20,0,6,3,['Bug']
67069,"cudatoolkit=11.3 reports ""Torch not compiled with CUDA enabled""",454,1,12,3,['Other']
67061,[Distributed Tests] Run a single distributed test in a standalone process,62,1,3,5,['Critical']
67038,Building error with CUPTI/KINETO enabled,1,0,4,4,['Bug']
67027,__getitem__ stops working after simple wrapping,4,1,0,2,['Other']
67024,All workflows are affected by github outage,0,0,1,2,['Other']
67013,How to use torch.distributions.multivariate_normal.MultivariateNormal in multi-gpu mode,235,0,3,3,['Other']
67012,`x.T` used on an input that's not a matrix in the OpInfo of `torch.tile`,21,1,3,2,['Other']
67009,Autograd fails without giving any warning while doing matrix operations,0,0,2,2,['Other']
67007,BCELoss pos_weight parameter,15,0,1,2,['Other']
66993,"[iOS] [HelloWorld] In Xcode Release mode, any module outputs always same",20,0,6,1,['Other']
66988,"import torch: Error loading ""XXXX\torch_python.dll"" or one of its dependencies.",0,0,2,2,['Bug']
66987,torch.onnx.export,74,0,4,3,['Other']
66983,DISABLED test_init_pg_and_rpc_with_same_socket (__main__.TCPStoreTest),13,1,3,4,['Critical']
66982,DISABLED test_barrier_timeout_global (__main__.TestDistBackendWithSpawn,40,0,2,4,['Critical']
66951,DISABLED test_ddp_comparison (__main__.TensorPipeDdpComparisonTest),41,0,4,4,['Critical']
66946,Error in icdf method of TransformedDistribution,99,0,1,3,['Bug']
66943,Return values of `func()` and the actual operator have different identities under `enable_python_mode()`,36,0,3,2,['Other']
66935,Why slower than torch2trt,96,0,3,5,['Other']
66928,RuntimeError: derivative for to_sparse is not implemented,0,0,4,3,['Bug']
66923,Extra memory used for the backward pass?,0,0,3,0,['Other']
66922,unfold bugs,5,0,3,3,['Bug']
66916,how to install torch version1.8.0 with cuda 11.2,1,0,1,0,['Other']
66911,[FSDP] Wait for optimizer stream in forward pre hook,361,0,1,2,['Other']
66910,Build LibTorch nightly for macOS with Metal support,18,0,5,2,['Other']
66906,Stop using Homebrew in our macos jobs,131,0,3,4,['enhancement']
66903,Test classes should extend common_utils.TestCase vs vanilla TestCase,97,0,2,4,['Other']
66896,[bug build] disable ninja to build pytorch,4,0,3,2,['Bug']
66893,DISABLED test_profiler_seq_nr (__main__.TestAutograd),428,0,10,5,['Other']
66892,torchaudio has unit tests failing only on Linux CPU Python 3.9,119,0,7,3,['Other']
66888,Migrate pytorch_linux_xenial_py3_6_gcc7 to GHA,5,0,0,2,['Other']
66883,Symbolic script produces wrong gradients,44,1,5,1,['Other']
66882,test_nccl_timeout (__main__.NcclErrorHandlingTest) is flaky,28,1,2,3,"['Critical', 'Bug']"
66876,TorchBench v1 score speedsup 0.8% on 20210620,0,0,0,0,['Other']
66873,Add documentation for how to work with PyTorch in Windows SSH,132,0,1,3,['Documentation']
66872,torch.nn.functional.nll_loss behaves differently in two cases of cpu and cuda,13,0,14,4,['Other']
66867,error while building PyTorch v1.10 on ppc64le ,8,0,22,3,['Bug']
66856,`random_fullrank_matrix_distinct_singular_value` may not be robust for creating large invertible matrices on CUDA,78,0,4,4,['Other']
66855,ONNX export failed: Couldn't export Python operator Scatter,26,0,1,3,['Other']
66810,"bazel CI running into ""403 Forbidden"" when installing dependencies",0,1,9,4,['Critical']
66802,test_addr_type_promotion in test_linalg takes too long,0,0,0,3,['Other']
66800,TorchBench Performance Event: Score down 0.6% on 20210712,16,0,14,4,['Other']
66786,torch.onnx.export fails to export Hugging Face BERT with meaningful weight name,84,1,1,3,['Other']
66785,Different package names between conda and pip messes with requirements.txt looking for torch,78,0,1,2,['Other']
66780,Wrong argument to torch.is_floating_type in test_result_dtype,129,1,1,3,['Bug']
66769,f,0,0,0,0,['Other']
66764,Incorrect result when conditionally updating tensor with boolean mask. ,1,0,2,3,['Other']
66763,dot to ONNX format issue using 1.9.1,8,0,1,2,['Other']
66759,Pytorch 1.11nightly suddenly not compiling my cuda extensions?,10,0,5,2,['Other']
66748,torch.sum mismatch on cuda after extending a non-reduced dimension,1,0,2,0,['Other']
66725,Merge `ciflow-should-run` job into the first build job,67,1,1,4,['enhancement']
66712,CPU Capability is being reported as AVX512 even if PyTorch is built without AVX512 ATen kernels,206,2,6,4,['Critical']
66710,Internal assert failed when using a mask to index a cuda tensor in deterministic mode,1,0,3,0,['Other']
66686,Improve use_state_dict in AveragedModel,103,1,7,2,['Other']
66685,Can't integrate pytorch-mobile with react-native android app,0,0,2,0,['Other']
66682,Pytorch tutorial - Colab link broken,0,0,1,0,['Other']
66679,Nightly build downloads logic should be improved,17,0,1,3,['Other']
66674,win-vs2019-cuda11.3-py3 OOMing,136,0,9,3,['Other']
66654,[JIT] Optimize Cat,232,1,0,2,['Other']
66652,[JIT] Support Submodule Parameter Preservation in Freezing,232,1,0,1,['Other']
66650, [JIT] Add Debug Assertions that the Stack is empty after inference,54,1,0,1,['Bug']
66641,DISABLED test_create_store_multi (__main__.DistributedUtilTest),12,0,5,3,['Other']
66635,DISABLED test_timeout (__main__.TestDataLoader),165,1,2,5,['Critical']
66634,test_dropout (test_jit_fuser.TestFuser) fails intermittently,0,0,1,4,['Critical']
66633,test_timeout in TestDataLoader fails intermittently,0,0,3,4,['Critical']
66619,derivative for heaviside is not implemented in version 1.9.0,0,0,1,0,['Other']
66618,Derivative for aten::linalg_pinv is not implemented,3,0,6,3,['Other']
66616,RuntimeError: Exporting the operator __is_ to ONNX opset version 13 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.,4,0,3,3,['Bug']
66610,Exporting the operator _sparse_mm to ONNX opset version 10 is not supported. Please open a bug to request ONNX export support for the missing operator.,1,0,1,2,['Bug']
66609,123,0,0,0,0,['Other']
66556,Scalar equality check does not use tolerances specified in OpInfo decorators,133,1,2,3,['Bug']
66552,"MacOS and iOS CI failing with ""ssh: connect to host github.com port 22: Operation timed out""",0,0,6,5,"['Critical', 'Bug']"
66551,Issues related to Pytorch1.4.0 detach function,5,0,2,0,['Other']
66549,add unpack_sequence and unpad_sequence functions,28,0,1,4,['enhancement']
66548,`torch.save` and `torch.load` fail to roundtrip with `io.BytesIO`,2,0,3,1,['Other']
66546,Magma / cuBLAS for 2-norm and other norms,0,0,4,5,['enhancement']
66543,"`torch::stft` function in LibTorch-Lite expects `0 < n_fft < 1`, `torch::fft_fft2` function says ATen not compiled with MKL, and LAPACK not found",1,0,14,2,['Other']
66541,Static Runtime clone test is failing intermittently,7,1,4,4,['Critical']
66537,An error occurred when exporting a gcn model using torch.onnx.export().,37,0,5,3,['Bug']
66526,Simple Calculations on Multipl GPU,0,0,1,0,['Other']
66511,Add a config to PRs where we assume there is only 1 GPU available,34,1,2,3,['Other']
66510,Identify if there are more people struggling with #66434,138,0,2,2,['Other']
66508,Add retries to docker sign-in and docker pull for all CI,86,0,2,2,['Other']
66507,Periodic jobs have been skipped on trunk for a long long time now,20,0,1,2,['Other']
66503,DISABLED test_timer_tiny_fast_snippet (__main__.TestBenchmarkUtils),68,1,4,4,['Critical']
66502,ONNX Runtime backend tests on CI are disabled,1,1,4,4,['Critical']
66495,index_put_ internal assert on CUDA but not on CPU,9,0,2,3,['Critical']
66490,[ci] Tracking issue: GHA cancellations,139,1,4,2,['Other']
66488,DISABLED test_ddp_comparison_uneven_inputs (__main__.TensorPipeDdpComparisonTest),16,0,2,3,['Other']
66487,TestBenchmarkUtils.test_timer_tiny_fast_snippet raises divide by 0 error,0,0,1,3,['Bug']
66483,Quantization - Linear-Bn1d fusion should support QAT,188,1,1,1,['Other']
66479,nn_upsample_***,0,0,1,0,['Other']
66475,Exporting the operator roll to ONNX opset version 12 is not supported,377,1,4,3,['Other']
66474,ONNX export produce wrong result on nightly build,2,1,2,3,['Other']
66471,No win cuda tests are running on PRs?,42,1,5,3,['Critical']
66468,distribute的hang ,0,0,0,0,['Other']
66466,documentation build run in CI is different from documentation build run on master,1,1,2,4,"['Documentation', 'Critical']"
66462,Deprecating Python 3.6 support,126,1,5,5,['Other']
66458,torch.mm unexpected behavior,0,0,1,1,['Other']
66446,Enable backward pass comms for sharded linear.,58,0,0,3,['Other']
66444,`torch.load()` fails under `enable_python_mode()`,100,0,3,3,['Other']
66439,PythonProcessGroupTest.test_collectives is flaky,1,0,2,4,['Critical']
66434,CircleCI workflows consistently erring for some exported PRs with permission issues,21,0,5,3,['Bug']
66425,"torch/onnx/utils.py"", line 501, in _model_to_graph     params_dict = torch._C._jit_pass_onnx_constant_fold(graph, params_dict, RuntimeError: expected scalar type Long but found Float",84,1,4,5,['Bug']
66424,Add Python-3.10 support,331,1,22,4,"['Critical', 'enhancement']"
66423,DISABLED test_send_recv (__main__.PythonProcessGroupTest),15,1,1,6,['Critical']
66422,DISABLED test_collectives (__main__.PythonProcessGroupTest),15,1,4,7,['Critical']
66420,lstsq not working with autograd,1,1,6,5,['Critical']
66418,How to implement dynamic sampling of training data?,1,0,2,2,['Other']
66406,IBM z14/15 simd support,85,0,10,3,['Other']
66402,torch.isfinite incorrect output on cpu,204,0,4,4,['Other']
66399,"ERROR: could not find a version that satisfies the requirement torch==1.9.1+cu111(from versions 0.1.2, 0.1.2post1, 0.1.2post2 ERROR: No matching distribution found for torch==1.9.1+cu111",0,0,3,2,['Bug']
66382,Support memoryview(tensor) and buffer protocol on tensors,1,0,1,2,['Other']
66375,discuss.pytorch.org is down,1,0,2,1,['Other']
66365,Unsupported prim::Constant kind: `ival`,317,0,7,2,['Other']
66363,`torch.nn.utils.parametrizations.spectral_norm` cannot use twice,2,0,2,2,['Other']
66360,Doubts about masked_scatter gradient,0,0,0,0,['Other']
66354,test_nccl_timeout should not rely on time.sleep(),62,0,1,4,['Critical']
66353,Segfault in nightly binaries while creating a tensor form a list if numpy is missing,3,1,3,6,"['Critical', 'Bug']"
66345,CosineAnnealingWarmRestarts η_max,0,0,1,0,['Other']
66333,CUDA extension gets build error when no GPU/driver is present.,0,0,1,0,['Other']
66330,Should the Complexity of GPU Cumsum Be O(n)?,4,0,1,2,['Other']
66329,Add _reduce_scatter_base and _allgather_base to processGroupWrapper,263,2,0,5,['Other']
66328,Better (optional) tensor list handling in native kernels,175,1,8,3,['Other']
66322,Audit BinaryUfuncInfos,105,0,0,2,['Other']
66319,DISABLED test_create_store_multi (__main__.DistributedUtilTest),18,0,2,5,['Critical']
66309,How to find the source kernel code of cumsum (gpu),0,0,2,0,['Other']
66307,mobile_optimizer.optimize_for_mobile fail when backend is Metal,0,0,4,0,['Other']
66287,Android and mobile CI build on CircleCI timed out for seemingly no reason,143,0,3,2,['Other']
66281,Rearrange row logic seems not to work correctly in _handle_col_wise_sharding ,19,0,1,3,['Other']
66278,Windows build in CI failing due to mt.exe manifest issue,144,0,7,3,['Other']
66269,Checkout PyTorch failure: Error: fatal: not a git repository: ...third_party/NNPACK_deps/psimd,4,0,4,2,['Bug']
66268,[pytorch_xla_linux_bionic_py3_6_clang9_build] llvm apt repositories erroring out on fetch (File has unexpected size),0,0,1,1,['Bug']
66266,[bootcamp task] Add forward AD support for specific ops,192,1,0,4,['Other']
66259,TorchBench v1 score regresses 2% on 20210605,140,3,2,2,['Other']
66252,`binary_macos_wheel_3_7_cpu_build` are broken,0,0,3,3,['Critical']
66250,Switch from onnx.optimizer to onnxoptimizer,193,1,6,4,['Other']
66248,Breaking change in torch.nn.functional.gelu,4,0,2,0,['Other']
66246,Why BatchNorm need to distinguish ndim,136,0,4,4,['Other']
66232,[RFC] Establishing PyTorch Test Owners,29,0,17,2,['Other']
66231,Weird Transpose CNN behavior ,2,0,1,0,['Other']
66229,Clarify hook support in DDP,182,1,2,4,['Critical']
66228,Virtualize `FloatStorage` and other `<type>Storage` classes,167,1,0,2,['Other']
66215,Track models with SyncBN in DDP,12,0,0,4,['Other']
66212,Precision issue in matrix-vector multiplication,2,0,2,1,['Other']
66207,DISABLED test_create_store_single_server (__main__.DistributedUtilTest),438,0,5,6,['Critical']
66203,Load LSTM layer in one GPU but other GPUS' memory usage also increase when inferencing,93,0,1,2,['Other']
66190,Error on unsupported key in dispatch in native_functions.yaml,139,0,0,2,['Bug']
66187,Revise `gather()` method of `ShardedTensor`,310,0,1,3,['Other']
66184,test_import_stats is flaky,0,0,2,4,['Critical']
66180,Add tests to cover default args + concrete_args,383,1,0,2,['Other']
66178,[Meta] CI Revert Tracker,398,0,30,2,['Other']
66173,DISABLED jfkdjgfkldjgldg.gdg [IGNORE THIS],0,1,2,0,['Other']
66151,FX throws NameError: name 'Proxy' is not defined,0,0,1,1,['Bug']
66124,No GHA workflows are scheduled for PR,6,0,6,4,['Critical']
66119,Potential strict aliasing rule violation in bitwise_binary_op (on ARM/NEON),48,0,8,4,['Critical']
66111,`caffe2/pytrhon/ideep/conv_op_test.py` fails if AVX512 acceleration is used,294,0,0,4,['Other']
66110,Some workflows does not seem to be triggered by GHA,1,0,1,2,['Other']
66105,Add input node id tracking to autograd profiler along with input tensor dimensions,177,0,6,1,['Other']
66088,facebook.com outage affecting upload of test stats causing workflows to fail,0,0,2,0,['Other']
66086,Backwards compatibility is broken between 1.9.1 and nightly for `torch.cosine_similarity`,2,0,3,3,['Critical']
66084,Torch.angle() with NaN gradients,0,0,1,0,['Other']
66077,error: 'cout' is not a member of 'std' on ppc64le,0,0,8,3,['Bug']
66072,Batched torch.cholesky_solve is incorrect for CUDA inputs in 1.9.1,63,1,5,5,['Critical']
66067,RuntimeError: Error while setting up backward hooks. Please open an issue with a code sample to reproduce this ,1,0,6,2,['Bug']
66062,TestZeroRedundancyOptimizerDistributed.test_multiple_groups is timing out,0,0,1,3,['Critical']
66061,TorchScript model conversion failed with  INTERNAL ASSERT FAILED,16,0,1,1,['Other']
66059,TestZeroRedundancyOptimizerDistributed.test_multiple_groups is failing intermittently,164,1,5,6,['Critical']
66053,Comparison operators throw internal assert for cpu scalar - cuda tensor op,20,1,1,3,['Other']
66047,Conda installs CPU ver despite cudatoolkit is provided,8,0,9,3,['Other']
66039,Difference between torch.rand and nn.init.uniform_ to create a learnable parameter,1,0,1,0,['Other']
66037,Segmentation fault after removing hook within its associated hook function.,4,0,3,4,['Critical']
66034,Building PyTorch without conda,0,0,2,2,['Other']
66030,Building libtorch + tests results in a failure,3,0,2,3,['Other']
66024,`Tensor.tolist()` produces incorrect values for conjugated tensors,12,0,3,4,['Critical']
66020,Testing ROCm labeling,0,0,1,1,['Other']
65999,"All datapipes that take a single callable, should also take args and kwargs",73,0,1,2,['Other']
65997,Per-overload torch.ops API,96,1,4,3,['Other']
65992,How to use `MASTER_ADDR` in a distributed training script,31,0,19,2,['Other']
65991,Libtorch.so exporting mkl symbols?,0,0,1,0,['Other']
65989,Bug: torch.tensordot is not consistent with np.tensordot,0,0,1,2,['Bug']
65988,Many iOS jobs are broken due to expired cert,0,0,3,2,['Other']
65981,saved_variable hook,0,0,1,0,['Other']
65980,"Improve this error message: RuntimeError: Expected from <= to to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",116,0,4,3,"['enhancement', 'Bug']"
65978,Scale-down lambda incorrectly marking runners for deletion,0,1,3,3,['Critical']
65956,./aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:192:12: error: cout is not a member of std,5,0,2,4,['Bug']
65945,Negative view test fails for resize_,4,0,3,6,['Critical']
65931,`pytorch_linux_xenial_py3_6_gcc5_4_test` failing due to cert issues,0,0,3,6,['Critical']
65925, GPU cannot load the video frames,5,0,1,3,['Other']
65922,Queue time for GPU tests exceeds 7 hours,0,1,4,4,['Critical']
65920,Obscure error when source dir is not writeable,12,1,0,3,['Bug']
65919,Function matmul returns incorrect/imprecise results.,3,0,3,2,['Other']
65916,Implementation of Parameterized Hypercomplex Multiplication Layer,4,0,1,3,['enhancement']
65911,`pinv` could be differentiable on a wider range of inputs,11,1,4,3,['Other']
65909,Deprecation: Remove nn.functional.tanh,419,0,7,5,['Other']
65908,Function request: np.around (alias with torch.round),118,1,4,4,['Critical']
65906,Function request: alias arctan2 to atan2,47,0,2,4,['Other']
65905,Docs: acosh documentation needs its mathematical formula moved above its note,300,1,2,3,['Documentation']
65884,DISABLED test_fn_grad_min_binary_cuda_float64 (__main__.TestGradientsCUDA),180,0,10,3,['Other']
65870,nvidia-smi utilization and memory stats native in pytorch,69,0,4,4,['enhancement']
65863,torch.sort may have a regression in nightly,1,0,5,4,['Critical']
65858,High CPU usage occurred when using 'torch::from_blob' to create tensor from Mat in C++,1,0,1,0,['Other']
65853,Couldn't export Python operator when operator_export_type set to ONNX_FALLTHROUGH,379,1,5,2,['Other']
65830,c10::Scalar::to<T>() generated code is ludicrously long,21,0,1,3,['Other']
65822,Impossible to launch operators on an external CUDA stream,8,0,3,2,['Other']
65817,torch.all with dim Onnx: _all() takes 2 positional arguments but 4 were given ,6,1,2,2,['Other']
65816,How to install PyTorch on ppc64le with pip?,2,0,1,0,['Other']
65810,Torch.onnx.export: [error in flatten: list index out of range] ,96,1,2,4,['Bug']
65809,some confusion about libtorch-BatchNorm2d,2,0,1,0,['Other']
65808,Closing tar file in `TarFileReader` breaks buffered datapipes,1,0,2,2,['Other']
65797,CUDA ROCm grad tests sometimes leak memory ,33,0,5,4,['Critical']
65794,[ShardedTensor] Rename ShardMetadata.shard_lengths to shard_sizes,51,0,0,3,['Other']
65793,`torch.cuda.memory_stats` returns empty dict,0,0,2,1,['Other']
65786,`torch.get_autocast_cpu_dtype()` returns a new dtype,14,0,2,3,['Critical']
65779,Comparing tensor subclass instance with `None` causes segmentation fault,99,0,4,4,['Critical']
65767,Elevated Queue Times for Github Actions,0,1,1,5,['Critical']
65750,Add memory_format support for `torch.zeros`,30,2,1,2,['Other']
65747,Something went wrong when running an inference with a trained model,3,0,1,0,['Other']
65738,Save and restore Sobol state,0,0,0,0,['Other']
65727,`pytorch_linux_xenial_py3_clang7_asan_test2` times out,13,0,7,5,['Critical']
65719,.jenkins/pytorch/win-test-helpers/installation-helpers/install_sccache.bat,0,0,0,0,['Other']
65717,Stop printing verbose compilation commands for windows CI,239,1,4,3,['Other']
65711,Cleanup optimizer handling of complex numbers.,373,0,19,4,['Other']
65709,Difference in `torch.normal` between pytorch 1.8.1 and pytorch 1.9.0,14,0,3,3,['Critical']
65696,`_object_to_tensor` is much slower for large objects since 1.9,0,1,3,2,['Other']
65689,Questions in use pack_padded_sequence: how to pack Multiple tensor?,0,0,1,0,['Other']
65685,A Strange type properties in pytorch math function,1,0,4,2,['Other']
65684,"`torch.nn.functional.l1_loss` is ""wrong"" for complex inputs",0,0,3,2,['Other']
65682,How to export split to ONNX with dynamic split_size?,395,1,4,2,['Other']
65679,"Libtorch windows 32bit, load model error",118,0,1,2,['Bug']
65678,-m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE,9,0,4,2,['Other']
65676,TypeError: forward() takes 2 positional arguments but 3 were given,0,0,1,0,['Other']
65666,Exporting torch.stft and torch.istft to ONNX,354,0,6,3,['Other']
65659,"/opt/conda/conda-bld/pytorch_1631630806732/work/aten/src/ATen/native/cuda/Loss.cu:111: operator(): block: [0,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.",1,0,2,0,['Other']
65656,Layernormal seems only support torch.float32 。,2,0,2,0,['Other']
65652,[Pytorch Tensorboard] torch.utils.tensorboard parse jit tracing pytorch graph incorrectly,25,0,3,1,['Other']
65651,Why official released torch whl doesn't contain __cxx11 symbol about c10::Error::Error(std::__cxx11::basic_string...) in libc10.so?,1,0,2,0,['Other']
65648,Stop windows cuda 10.2 CI builds and releases,4,0,2,5,['Other']
